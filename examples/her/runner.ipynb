{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n",
      "2020-09-10 08:52:41.865291 EEST | Variant:\n",
      "2020-09-10 08:52:41.865503 EEST | {\n",
      "  \"algorithm\": \"HER-DDPG\",\n",
      "  \"version\": \"normal\",\n",
      "  \"num_demos\": 100,\n",
      "  \"env_name\": \"ClothSidewaysStrictPixels-v1\",\n",
      "  \"env_type\": \"sideways\",\n",
      "  \"demo_file_name\": \"/Users/juliushietala/Desktop/Robotics/baselines/baselines/her/experiment/data_generation/data_cloth_diagonal_rlkit_100.npz\",\n",
      "  \"algo_kwargs\": {\n",
      "    \"batch_size\": 1024,\n",
      "    \"num_epochs\": 100,\n",
      "    \"num_eval_steps_per_epoch\": 500,\n",
      "    \"num_expl_steps_per_train_loop\": 50,\n",
      "    \"num_trains_per_train_loop\": 40,\n",
      "    \"num_train_loops_per_epoch\": 20,\n",
      "    \"min_num_steps_before_training\": 0,\n",
      "    \"max_path_length\": 50\n",
      "  },\n",
      "  \"ddpg_trainer_kwargs\": {\n",
      "    \"use_soft_update\": true,\n",
      "    \"target_soft_update_period\": 40,\n",
      "    \"tau\": 0.05,\n",
      "    \"discount\": 0.99,\n",
      "    \"qf_learning_rate\": 0.001,\n",
      "    \"policy_learning_rate\": 0.001\n",
      "  },\n",
      "  \"replay_buffer_kwargs\": {\n",
      "    \"max_size\": 500000,\n",
      "    \"fraction_goals_rollout_goals\": 0.2,\n",
      "    \"fraction_goals_env_goals\": 0,\n",
      "    \"internal_keys\": \"['image']\"\n",
      "  },\n",
      "  \"demo_buffer_kwargs\": {\n",
      "    \"max_size\": 100,\n",
      "    \"internal_keys\": \"['image']\"\n",
      "  },\n",
      "  \"qf_kwargs\": {\n",
      "    \"hidden_sizes\": [\n",
      "      256,\n",
      "      256,\n",
      "      256\n",
      "    ]\n",
      "  },\n",
      "  \"policy_kwargs\": {\n",
      "    \"input_width\": 84,\n",
      "    \"input_height\": 84,\n",
      "    \"input_channels\": 3,\n",
      "    \"kernel_sizes\": [\n",
      "      3,\n",
      "      3,\n",
      "      3,\n",
      "      3\n",
      "    ],\n",
      "    \"n_channels\": [\n",
      "      32,\n",
      "      32,\n",
      "      32,\n",
      "      32\n",
      "    ],\n",
      "    \"strides\": [\n",
      "      2,\n",
      "      2,\n",
      "      2,\n",
      "      2\n",
      "    ],\n",
      "    \"paddings\": [\n",
      "      0,\n",
      "      0,\n",
      "      0,\n",
      "      0\n",
      "    ],\n",
      "    \"hidden_sizes\": [\n",
      "      256,\n",
      "      256,\n",
      "      256,\n",
      "      256\n",
      "    ],\n",
      "    \"added_fc_input_size\": 6,\n",
      "    \"batch_norm_conv\": false,\n",
      "    \"batch_norm_fc\": false,\n",
      "    \"init_w\": 0.0001,\n",
      "    \"aux_output_size\": 12\n",
      "  }\n",
      "}\n",
      "ITERATION NUMBER  1 Success so far 0\n",
      "ITERATION NUMBER  2 Success so far 0\n",
      "ITERATION NUMBER  3 Success so far 0\n",
      "ITERATION NUMBER  4 Success so far 0\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  5 Success so far 1\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  6 Success so far 2\n",
      "ITERATION NUMBER  7 Success so far 2\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  8 Success so far 3\n",
      "ITERATION NUMBER  9 Success so far 3\n",
      "ITERATION NUMBER  10 Success so far 3\n",
      "ITERATION NUMBER  11 Success so far 3\n",
      "ITERATION NUMBER  12 Success so far 3\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  13 Success so far 4\n",
      "ITERATION NUMBER  14 Success so far 4\n",
      "ITERATION NUMBER  15 Success so far 4\n",
      "ITERATION NUMBER  16 Success so far 4\n",
      "ITERATION NUMBER  17 Success so far 4\n",
      "ITERATION NUMBER  18 Success so far 4\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  19 Success so far 5\n",
      "ITERATION NUMBER  20 Success so far 5\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  21 Success so far 6\n",
      "ITERATION NUMBER  22 Success so far 6\n",
      "ITERATION NUMBER  23 Success so far 6\n",
      "ITERATION NUMBER  24 Success so far 6\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  25 Success so far 7\n",
      "ITERATION NUMBER  26 Success so far 7\n",
      "ITERATION NUMBER  27 Success so far 7\n",
      "ITERATION NUMBER  28 Success so far 7\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  29 Success so far 8\n",
      "ITERATION NUMBER  30 Success so far 8\n",
      "ITERATION NUMBER  31 Success so far 8\n",
      "ITERATION NUMBER  32 Success so far 8\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  33 Success so far 9\n",
      "ITERATION NUMBER  34 Success so far 9\n",
      "ITERATION NUMBER  35 Success so far 9\n",
      "ITERATION NUMBER  36 Success so far 9\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  37 Success so far 10\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  38 Success so far 11\n",
      "ITERATION NUMBER  39 Success so far 11\n",
      "ITERATION NUMBER  40 Success so far 11\n",
      "ITERATION NUMBER  41 Success so far 11\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  42 Success so far 12\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  43 Success so far 13\n",
      "ITERATION NUMBER  44 Success so far 13\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  45 Success so far 14\n",
      "ITERATION NUMBER  46 Success so far 14\n",
      "ITERATION NUMBER  47 Success so far 14\n",
      "ITERATION NUMBER  48 Success so far 14\n",
      "ITERATION NUMBER  49 Success so far 14\n",
      "ITERATION NUMBER  50 Success so far 14\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  51 Success so far 15\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  52 Success so far 16\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  53 Success so far 17\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  54 Success so far 18\n",
      "ITERATION NUMBER  55 Success so far 18\n",
      "ITERATION NUMBER  56 Success so far 18\n",
      "ITERATION NUMBER  57 Success so far 18\n",
      "ITERATION NUMBER  58 Success so far 18\n",
      "ITERATION NUMBER  59 Success so far 18\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  60 Success so far 19\n",
      "ITERATION NUMBER  61 Success so far 19\n",
      "ITERATION NUMBER  62 Success so far 19\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  63 Success so far 20\n",
      "ITERATION NUMBER  64 Success so far 20\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  65 Success so far 21\n",
      "ITERATION NUMBER  66 Success so far 21\n",
      "ITERATION NUMBER  67 Success so far 21\n",
      "ITERATION NUMBER  68 Success so far 21\n",
      "ITERATION NUMBER  69 Success so far 21\n",
      "ITERATION NUMBER  70 Success so far 21\n",
      "ITERATION NUMBER  71 Success so far 21\n",
      "ITERATION NUMBER  72 Success so far 21\n",
      "ITERATION NUMBER  73 Success so far 21\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  74 Success so far 22\n",
      "ITERATION NUMBER  75 Success so far 22\n",
      "ITERATION NUMBER  76 Success so far 22\n",
      "ITERATION NUMBER  77 Success so far 22\n",
      "ITERATION NUMBER  78 Success so far 22\n",
      "ITERATION NUMBER  79 Success so far 22\n",
      "ITERATION NUMBER  80 Success so far 22\n",
      "ITERATION NUMBER  81 Success so far 22\n",
      "ITERATION NUMBER  82 Success so far 22\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  83 Success so far 23\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  84 Success so far 24\n",
      "ITERATION NUMBER  85 Success so far 24\n",
      "ITERATION NUMBER  86 Success so far 24\n",
      "ITERATION NUMBER  87 Success so far 24\n",
      "ITERATION NUMBER  88 Success so far 24\n",
      "ITERATION NUMBER  89 Success so far 24\n",
      "ITERATION NUMBER  90 Success so far 24\n",
      "ITERATION NUMBER  91 Success so far 24\n",
      "ITERATION NUMBER  92 Success so far 24\n",
      "ITERATION NUMBER  93 Success so far 24\n",
      "ITERATION NUMBER  94 Success so far 24\n",
      "ITERATION NUMBER  95 Success so far 24\n",
      "ITERATION NUMBER  96 Success so far 24\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  97 Success so far 25\n",
      "ITERATION NUMBER  98 Success so far 25\n",
      "ITERATION NUMBER  99 Success so far 25\n",
      "ITERATION NUMBER  100 Success so far 25\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  101 Success so far 26\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  102 Success so far 27\n",
      "ITERATION NUMBER  103 Success so far 27\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  104 Success so far 28\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  105 Success so far 29\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  106 Success so far 30\n",
      "ITERATION NUMBER  107 Success so far 30\n",
      "ITERATION NUMBER  108 Success so far 30\n",
      "ITERATION NUMBER  109 Success so far 30\n",
      "ITERATION NUMBER  110 Success so far 30\n",
      "ITERATION NUMBER  111 Success so far 30\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  112 Success so far 31\n",
      "ITERATION NUMBER  113 Success so far 31\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  114 Success so far 32\n",
      "ITERATION NUMBER  115 Success so far 32\n",
      "ITERATION NUMBER  116 Success so far 32\n",
      "ITERATION NUMBER  117 Success so far 32\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  118 Success so far 33\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  119 Success so far 34\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  120 Success so far 35\n",
      "ITERATION NUMBER  121 Success so far 35\n",
      "ITERATION NUMBER  122 Success so far 35\n",
      "ITERATION NUMBER  123 Success so far 35\n",
      "ITERATION NUMBER  124 Success so far 35\n",
      "ITERATION NUMBER  125 Success so far 35\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  126 Success so far 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION NUMBER  127 Success so far 36\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  128 Success so far 37\n",
      "ITERATION NUMBER  129 Success so far 37\n",
      "ITERATION NUMBER  130 Success so far 37\n",
      "ITERATION NUMBER  131 Success so far 37\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  132 Success so far 38\n",
      "ITERATION NUMBER  133 Success so far 38\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  134 Success so far 39\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  135 Success so far 40\n",
      "ITERATION NUMBER  136 Success so far 40\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  137 Success so far 41\n",
      "ITERATION NUMBER  138 Success so far 41\n",
      "ITERATION NUMBER  139 Success so far 41\n",
      "ITERATION NUMBER  140 Success so far 41\n",
      "ITERATION NUMBER  141 Success so far 41\n",
      "ITERATION NUMBER  142 Success so far 41\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  143 Success so far 42\n",
      "ITERATION NUMBER  144 Success so far 42\n",
      "ITERATION NUMBER  145 Success so far 42\n",
      "ITERATION NUMBER  146 Success so far 42\n",
      "ITERATION NUMBER  147 Success so far 42\n",
      "ITERATION NUMBER  148 Success so far 42\n",
      "ITERATION NUMBER  149 Success so far 42\n",
      "ITERATION NUMBER  150 Success so far 42\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  151 Success so far 43\n",
      "ITERATION NUMBER  152 Success so far 43\n",
      "ITERATION NUMBER  153 Success so far 43\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  154 Success so far 44\n",
      "ITERATION NUMBER  155 Success so far 44\n",
      "ITERATION NUMBER  156 Success so far 44\n",
      "ITERATION NUMBER  157 Success so far 44\n",
      "ITERATION NUMBER  158 Success so far 44\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  159 Success so far 45\n",
      "ITERATION NUMBER  160 Success so far 45\n",
      "ITERATION NUMBER  161 Success so far 45\n",
      "ITERATION NUMBER  162 Success so far 45\n",
      "ITERATION NUMBER  163 Success so far 45\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  164 Success so far 46\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  165 Success so far 47\n",
      "ITERATION NUMBER  166 Success so far 47\n",
      "ITERATION NUMBER  167 Success so far 47\n",
      "ITERATION NUMBER  168 Success so far 47\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  169 Success so far 48\n",
      "ITERATION NUMBER  170 Success so far 48\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  171 Success so far 49\n",
      "ITERATION NUMBER  172 Success so far 49\n",
      "ITERATION NUMBER  173 Success so far 49\n",
      "ITERATION NUMBER  174 Success so far 49\n",
      "ITERATION NUMBER  175 Success so far 49\n",
      "ITERATION NUMBER  176 Success so far 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  177 Success so far 50\n",
      "ITERATION NUMBER  178 Success so far 50\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  179 Success so far 51\n",
      "ITERATION NUMBER  180 Success so far 51\n",
      "ITERATION NUMBER  181 Success so far 51\n",
      "ITERATION NUMBER  182 Success so far 51\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  183 Success so far 52\n",
      "ITERATION NUMBER  184 Success so far 52\n",
      "ITERATION NUMBER  185 Success so far 52\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  186 Success so far 53\n",
      "ITERATION NUMBER  187 Success so far 53\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  188 Success so far 54\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  189 Success so far 55\n",
      "ITERATION NUMBER  190 Success so far 55\n",
      "ITERATION NUMBER  191 Success so far 55\n",
      "ITERATION NUMBER  192 Success so far 55\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  193 Success so far 56\n",
      "ITERATION NUMBER  194 Success so far 56\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  195 Success so far 57\n",
      "ITERATION NUMBER  196 Success so far 57\n",
      "ITERATION NUMBER  197 Success so far 57\n",
      "ITERATION NUMBER  198 Success so far 57\n",
      "ITERATION NUMBER  199 Success so far 57\n",
      "ITERATION NUMBER  200 Success so far 57\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  201 Success so far 58\n",
      "ITERATION NUMBER  202 Success so far 58\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  203 Success so far 59\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  204 Success so far 60\n",
      "ITERATION NUMBER  205 Success so far 60\n",
      "ITERATION NUMBER  206 Success so far 60\n",
      "ITERATION NUMBER  207 Success so far 60\n",
      "ITERATION NUMBER  208 Success so far 60\n",
      "ITERATION NUMBER  209 Success so far 60\n",
      "ITERATION NUMBER  210 Success so far 60\n",
      "ITERATION NUMBER  211 Success so far 60\n",
      "ITERATION NUMBER  212 Success so far 60\n",
      "ITERATION NUMBER  213 Success so far 60\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  214 Success so far 61\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  215 Success so far 62\n",
      "ITERATION NUMBER  216 Success so far 62\n",
      "ITERATION NUMBER  217 Success so far 62\n",
      "ITERATION NUMBER  218 Success so far 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  219 Success so far 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  220 Success so far 64\n",
      "ITERATION NUMBER  221 Success so far 64\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  222 Success so far 65\n",
      "ITERATION NUMBER  223 Success so far 65\n",
      "ITERATION NUMBER  224 Success so far 65\n",
      "ITERATION NUMBER  225 Success so far 65\n",
      "ITERATION NUMBER  226 Success so far 65\n",
      "ITERATION NUMBER  227 Success so far 65\n",
      "ITERATION NUMBER  228 Success so far 65\n",
      "ITERATION NUMBER  229 Success so far 65\n",
      "ITERATION NUMBER  230 Success so far 65\n",
      "ITERATION NUMBER  231 Success so far 65\n",
      "ITERATION NUMBER  232 Success so far 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  233 Success so far 66\n",
      "ITERATION NUMBER  234 Success so far 66\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  235 Success so far 67\n",
      "ITERATION NUMBER  236 Success so far 67\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  237 Success so far 68\n",
      "ITERATION NUMBER  238 Success so far 68\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  239 Success so far 69\n",
      "ITERATION NUMBER  240 Success so far 69\n",
      "ITERATION NUMBER  241 Success so far 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  242 Success so far 70\n",
      "ITERATION NUMBER  243 Success so far 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  244 Success so far 71\n",
      "ITERATION NUMBER  245 Success so far 71\n",
      "ITERATION NUMBER  246 Success so far 71\n",
      "ITERATION NUMBER  247 Success so far 71\n",
      "ITERATION NUMBER  248 Success so far 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  249 Success so far 72\n",
      "ITERATION NUMBER  250 Success so far 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  251 Success so far 73\n",
      "ITERATION NUMBER  252 Success so far 73\n",
      "ITERATION NUMBER  253 Success so far 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  254 Success so far 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  255 Success so far 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  256 Success so far 76\n",
      "ITERATION NUMBER  257 Success so far 76\n",
      "ITERATION NUMBER  258 Success so far 76\n",
      "ITERATION NUMBER  259 Success so far 76\n",
      "ITERATION NUMBER  260 Success so far 76\n",
      "ITERATION NUMBER  261 Success so far 76\n",
      "ITERATION NUMBER  262 Success so far 76\n",
      "ITERATION NUMBER  263 Success so far 76\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  264 Success so far 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  265 Success so far 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  266 Success so far 79\n",
      "ITERATION NUMBER  267 Success so far 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  268 Success so far 80\n",
      "ITERATION NUMBER  269 Success so far 80\n",
      "ITERATION NUMBER  270 Success so far 80\n",
      "ITERATION NUMBER  271 Success so far 80\n",
      "ITERATION NUMBER  272 Success so far 80\n",
      "ITERATION NUMBER  273 Success so far 80\n",
      "ITERATION NUMBER  274 Success so far 80\n",
      "ITERATION NUMBER  275 Success so far 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  276 Success so far 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  277 Success so far 82\n",
      "ITERATION NUMBER  278 Success so far 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  279 Success so far 83\n",
      "ITERATION NUMBER  280 Success so far 83\n",
      "ITERATION NUMBER  281 Success so far 83\n",
      "ITERATION NUMBER  282 Success so far 83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION NUMBER  283 Success so far 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  284 Success so far 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  285 Success so far 85\n",
      "ITERATION NUMBER  286 Success so far 85\n",
      "ITERATION NUMBER  287 Success so far 85\n",
      "ITERATION NUMBER  288 Success so far 85\n",
      "ITERATION NUMBER  289 Success so far 85\n",
      "ITERATION NUMBER  290 Success so far 85\n",
      "ITERATION NUMBER  291 Success so far 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  292 Success so far 86\n",
      "ITERATION NUMBER  293 Success so far 86\n",
      "ITERATION NUMBER  294 Success so far 86\n",
      "ITERATION NUMBER  295 Success so far 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  296 Success so far 87\n",
      "ITERATION NUMBER  297 Success so far 87\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  298 Success so far 88\n",
      "ITERATION NUMBER  299 Success so far 88\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  300 Success so far 89\n",
      "ITERATION NUMBER  301 Success so far 89\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  302 Success so far 90\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  303 Success so far 91\n",
      "ITERATION NUMBER  304 Success so far 91\n",
      "ITERATION NUMBER  305 Success so far 91\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  306 Success so far 92\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  307 Success so far 93\n",
      "ITERATION NUMBER  308 Success so far 93\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  309 Success so far 94\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  310 Success so far 95\n",
      "ITERATION NUMBER  311 Success so far 95\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  312 Success so far 96\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  313 Success so far 97\n",
      "ITERATION NUMBER  314 Success so far 97\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  315 Success so far 98\n",
      "ITERATION NUMBER  316 Success so far 98\n",
      "ITERATION NUMBER  317 Success so far 98\n",
      "ITERATION NUMBER  318 Success so far 98\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "ITERATION NUMBER  319 Success so far 99\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation sampling\n",
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 0\n",
      "\n",
      " Cycle 0 0\n",
      "Added episode 50\n",
      "Replay buf 50\n",
      "Soft update 0\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 0\n",
      "Added episode 50\n",
      "Replay buf 100\n",
      "Soft update 40\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 0\n",
      "Added episode 50\n",
      "Replay buf 150\n",
      "Soft update 80\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 0\n",
      "Added episode 50\n",
      "Replay buf 200\n",
      "Soft update 120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 0\n",
      "Added episode 50\n",
      "Replay buf 250\n",
      "Soft update 160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 0\n",
      "Added episode 50\n",
      "Replay buf 300\n",
      "Soft update 200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 0\n",
      "Added episode 50\n",
      "Replay buf 350\n",
      "Soft update 240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 0\n",
      "Added episode 50\n",
      "Replay buf 400\n",
      "Soft update 280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 0\n",
      "Added episode 50\n",
      "Replay buf 450\n",
      "Soft update 320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 0\n",
      "Added episode 50\n",
      "Replay buf 500\n",
      "Soft update 360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 0\n",
      "Added episode 50\n",
      "Replay buf 550\n",
      "Soft update 400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 0\n",
      "Added episode 50\n",
      "Replay buf 600\n",
      "Soft update 440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 0\n",
      "Added episode 50\n",
      "Replay buf 650\n",
      "Soft update 480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 0\n",
      "Added episode 50\n",
      "Replay buf 700\n",
      "Soft update 520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 0\n",
      "Added episode 50\n",
      "Replay buf 750\n",
      "Soft update 560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 0\n",
      "Added episode 50\n",
      "Replay buf 800\n",
      "Soft update 600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 0\n",
      "Added episode 50\n",
      "Replay buf 850\n",
      "Soft update 640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 0\n",
      "Added episode 50\n",
      "Replay buf 900\n",
      "Soft update 680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 0\n",
      "Added episode 50\n",
      "Replay buf 950\n",
      "Soft update 720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 0\n",
      "Added episode 50\n",
      "Replay buf 1000\n",
      "Soft update 760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:03:32.337826 EEST | [final-sideways-pixels-final-31] Epoch 0 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                 0.482642\n",
      "trainer/Policy Loss                                             0.00172348\n",
      "trainer/Raw Policy Loss                                         0.00172348\n",
      "trainer/State estimation loss                                   0.219744\n",
      "trainer/Preactivation Policy Loss                               0\n",
      "trainer/Q Predictions Mean                                      0.00166551\n",
      "trainer/Q Predictions Std                                       5.79539e-05\n",
      "trainer/Q Predictions Max                                       0.00197737\n",
      "trainer/Q Predictions Min                                       0.00150593\n",
      "trainer/Q Targets Mean                                         -0.480994\n",
      "trainer/Q Targets Std                                           0.499677\n",
      "trainer/Q Targets Max                                           0.00164612\n",
      "trainer/Q Targets Min                                          -0.998395\n",
      "trainer/Bellman Errors Mean                                     0.482642\n",
      "trainer/Bellman Errors Std                                      0.499702\n",
      "trainer/Bellman Errors Max                                      1.00066\n",
      "trainer/Bellman Errors Min                                      3.52501e-15\n",
      "trainer/Policy Action Mean                                     -5.37533e-05\n",
      "trainer/Policy Action Std                                       2.3812e-05\n",
      "trainer/Policy Action Max                                      -2.10776e-05\n",
      "trainer/Policy Action Min                                      -7.71436e-05\n",
      "exploration/num steps total                                  1000\n",
      "exploration/num paths total                                    20\n",
      "exploration/path length Mean                                   50\n",
      "exploration/path length Std                                     0\n",
      "exploration/path length Max                                    50\n",
      "exploration/path length Min                                    50\n",
      "exploration/Rewards Mean                                       -1\n",
      "exploration/Rewards Std                                         0\n",
      "exploration/Rewards Max                                        -1\n",
      "exploration/Rewards Min                                        -1\n",
      "exploration/Returns Mean                                      -50\n",
      "exploration/Returns Std                                         0\n",
      "exploration/Returns Max                                       -50\n",
      "exploration/Returns Min                                       -50\n",
      "exploration/Actions Mean                                       -0.0700683\n",
      "exploration/Actions Std                                         0.424159\n",
      "exploration/Actions Max                                         1\n",
      "exploration/Actions Min                                        -1\n",
      "exploration/Num Paths                                          20\n",
      "exploration/Average Returns                                   -50\n",
      "exploration/env_infos/final/is_success Mean                     0\n",
      "exploration/env_infos/final/is_success Std                      0\n",
      "exploration/env_infos/final/is_success Max                      0\n",
      "exploration/env_infos/final/is_success Min                      0\n",
      "exploration/env_infos/initial/is_success Mean                   0\n",
      "exploration/env_infos/initial/is_success Std                    0\n",
      "exploration/env_infos/initial/is_success Max                    0\n",
      "exploration/env_infos/initial/is_success Min                    0\n",
      "exploration/env_infos/is_success Mean                           0\n",
      "exploration/env_infos/is_success Std                            0\n",
      "exploration/env_infos/is_success Max                            0\n",
      "exploration/env_infos/is_success Min                            0\n",
      "evaluation/num steps total                                    500\n",
      "evaluation/num paths total                                     10\n",
      "evaluation/path length Mean                                    50\n",
      "evaluation/path length Std                                      0\n",
      "evaluation/path length Max                                     50\n",
      "evaluation/path length Min                                     50\n",
      "evaluation/Rewards Mean                                        -1\n",
      "evaluation/Rewards Std                                          0\n",
      "evaluation/Rewards Max                                         -1\n",
      "evaluation/Rewards Min                                         -1\n",
      "evaluation/Returns Mean                                       -50\n",
      "evaluation/Returns Std                                          0\n",
      "evaluation/Returns Max                                        -50\n",
      "evaluation/Returns Min                                        -50\n",
      "evaluation/Actions Mean                                        -5.37533e-05\n",
      "evaluation/Actions Std                                          2.3812e-05\n",
      "evaluation/Actions Max                                         -2.10776e-05\n",
      "evaluation/Actions Min                                         -7.71436e-05\n",
      "evaluation/Num Paths                                           10\n",
      "evaluation/Average Returns                                    -50\n",
      "evaluation/env_infos/final/is_success Mean                      0\n",
      "evaluation/env_infos/final/is_success Std                       0\n",
      "evaluation/env_infos/final/is_success Max                       0\n",
      "evaluation/env_infos/final/is_success Min                       0\n",
      "evaluation/env_infos/initial/is_success Mean                    0\n",
      "evaluation/env_infos/initial/is_success Std                     0\n",
      "evaluation/env_infos/initial/is_success Max                     0\n",
      "evaluation/env_infos/initial/is_success Min                     0\n",
      "evaluation/env_infos/is_success Mean                            0\n",
      "evaluation/env_infos/is_success Std                             0\n",
      "evaluation/env_infos/is_success Max                             0\n",
      "evaluation/env_infos/is_success Min                             0\n",
      "evaluation/demonstrations/Rewards Mean                         -0.971264\n",
      "evaluation/demonstrations/Rewards Std                           0.167063\n",
      "evaluation/demonstrations/Rewards Max                          -0\n",
      "evaluation/demonstrations/Rewards Min                          -1\n",
      "evaluation/demonstrations/Returns Mean                        -33.8\n",
      "evaluation/demonstrations/Returns Std                           5.97997\n",
      "evaluation/demonstrations/Returns Max                         -28\n",
      "evaluation/demonstrations/Returns Min                         -47\n",
      "evaluation/demonstrations/Actions Mean                         -0.0799319\n",
      "evaluation/demonstrations/Actions Std                           0.291659\n",
      "evaluation/demonstrations/Actions Max                           0.522945\n",
      "evaluation/demonstrations/Actions Min                          -0.779109\n",
      "evaluation/demonstrations/Num Paths                            10\n",
      "evaluation/demonstrations/Average Returns                     -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean       1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std        0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min        1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean     0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min      0\n",
      "evaluation/demonstrations/env_infos/is_success Mean             0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std              0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max              1\n",
      "evaluation/demonstrations/env_infos/is_success Min              0\n",
      "time/data storing (s)                                           0.116781\n",
      "time/evaluation sampling (s)                                   13.3451\n",
      "time/exploration sampling (s)                                  28.2498\n",
      "time/logging (s)                                                0.00675549\n",
      "time/saving (s)                                                 0.0712902\n",
      "time/training (s)                                             197.512\n",
      "time/epoch (s)                                                239.302\n",
      "time/total (s)                                                650.673\n",
      "Epoch                                                           0\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 1\n",
      "\n",
      " Cycle 0 1\n",
      "Added episode 50\n",
      "Replay buf 1050\n",
      "Soft update 800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 1\n",
      "Added episode 50\n",
      "Replay buf 1100\n",
      "Soft update 840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 1\n",
      "Added episode 50\n",
      "Replay buf 1150\n",
      "Soft update 880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 1\n",
      "Added episode 50\n",
      "Replay buf 1200\n",
      "Soft update 920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 1\n",
      "Added episode 50\n",
      "Replay buf 1250\n",
      "Soft update 960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 1\n",
      "Added episode 50\n",
      "Replay buf 1300\n",
      "Soft update 1000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 1\n",
      "Added episode 50\n",
      "Replay buf 1350\n",
      "Soft update 1040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 1\n",
      "Added episode 50\n",
      "Replay buf 1400\n",
      "Soft update 1080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 1\n",
      "Added episode 50\n",
      "Replay buf 1450\n",
      "Soft update 1120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 1\n",
      "Added episode 50\n",
      "Replay buf 1500\n",
      "Soft update 1160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 1\n",
      "Added episode 50\n",
      "Replay buf 1550\n",
      "Soft update 1200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 1\n",
      "Added episode 50\n",
      "Replay buf 1600\n",
      "Soft update 1240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 1\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 45\n",
      "Added episode 50\n",
      "Replay buf 1695\n",
      "Soft update 1280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 1\n",
      "Added episode 50\n",
      "Replay buf 1745\n",
      "Soft update 1320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 1\n",
      "Added episode 50\n",
      "Replay buf 1795\n",
      "Soft update 1360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 1\n",
      "Added episode 50\n",
      "Replay buf 1845\n",
      "Soft update 1400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 1\n",
      "Added episode 50\n",
      "Replay buf 1895\n",
      "Soft update 1440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 1\n",
      "Added episode 50\n",
      "Replay buf 1945\n",
      "Soft update 1480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 1\n",
      "Added episode 50\n",
      "Replay buf 1995\n",
      "Soft update 1520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 1\n",
      "Added episode 50\n",
      "Replay buf 2045\n",
      "Soft update 1560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:07:36.187146 EEST | [final-sideways-pixels-final-31] Epoch 1 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                 0.0539489\n",
      "trainer/Policy Loss                                             0.00161334\n",
      "trainer/Raw Policy Loss                                         0.00161334\n",
      "trainer/State estimation loss                                   0.0127814\n",
      "trainer/Preactivation Policy Loss                               0\n",
      "trainer/Q Predictions Mean                                     -1.11086\n",
      "trainer/Q Predictions Std                                       0.423451\n",
      "trainer/Q Predictions Max                                      -0.291926\n",
      "trainer/Q Predictions Min                                      -1.76952\n",
      "trainer/Q Targets Mean                                         -1.13677\n",
      "trainer/Q Targets Std                                           0.497392\n",
      "trainer/Q Targets Max                                          -0\n",
      "trainer/Q Targets Min                                          -1.60469\n",
      "trainer/Bellman Errors Mean                                     0.0539489\n",
      "trainer/Bellman Errors Std                                      0.137283\n",
      "trainer/Bellman Errors Max                                      1.4667\n",
      "trainer/Bellman Errors Min                                      8.82503e-08\n",
      "trainer/Policy Action Mean                                     -0.0477334\n",
      "trainer/Policy Action Std                                       0.330636\n",
      "trainer/Policy Action Max                                       0.672297\n",
      "trainer/Policy Action Min                                      -0.801793\n",
      "exploration/num steps total                                  2045\n",
      "exploration/num paths total                                    41\n",
      "exploration/path length Mean                                   49.7619\n",
      "exploration/path length Std                                     1.06479\n",
      "exploration/path length Max                                    50\n",
      "exploration/path length Min                                    45\n",
      "exploration/Rewards Mean                                       -0.999043\n",
      "exploration/Rewards Std                                         0.0309196\n",
      "exploration/Rewards Max                                        -0\n",
      "exploration/Rewards Min                                        -1\n",
      "exploration/Returns Mean                                      -49.7143\n",
      "exploration/Returns Std                                         1.27775\n",
      "exploration/Returns Max                                       -44\n",
      "exploration/Returns Min                                       -50\n",
      "exploration/Actions Mean                                       -0.0801164\n",
      "exploration/Actions Std                                         0.315465\n",
      "exploration/Actions Max                                         0.995428\n",
      "exploration/Actions Min                                        -0.993631\n",
      "exploration/Num Paths                                          21\n",
      "exploration/Average Returns                                   -49.7143\n",
      "exploration/env_infos/final/is_success Mean                     0.0476191\n",
      "exploration/env_infos/final/is_success Std                      0.212959\n",
      "exploration/env_infos/final/is_success Max                      1\n",
      "exploration/env_infos/final/is_success Min                      0\n",
      "exploration/env_infos/initial/is_success Mean                   0\n",
      "exploration/env_infos/initial/is_success Std                    0\n",
      "exploration/env_infos/initial/is_success Max                    0\n",
      "exploration/env_infos/initial/is_success Min                    0\n",
      "exploration/env_infos/is_success Mean                           0.000956938\n",
      "exploration/env_infos/is_success Std                            0.0309196\n",
      "exploration/env_infos/is_success Max                            1\n",
      "exploration/env_infos/is_success Min                            0\n",
      "evaluation/num steps total                                   1000\n",
      "evaluation/num paths total                                     20\n",
      "evaluation/path length Mean                                    50\n",
      "evaluation/path length Std                                      0\n",
      "evaluation/path length Max                                     50\n",
      "evaluation/path length Min                                     50\n",
      "evaluation/Rewards Mean                                        -1\n",
      "evaluation/Rewards Std                                          0\n",
      "evaluation/Rewards Max                                         -1\n",
      "evaluation/Rewards Min                                         -1\n",
      "evaluation/Returns Mean                                       -50\n",
      "evaluation/Returns Std                                          0\n",
      "evaluation/Returns Max                                        -50\n",
      "evaluation/Returns Min                                        -50\n",
      "evaluation/Actions Mean                                        -0.0626587\n",
      "evaluation/Actions Std                                          0.247573\n",
      "evaluation/Actions Max                                          0.464184\n",
      "evaluation/Actions Min                                         -0.660323\n",
      "evaluation/Num Paths                                           10\n",
      "evaluation/Average Returns                                    -50\n",
      "evaluation/env_infos/final/is_success Mean                      0\n",
      "evaluation/env_infos/final/is_success Std                       0\n",
      "evaluation/env_infos/final/is_success Max                       0\n",
      "evaluation/env_infos/final/is_success Min                       0\n",
      "evaluation/env_infos/initial/is_success Mean                    0\n",
      "evaluation/env_infos/initial/is_success Std                     0\n",
      "evaluation/env_infos/initial/is_success Max                     0\n",
      "evaluation/env_infos/initial/is_success Min                     0\n",
      "evaluation/env_infos/is_success Mean                            0\n",
      "evaluation/env_infos/is_success Std                             0\n",
      "evaluation/env_infos/is_success Max                             0\n",
      "evaluation/env_infos/is_success Min                             0\n",
      "evaluation/demonstrations/Rewards Mean                         -0.971264\n",
      "evaluation/demonstrations/Rewards Std                           0.167063\n",
      "evaluation/demonstrations/Rewards Max                          -0\n",
      "evaluation/demonstrations/Rewards Min                          -1\n",
      "evaluation/demonstrations/Returns Mean                        -33.8\n",
      "evaluation/demonstrations/Returns Std                           5.97997\n",
      "evaluation/demonstrations/Returns Max                         -28\n",
      "evaluation/demonstrations/Returns Min                         -47\n",
      "evaluation/demonstrations/Actions Mean                         -0.0799319\n",
      "evaluation/demonstrations/Actions Std                           0.291659\n",
      "evaluation/demonstrations/Actions Max                           0.522945\n",
      "evaluation/demonstrations/Actions Min                          -0.779109\n",
      "evaluation/demonstrations/Num Paths                            10\n",
      "evaluation/demonstrations/Average Returns                     -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean       1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std        0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min        1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean     0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min      0\n",
      "evaluation/demonstrations/env_infos/is_success Mean             0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std              0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max              1\n",
      "evaluation/demonstrations/env_infos/is_success Min              0\n",
      "time/data storing (s)                                           0.116302\n",
      "time/evaluation sampling (s)                                   14.7289\n",
      "time/exploration sampling (s)                                  31.2685\n",
      "time/logging (s)                                                0.00697731\n",
      "time/saving (s)                                                 0.0714478\n",
      "time/training (s)                                             197.652\n",
      "time/epoch (s)                                                243.845\n",
      "time/total (s)                                                894.521\n",
      "Epoch                                                           1\n",
      "-----------------------------------------------------------  --------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation sampling\n",
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 2\n",
      "\n",
      " Cycle 0 2\n",
      "Added episode 50\n",
      "Replay buf 2095\n",
      "Soft update 1600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 2\n",
      "Added episode 50\n",
      "Replay buf 2145\n",
      "Soft update 1640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 2\n",
      "Added episode 50\n",
      "Replay buf 2195\n",
      "Soft update 1680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 2\n",
      "Added episode 50\n",
      "Replay buf 2245\n",
      "Soft update 1720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 2\n",
      "Added episode 50\n",
      "Replay buf 2295\n",
      "Soft update 1760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 2\n",
      "Added episode 50\n",
      "Replay buf 2345\n",
      "Soft update 1800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 2\n",
      "Added episode 50\n",
      "Replay buf 2395\n",
      "Soft update 1840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 2\n",
      "Added episode 50\n",
      "Replay buf 2445\n",
      "Soft update 1880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 2\n",
      "Added episode 50\n",
      "Replay buf 2495\n",
      "Soft update 1920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 2\n",
      "Added episode 50\n",
      "Replay buf 2545\n",
      "Soft update 1960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 2\n",
      "Added episode 50\n",
      "Replay buf 2595\n",
      "Soft update 2000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 2\n",
      "Added episode 50\n",
      "Replay buf 2645\n",
      "Soft update 2040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 2\n",
      "Added episode 50\n",
      "Replay buf 2695\n",
      "Soft update 2080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 2\n",
      "Added episode 50\n",
      "Replay buf 2745\n",
      "Soft update 2120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 2\n",
      "Added episode 50\n",
      "Replay buf 2795\n",
      "Soft update 2160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 2\n",
      "Added episode 50\n",
      "Replay buf 2845\n",
      "Soft update 2200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 2\n",
      "Added episode 50\n",
      "Replay buf 2895\n",
      "Soft update 2240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 2\n",
      "Added episode 50\n",
      "Replay buf 2945\n",
      "Soft update 2280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 2\n",
      "Added episode 50\n",
      "Replay buf 2995\n",
      "Soft update 2320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 2\n",
      "Added episode 50\n",
      "Replay buf 3045\n",
      "Soft update 2360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:11:45.822095 EEST | [final-sideways-pixels-final-31] Epoch 2 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                 0.0563836\n",
      "trainer/Policy Loss                                             0.00180046\n",
      "trainer/Raw Policy Loss                                         0.00180046\n",
      "trainer/State estimation loss                                   0.00513522\n",
      "trainer/Preactivation Policy Loss                               0\n",
      "trainer/Q Predictions Mean                                     -1.66052\n",
      "trainer/Q Predictions Std                                       0.668254\n",
      "trainer/Q Predictions Max                                      -0.202653\n",
      "trainer/Q Predictions Min                                      -2.57362\n",
      "trainer/Q Targets Mean                                         -1.59721\n",
      "trainer/Q Targets Std                                           0.721552\n",
      "trainer/Q Targets Max                                          -0\n",
      "trainer/Q Targets Min                                          -2.48733\n",
      "trainer/Bellman Errors Mean                                     0.0563836\n",
      "trainer/Bellman Errors Std                                      0.161059\n",
      "trainer/Bellman Errors Max                                      1.84175\n",
      "trainer/Bellman Errors Min                                      1.11052e-08\n",
      "trainer/Policy Action Mean                                     -0.117849\n",
      "trainer/Policy Action Std                                       0.342889\n",
      "trainer/Policy Action Max                                       0.85397\n",
      "trainer/Policy Action Min                                      -0.990357\n",
      "exploration/num steps total                                  3045\n",
      "exploration/num paths total                                    61\n",
      "exploration/path length Mean                                   50\n",
      "exploration/path length Std                                     0\n",
      "exploration/path length Max                                    50\n",
      "exploration/path length Min                                    50\n",
      "exploration/Rewards Mean                                       -1\n",
      "exploration/Rewards Std                                         0\n",
      "exploration/Rewards Max                                        -1\n",
      "exploration/Rewards Min                                        -1\n",
      "exploration/Returns Mean                                      -50\n",
      "exploration/Returns Std                                         0\n",
      "exploration/Returns Max                                       -50\n",
      "exploration/Returns Min                                       -50\n",
      "exploration/Actions Mean                                       -0.200641\n",
      "exploration/Actions Std                                         0.462009\n",
      "exploration/Actions Max                                         1\n",
      "exploration/Actions Min                                        -1\n",
      "exploration/Num Paths                                          20\n",
      "exploration/Average Returns                                   -50\n",
      "exploration/env_infos/final/is_success Mean                     0\n",
      "exploration/env_infos/final/is_success Std                      0\n",
      "exploration/env_infos/final/is_success Max                      0\n",
      "exploration/env_infos/final/is_success Min                      0\n",
      "exploration/env_infos/initial/is_success Mean                   0\n",
      "exploration/env_infos/initial/is_success Std                    0\n",
      "exploration/env_infos/initial/is_success Max                    0\n",
      "exploration/env_infos/initial/is_success Min                    0\n",
      "exploration/env_infos/is_success Mean                           0\n",
      "exploration/env_infos/is_success Std                            0\n",
      "exploration/env_infos/is_success Max                            0\n",
      "exploration/env_infos/is_success Min                            0\n",
      "evaluation/num steps total                                   1534\n",
      "evaluation/num paths total                                     35\n",
      "evaluation/path length Mean                                    35.6\n",
      "evaluation/path length Std                                     13.4897\n",
      "evaluation/path length Max                                     50\n",
      "evaluation/path length Min                                     22\n",
      "evaluation/Rewards Mean                                        -0.985019\n",
      "evaluation/Rewards Std                                          0.121478\n",
      "evaluation/Rewards Max                                         -0\n",
      "evaluation/Rewards Min                                         -1\n",
      "evaluation/Returns Mean                                       -35.0667\n",
      "evaluation/Returns Std                                         13.9879\n",
      "evaluation/Returns Max                                        -21\n",
      "evaluation/Returns Min                                        -50\n",
      "evaluation/Actions Mean                                        -0.154523\n",
      "evaluation/Actions Std                                          0.288712\n",
      "evaluation/Actions Max                                          0.425856\n",
      "evaluation/Actions Min                                         -0.8005\n",
      "evaluation/Num Paths                                           15\n",
      "evaluation/Average Returns                                    -35.0667\n",
      "evaluation/env_infos/final/is_success Mean                      0.533333\n",
      "evaluation/env_infos/final/is_success Std                       0.498888\n",
      "evaluation/env_infos/final/is_success Max                       1\n",
      "evaluation/env_infos/final/is_success Min                       0\n",
      "evaluation/env_infos/initial/is_success Mean                    0\n",
      "evaluation/env_infos/initial/is_success Std                     0\n",
      "evaluation/env_infos/initial/is_success Max                     0\n",
      "evaluation/env_infos/initial/is_success Min                     0\n",
      "evaluation/env_infos/is_success Mean                            0.0149813\n",
      "evaluation/env_infos/is_success Std                             0.121478\n",
      "evaluation/env_infos/is_success Max                             1\n",
      "evaluation/env_infos/is_success Min                             0\n",
      "evaluation/demonstrations/Rewards Mean                         -0.971264\n",
      "evaluation/demonstrations/Rewards Std                           0.167063\n",
      "evaluation/demonstrations/Rewards Max                          -0\n",
      "evaluation/demonstrations/Rewards Min                          -1\n",
      "evaluation/demonstrations/Returns Mean                        -33.8\n",
      "evaluation/demonstrations/Returns Std                           5.97997\n",
      "evaluation/demonstrations/Returns Max                         -28\n",
      "evaluation/demonstrations/Returns Min                         -47\n",
      "evaluation/demonstrations/Actions Mean                         -0.0799319\n",
      "evaluation/demonstrations/Actions Std                           0.291659\n",
      "evaluation/demonstrations/Actions Max                           0.522945\n",
      "evaluation/demonstrations/Actions Min                          -0.779109\n",
      "evaluation/demonstrations/Num Paths                            10\n",
      "evaluation/demonstrations/Average Returns                     -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean       1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std        0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min        1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean     0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min      0\n",
      "evaluation/demonstrations/env_infos/is_success Mean             0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std              0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max              1\n",
      "evaluation/demonstrations/env_infos/is_success Min              0\n",
      "time/data storing (s)                                           0.110548\n",
      "time/evaluation sampling (s)                                   15.3531\n",
      "time/exploration sampling (s)                                  31.8991\n",
      "time/logging (s)                                                0.00751508\n",
      "time/saving (s)                                                 0.0726772\n",
      "time/training (s)                                             202.187\n",
      "time/epoch (s)                                                249.63\n",
      "time/total (s)                                               1144.16\n",
      "Epoch                                                           2\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 3\n",
      "\n",
      " Cycle 0 3\n",
      "Added episode 50\n",
      "Replay buf 3095\n",
      "Soft update 2400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 3\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 3154\n",
      "Soft update 2440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 3\n",
      "Added episode 50\n",
      "Replay buf 3204\n",
      "Soft update 2480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 3\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 19\n",
      "Added episode 50\n",
      "Replay buf 3273\n",
      "Soft update 2520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 3\n",
      "Added episode 50\n",
      "Replay buf 3323\n",
      "Soft update 2560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 3\n",
      "Added episode 50\n",
      "Replay buf 3373\n",
      "Soft update 2600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 3\n",
      "Added episode 50\n",
      "Replay buf 3423\n",
      "Soft update 2640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 3\n",
      "Added episode 50\n",
      "Replay buf 3473\n",
      "Soft update 2680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 3\n",
      "Added episode 50\n",
      "Replay buf 3523\n",
      "Soft update 2720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 3\n",
      "Added episode 50\n",
      "Replay buf 3573\n",
      "Soft update 2760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 3\n",
      "Added episode 50\n",
      "Replay buf 3623\n",
      "Soft update 2800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 3\n",
      "Added episode 50\n",
      "Replay buf 3673\n",
      "Soft update 2840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 3\n",
      "Added episode 50\n",
      "Replay buf 3723\n",
      "Soft update 2880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 3\n",
      "Added episode 50\n",
      "Replay buf 3773\n",
      "Soft update 2920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 3\n",
      "Added episode 50\n",
      "Replay buf 3823\n",
      "Soft update 2960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 3\n",
      "Added episode 50\n",
      "Replay buf 3873\n",
      "Soft update 3000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 3\n",
      "Added episode 50\n",
      "Replay buf 3923\n",
      "Soft update 3040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 3\n",
      "Added episode 50\n",
      "Replay buf 3973\n",
      "Soft update 3080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 3\n",
      "Added episode 50\n",
      "Replay buf 4023\n",
      "Soft update 3120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 3\n",
      "Added episode 50\n",
      "Replay buf 4073\n",
      "Soft update 3160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:15:54.974590 EEST | [final-sideways-pixels-final-31] Epoch 3 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                 0.0443117\n",
      "trainer/Policy Loss                                             0.0018961\n",
      "trainer/Raw Policy Loss                                         0.0018961\n",
      "trainer/State estimation loss                                   0.00587221\n",
      "trainer/Preactivation Policy Loss                               0\n",
      "trainer/Q Predictions Mean                                     -2.03406\n",
      "trainer/Q Predictions Std                                       1.05012\n",
      "trainer/Q Predictions Max                                      -0.115045\n",
      "trainer/Q Predictions Min                                      -3.46611\n",
      "trainer/Q Targets Mean                                         -2.04239\n",
      "trainer/Q Targets Std                                           1.06754\n",
      "trainer/Q Targets Max                                          -0\n",
      "trainer/Q Targets Min                                          -3.4935\n",
      "trainer/Bellman Errors Mean                                     0.0443117\n",
      "trainer/Bellman Errors Std                                      0.146406\n",
      "trainer/Bellman Errors Max                                      2.13208\n",
      "trainer/Bellman Errors Min                                      6.75357e-10\n",
      "trainer/Policy Action Mean                                     -0.250379\n",
      "trainer/Policy Action Std                                       0.640978\n",
      "trainer/Policy Action Max                                       0.999997\n",
      "trainer/Policy Action Min                                      -1\n",
      "exploration/num steps total                                  4073\n",
      "exploration/num paths total                                    83\n",
      "exploration/path length Mean                                   46.7273\n",
      "exploration/path length Std                                    10.4585\n",
      "exploration/path length Max                                    50\n",
      "exploration/path length Min                                     9\n",
      "exploration/Rewards Mean                                       -0.998054\n",
      "exploration/Rewards Std                                         0.0440652\n",
      "exploration/Rewards Max                                        -0\n",
      "exploration/Rewards Min                                        -1\n",
      "exploration/Returns Mean                                      -46.6364\n",
      "exploration/Returns Std                                        10.7431\n",
      "exploration/Returns Max                                        -8\n",
      "exploration/Returns Min                                       -50\n",
      "exploration/Actions Mean                                       -0.334787\n",
      "exploration/Actions Std                                         0.590688\n",
      "exploration/Actions Max                                         1\n",
      "exploration/Actions Min                                        -1\n",
      "exploration/Num Paths                                          22\n",
      "exploration/Average Returns                                   -46.6364\n",
      "exploration/env_infos/final/is_success Mean                     0.0909091\n",
      "exploration/env_infos/final/is_success Std                      0.28748\n",
      "exploration/env_infos/final/is_success Max                      1\n",
      "exploration/env_infos/final/is_success Min                      0\n",
      "exploration/env_infos/initial/is_success Mean                   0\n",
      "exploration/env_infos/initial/is_success Std                    0\n",
      "exploration/env_infos/initial/is_success Max                    0\n",
      "exploration/env_infos/initial/is_success Min                    0\n",
      "exploration/env_infos/is_success Mean                           0.00194553\n",
      "exploration/env_infos/is_success Std                            0.0440652\n",
      "exploration/env_infos/is_success Max                            1\n",
      "exploration/env_infos/is_success Min                            0\n",
      "evaluation/num steps total                                   2048\n",
      "evaluation/num paths total                                     46\n",
      "evaluation/path length Mean                                    46.7273\n",
      "evaluation/path length Std                                     10.3493\n",
      "evaluation/path length Max                                     50\n",
      "evaluation/path length Min                                     14\n",
      "evaluation/Rewards Mean                                        -0.998054\n",
      "evaluation/Rewards Std                                          0.0440652\n",
      "evaluation/Rewards Max                                         -0\n",
      "evaluation/Rewards Min                                         -1\n",
      "evaluation/Returns Mean                                       -46.6364\n",
      "evaluation/Returns Std                                         10.6368\n",
      "evaluation/Returns Max                                        -13\n",
      "evaluation/Returns Min                                        -50\n",
      "evaluation/Actions Mean                                        -0.364842\n",
      "evaluation/Actions Std                                          0.536702\n",
      "evaluation/Actions Max                                          0.999248\n",
      "evaluation/Actions Min                                         -0.99999\n",
      "evaluation/Num Paths                                           11\n",
      "evaluation/Average Returns                                    -46.6364\n",
      "evaluation/env_infos/final/is_success Mean                      0.0909091\n",
      "evaluation/env_infos/final/is_success Std                       0.28748\n",
      "evaluation/env_infos/final/is_success Max                       1\n",
      "evaluation/env_infos/final/is_success Min                       0\n",
      "evaluation/env_infos/initial/is_success Mean                    0\n",
      "evaluation/env_infos/initial/is_success Std                     0\n",
      "evaluation/env_infos/initial/is_success Max                     0\n",
      "evaluation/env_infos/initial/is_success Min                     0\n",
      "evaluation/env_infos/is_success Mean                            0.00194553\n",
      "evaluation/env_infos/is_success Std                             0.0440652\n",
      "evaluation/env_infos/is_success Max                             1\n",
      "evaluation/env_infos/is_success Min                             0\n",
      "evaluation/demonstrations/Rewards Mean                         -0.971264\n",
      "evaluation/demonstrations/Rewards Std                           0.167063\n",
      "evaluation/demonstrations/Rewards Max                          -0\n",
      "evaluation/demonstrations/Rewards Min                          -1\n",
      "evaluation/demonstrations/Returns Mean                        -33.8\n",
      "evaluation/demonstrations/Returns Std                           5.97997\n",
      "evaluation/demonstrations/Returns Max                         -28\n",
      "evaluation/demonstrations/Returns Min                         -47\n",
      "evaluation/demonstrations/Actions Mean                         -0.0799319\n",
      "evaluation/demonstrations/Actions Std                           0.291659\n",
      "evaluation/demonstrations/Actions Max                           0.522945\n",
      "evaluation/demonstrations/Actions Min                          -0.779109\n",
      "evaluation/demonstrations/Num Paths                            10\n",
      "evaluation/demonstrations/Average Returns                     -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean       1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std        0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min        1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean     0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min      0\n",
      "evaluation/demonstrations/env_infos/is_success Mean             0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std              0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max              1\n",
      "evaluation/demonstrations/env_infos/is_success Min              0\n",
      "time/data storing (s)                                           0.110294\n",
      "time/evaluation sampling (s)                                   16.8252\n",
      "time/exploration sampling (s)                                  32.6125\n",
      "time/logging (s)                                                0.00699235\n",
      "time/saving (s)                                                 0.072771\n",
      "time/training (s)                                             199.519\n",
      "time/epoch (s)                                                249.147\n",
      "time/total (s)                                               1393.31\n",
      "Epoch                                                           3\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 4\n",
      "\n",
      " Cycle 0 4\n",
      "Added episode 50\n",
      "Replay buf 4123\n",
      "Soft update 3200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 4\n",
      "Added episode 50\n",
      "Replay buf 4173\n",
      "Soft update 3240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 4\n",
      "Added episode 50\n",
      "Replay buf 4223\n",
      "Soft update 3280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 4\n",
      "Added episode 50\n",
      "Replay buf 4273\n",
      "Soft update 3320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 4\n",
      "Added episode 50\n",
      "Replay buf 4323\n",
      "Soft update 3360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 4\n",
      "Added episode 50\n",
      "Replay buf 4373\n",
      "Soft update 3400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 4\n",
      "Added episode 50\n",
      "Replay buf 4423\n",
      "Soft update 3440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 4\n",
      "Added episode 50\n",
      "Replay buf 4473\n",
      "Soft update 3480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 4\n",
      "Added episode 50\n",
      "Replay buf 4523\n",
      "Soft update 3520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 4\n",
      "Added episode 50\n",
      "Replay buf 4573\n",
      "Soft update 3560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 4\n",
      "Added episode 50\n",
      "Replay buf 4623\n",
      "Soft update 3600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 4\n",
      "Added episode 50\n",
      "Replay buf 4673\n",
      "Soft update 3640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 4\n",
      "Added episode 50\n",
      "Replay buf 4723\n",
      "Soft update 3680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 4\n",
      "Added episode 50\n",
      "Replay buf 4773\n",
      "Soft update 3720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 4\n",
      "Added episode 50\n",
      "Replay buf 4823\n",
      "Soft update 3760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 4\n",
      "Added episode 50\n",
      "Replay buf 4873\n",
      "Soft update 3800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 4\n",
      "Added episode 50\n",
      "Replay buf 4923\n",
      "Soft update 3840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 4\n",
      "Added episode 50\n",
      "Replay buf 4973\n",
      "Soft update 3880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 4\n",
      "Added episode 50\n",
      "Replay buf 5023\n",
      "Soft update 3920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 4\n",
      "Added episode 50\n",
      "Replay buf 5073\n",
      "Soft update 3960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:20:00.213763 EEST | [final-sideways-pixels-final-31] Epoch 4 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                 0.0521963\n",
      "trainer/Policy Loss                                             0.002263\n",
      "trainer/Raw Policy Loss                                         0.002263\n",
      "trainer/State estimation loss                                   0.00462601\n",
      "trainer/Preactivation Policy Loss                               0\n",
      "trainer/Q Predictions Mean                                     -2.50327\n",
      "trainer/Q Predictions Std                                       1.37934\n",
      "trainer/Q Predictions Max                                      -0.0386508\n",
      "trainer/Q Predictions Min                                      -4.50085\n",
      "trainer/Q Targets Mean                                         -2.39501\n",
      "trainer/Q Targets Std                                           1.40587\n",
      "trainer/Q Targets Max                                          -0\n",
      "trainer/Q Targets Min                                          -4.34268\n",
      "trainer/Bellman Errors Mean                                     0.0521963\n",
      "trainer/Bellman Errors Std                                      0.139578\n",
      "trainer/Bellman Errors Max                                      1.59824\n",
      "trainer/Bellman Errors Min                                      2.95495e-09\n",
      "trainer/Policy Action Mean                                     -0.250219\n",
      "trainer/Policy Action Std                                       0.727679\n",
      "trainer/Policy Action Max                                       1\n",
      "trainer/Policy Action Min                                      -1\n",
      "exploration/num steps total                                  5073\n",
      "exploration/num paths total                                   103\n",
      "exploration/path length Mean                                   50\n",
      "exploration/path length Std                                     0\n",
      "exploration/path length Max                                    50\n",
      "exploration/path length Min                                    50\n",
      "exploration/Rewards Mean                                       -1\n",
      "exploration/Rewards Std                                         0\n",
      "exploration/Rewards Max                                        -1\n",
      "exploration/Rewards Min                                        -1\n",
      "exploration/Returns Mean                                      -50\n",
      "exploration/Returns Std                                         0\n",
      "exploration/Returns Max                                       -50\n",
      "exploration/Returns Min                                       -50\n",
      "exploration/Actions Mean                                       -0.314816\n",
      "exploration/Actions Std                                         0.596054\n",
      "exploration/Actions Max                                         1\n",
      "exploration/Actions Min                                        -1\n",
      "exploration/Num Paths                                          20\n",
      "exploration/Average Returns                                   -50\n",
      "exploration/env_infos/final/is_success Mean                     0\n",
      "exploration/env_infos/final/is_success Std                      0\n",
      "exploration/env_infos/final/is_success Max                      0\n",
      "exploration/env_infos/final/is_success Min                      0\n",
      "exploration/env_infos/initial/is_success Mean                   0\n",
      "exploration/env_infos/initial/is_success Std                    0\n",
      "exploration/env_infos/initial/is_success Max                    0\n",
      "exploration/env_infos/initial/is_success Min                    0\n",
      "exploration/env_infos/is_success Mean                           0\n",
      "exploration/env_infos/is_success Std                            0\n",
      "exploration/env_infos/is_success Max                            0\n",
      "exploration/env_infos/is_success Min                            0\n",
      "evaluation/num steps total                                   2548\n",
      "evaluation/num paths total                                     56\n",
      "evaluation/path length Mean                                    50\n",
      "evaluation/path length Std                                      0\n",
      "evaluation/path length Max                                     50\n",
      "evaluation/path length Min                                     50\n",
      "evaluation/Rewards Mean                                        -1\n",
      "evaluation/Rewards Std                                          0\n",
      "evaluation/Rewards Max                                         -1\n",
      "evaluation/Rewards Min                                         -1\n",
      "evaluation/Returns Mean                                       -50\n",
      "evaluation/Returns Std                                          0\n",
      "evaluation/Returns Max                                        -50\n",
      "evaluation/Returns Min                                        -50\n",
      "evaluation/Actions Mean                                        -0.276243\n",
      "evaluation/Actions Std                                          0.570516\n",
      "evaluation/Actions Max                                          0.999982\n",
      "evaluation/Actions Min                                         -0.999999\n",
      "evaluation/Num Paths                                           10\n",
      "evaluation/Average Returns                                    -50\n",
      "evaluation/env_infos/final/is_success Mean                      0\n",
      "evaluation/env_infos/final/is_success Std                       0\n",
      "evaluation/env_infos/final/is_success Max                       0\n",
      "evaluation/env_infos/final/is_success Min                       0\n",
      "evaluation/env_infos/initial/is_success Mean                    0\n",
      "evaluation/env_infos/initial/is_success Std                     0\n",
      "evaluation/env_infos/initial/is_success Max                     0\n",
      "evaluation/env_infos/initial/is_success Min                     0\n",
      "evaluation/env_infos/is_success Mean                            0\n",
      "evaluation/env_infos/is_success Std                             0\n",
      "evaluation/env_infos/is_success Max                             0\n",
      "evaluation/env_infos/is_success Min                             0\n",
      "evaluation/demonstrations/Rewards Mean                         -0.971264\n",
      "evaluation/demonstrations/Rewards Std                           0.167063\n",
      "evaluation/demonstrations/Rewards Max                          -0\n",
      "evaluation/demonstrations/Rewards Min                          -1\n",
      "evaluation/demonstrations/Returns Mean                        -33.8\n",
      "evaluation/demonstrations/Returns Std                           5.97997\n",
      "evaluation/demonstrations/Returns Max                         -28\n",
      "evaluation/demonstrations/Returns Min                         -47\n",
      "evaluation/demonstrations/Actions Mean                         -0.0799319\n",
      "evaluation/demonstrations/Actions Std                           0.291659\n",
      "evaluation/demonstrations/Actions Max                           0.522945\n",
      "evaluation/demonstrations/Actions Min                          -0.779109\n",
      "evaluation/demonstrations/Num Paths                            10\n",
      "evaluation/demonstrations/Average Returns                     -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean       1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std        0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min        1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean     0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min      0\n",
      "evaluation/demonstrations/env_infos/is_success Mean             0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std              0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max              1\n",
      "evaluation/demonstrations/env_infos/is_success Min              0\n",
      "time/data storing (s)                                           0.106966\n",
      "time/evaluation sampling (s)                                   15.5685\n",
      "time/exploration sampling (s)                                  31.9552\n",
      "time/logging (s)                                                0.00701456\n",
      "time/saving (s)                                                 0.0713857\n",
      "time/training (s)                                             197.525\n",
      "time/epoch (s)                                                245.234\n",
      "time/total (s)                                               1638.54\n",
      "Epoch                                                           4\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 5\n",
      "\n",
      " Cycle 0 5\n",
      "Added episode 50\n",
      "Replay buf 5123\n",
      "Soft update 4000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 5\n",
      "Added episode 50\n",
      "Replay buf 5173\n",
      "Soft update 4040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 5\n",
      "Added episode 50\n",
      "Replay buf 5223\n",
      "Soft update 4080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 5\n",
      "Added episode 50\n",
      "Replay buf 5273\n",
      "Soft update 4120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 5\n",
      "Added episode 50\n",
      "Replay buf 5323\n",
      "Soft update 4160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 5\n",
      "Added episode 50\n",
      "Replay buf 5373\n",
      "Soft update 4200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 5\n",
      "Added episode 50\n",
      "Replay buf 5423\n",
      "Soft update 4240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 5\n",
      "Added episode 50\n",
      "Replay buf 5473\n",
      "Soft update 4280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 5\n",
      "Added episode 50\n",
      "Replay buf 5523\n",
      "Soft update 4320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 5\n",
      "Added episode 50\n",
      "Replay buf 5573\n",
      "Soft update 4360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 5\n",
      "Added episode 50\n",
      "Replay buf 5623\n",
      "Soft update 4400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 5\n",
      "Added episode 50\n",
      "Replay buf 5673\n",
      "Soft update 4440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 5\n",
      "Added episode 50\n",
      "Replay buf 5723\n",
      "Soft update 4480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 5\n",
      "Added episode 50\n",
      "Replay buf 5773\n",
      "Soft update 4520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 5\n",
      "Added episode 50\n",
      "Replay buf 5823\n",
      "Soft update 4560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 5\n",
      "Added episode 50\n",
      "Replay buf 5873\n",
      "Soft update 4600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 5\n",
      "Added episode 50\n",
      "Replay buf 5923\n",
      "Soft update 4640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 5\n",
      "Added episode 50\n",
      "Replay buf 5973\n",
      "Soft update 4680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 5\n",
      "Added episode 50\n",
      "Replay buf 6023\n",
      "Soft update 4720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 5\n",
      "Added episode 50\n",
      "Replay buf 6073\n",
      "Soft update 4760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:24:05.323667 EEST | [final-sideways-pixels-final-31] Epoch 5 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  -------------\n",
      "trainer/QF Loss                                                 0.0399699\n",
      "trainer/Policy Loss                                             0.00252395\n",
      "trainer/Raw Policy Loss                                         0.00252395\n",
      "trainer/State estimation loss                                   0.00482125\n",
      "trainer/Preactivation Policy Loss                               0\n",
      "trainer/Q Predictions Mean                                     -2.62491\n",
      "trainer/Q Predictions Std                                       1.73668\n",
      "trainer/Q Predictions Max                                       0.114612\n",
      "trainer/Q Predictions Min                                      -5.15817\n",
      "trainer/Q Targets Mean                                         -2.67644\n",
      "trainer/Q Targets Std                                           1.72537\n",
      "trainer/Q Targets Max                                           0.0145663\n",
      "trainer/Q Targets Min                                          -5.2074\n",
      "trainer/Bellman Errors Mean                                     0.0399699\n",
      "trainer/Bellman Errors Std                                      0.109684\n",
      "trainer/Bellman Errors Max                                      1.06135\n",
      "trainer/Bellman Errors Min                                      7.4902e-09\n",
      "trainer/Policy Action Mean                                     -0.408403\n",
      "trainer/Policy Action Std                                       0.633613\n",
      "trainer/Policy Action Max                                       0.999754\n",
      "trainer/Policy Action Min                                      -0.999999\n",
      "exploration/num steps total                                  6073\n",
      "exploration/num paths total                                   123\n",
      "exploration/path length Mean                                   50\n",
      "exploration/path length Std                                     0\n",
      "exploration/path length Max                                    50\n",
      "exploration/path length Min                                    50\n",
      "exploration/Rewards Mean                                       -1\n",
      "exploration/Rewards Std                                         0\n",
      "exploration/Rewards Max                                        -1\n",
      "exploration/Rewards Min                                        -1\n",
      "exploration/Returns Mean                                      -50\n",
      "exploration/Returns Std                                         0\n",
      "exploration/Returns Max                                       -50\n",
      "exploration/Returns Min                                       -50\n",
      "exploration/Actions Mean                                       -0.315002\n",
      "exploration/Actions Std                                         0.563523\n",
      "exploration/Actions Max                                         1\n",
      "exploration/Actions Min                                        -1\n",
      "exploration/Num Paths                                          20\n",
      "exploration/Average Returns                                   -50\n",
      "exploration/env_infos/final/is_success Mean                     0\n",
      "exploration/env_infos/final/is_success Std                      0\n",
      "exploration/env_infos/final/is_success Max                      0\n",
      "exploration/env_infos/final/is_success Min                      0\n",
      "exploration/env_infos/initial/is_success Mean                   0\n",
      "exploration/env_infos/initial/is_success Std                    0\n",
      "exploration/env_infos/initial/is_success Max                    0\n",
      "exploration/env_infos/initial/is_success Min                    0\n",
      "exploration/env_infos/is_success Mean                           0\n",
      "exploration/env_infos/is_success Std                            0\n",
      "exploration/env_infos/is_success Max                            0\n",
      "exploration/env_infos/is_success Min                            0\n",
      "evaluation/num steps total                                   3048\n",
      "evaluation/num paths total                                     66\n",
      "evaluation/path length Mean                                    50\n",
      "evaluation/path length Std                                      0\n",
      "evaluation/path length Max                                     50\n",
      "evaluation/path length Min                                     50\n",
      "evaluation/Rewards Mean                                        -1\n",
      "evaluation/Rewards Std                                          0\n",
      "evaluation/Rewards Max                                         -1\n",
      "evaluation/Rewards Min                                         -1\n",
      "evaluation/Returns Mean                                       -50\n",
      "evaluation/Returns Std                                          0\n",
      "evaluation/Returns Max                                        -50\n",
      "evaluation/Returns Min                                        -50\n",
      "evaluation/Actions Mean                                        -0.346783\n",
      "evaluation/Actions Std                                          0.511109\n",
      "evaluation/Actions Max                                          0.984718\n",
      "evaluation/Actions Min                                         -1\n",
      "evaluation/Num Paths                                           10\n",
      "evaluation/Average Returns                                    -50\n",
      "evaluation/env_infos/final/is_success Mean                      0\n",
      "evaluation/env_infos/final/is_success Std                       0\n",
      "evaluation/env_infos/final/is_success Max                       0\n",
      "evaluation/env_infos/final/is_success Min                       0\n",
      "evaluation/env_infos/initial/is_success Mean                    0\n",
      "evaluation/env_infos/initial/is_success Std                     0\n",
      "evaluation/env_infos/initial/is_success Max                     0\n",
      "evaluation/env_infos/initial/is_success Min                     0\n",
      "evaluation/env_infos/is_success Mean                            0\n",
      "evaluation/env_infos/is_success Std                             0\n",
      "evaluation/env_infos/is_success Max                             0\n",
      "evaluation/env_infos/is_success Min                             0\n",
      "evaluation/demonstrations/Rewards Mean                         -0.971264\n",
      "evaluation/demonstrations/Rewards Std                           0.167063\n",
      "evaluation/demonstrations/Rewards Max                          -0\n",
      "evaluation/demonstrations/Rewards Min                          -1\n",
      "evaluation/demonstrations/Returns Mean                        -33.8\n",
      "evaluation/demonstrations/Returns Std                           5.97997\n",
      "evaluation/demonstrations/Returns Max                         -28\n",
      "evaluation/demonstrations/Returns Min                         -47\n",
      "evaluation/demonstrations/Actions Mean                         -0.0799319\n",
      "evaluation/demonstrations/Actions Std                           0.291659\n",
      "evaluation/demonstrations/Actions Max                           0.522945\n",
      "evaluation/demonstrations/Actions Min                          -0.779109\n",
      "evaluation/demonstrations/Num Paths                            10\n",
      "evaluation/demonstrations/Average Returns                     -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean       1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std        0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min        1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean     0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min      0\n",
      "evaluation/demonstrations/env_infos/is_success Mean             0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std              0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max              1\n",
      "evaluation/demonstrations/env_infos/is_success Min              0\n",
      "time/data storing (s)                                           0.107095\n",
      "time/evaluation sampling (s)                                   16.0496\n",
      "time/exploration sampling (s)                                  30.8735\n",
      "time/logging (s)                                                0.00695676\n",
      "time/saving (s)                                                 0.07147\n",
      "time/training (s)                                             197.996\n",
      "time/epoch (s)                                                245.105\n",
      "time/total (s)                                               1883.65\n",
      "Epoch                                                           5\n",
      "-----------------------------------------------------------  -------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 6\n",
      "\n",
      " Cycle 0 6\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 19\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 6156\n",
      "Soft update 4800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 6\n",
      "Added episode 50\n",
      "Replay buf 6206\n",
      "Soft update 4840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 6\n",
      "Added episode 50\n",
      "Replay buf 6256\n",
      "Soft update 4880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 6\n",
      "Added episode 50\n",
      "Replay buf 6306\n",
      "Soft update 4920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 6\n",
      "Added episode 50\n",
      "Replay buf 6356\n",
      "Soft update 4960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 6\n",
      "Added episode 50\n",
      "Replay buf 6406\n",
      "Soft update 5000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 6\n",
      "Added episode 50\n",
      "Replay buf 6456\n",
      "Soft update 5040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 6\n",
      "Added episode 50\n",
      "Replay buf 6506\n",
      "Soft update 5080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 6\n",
      "Added episode 50\n",
      "Replay buf 6556\n",
      "Soft update 5120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 6\n",
      "Added episode 50\n",
      "Replay buf 6606\n",
      "Soft update 5160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 6\n",
      "Added episode 50\n",
      "Replay buf 6656\n",
      "Soft update 5200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 6\n",
      "Added episode 50\n",
      "Replay buf 6706\n",
      "Soft update 5240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 6\n",
      "Added episode 50\n",
      "Replay buf 6756\n",
      "Soft update 5280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 6\n",
      "Added episode 50\n",
      "Replay buf 6806\n",
      "Soft update 5320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 6\n",
      "Added episode 50\n",
      "Replay buf 6856\n",
      "Soft update 5360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 6\n",
      "Added episode 50\n",
      "Replay buf 6906\n",
      "Soft update 5400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 6\n",
      "Added episode 50\n",
      "Replay buf 6956\n",
      "Soft update 5440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 6\n",
      "Added episode 50\n",
      "Replay buf 7006\n",
      "Soft update 5480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 6\n",
      "Added episode 50\n",
      "Replay buf 7056\n",
      "Soft update 5520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 6\n",
      "Added episode 50\n",
      "Replay buf 7106\n",
      "Soft update 5560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:28:12.134037 EEST | [final-sideways-pixels-final-31] Epoch 6 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                 0.0362941\n",
      "trainer/Policy Loss                                             0.00297691\n",
      "trainer/Raw Policy Loss                                         0.00297691\n",
      "trainer/State estimation loss                                   0.00606028\n",
      "trainer/Preactivation Policy Loss                               0\n",
      "trainer/Q Predictions Mean                                     -3.05194\n",
      "trainer/Q Predictions Std                                       2.0903\n",
      "trainer/Q Predictions Max                                       0.135373\n",
      "trainer/Q Predictions Min                                      -6.01886\n",
      "trainer/Q Targets Mean                                         -3.08444\n",
      "trainer/Q Targets Std                                           2.08838\n",
      "trainer/Q Targets Max                                           0.0755271\n",
      "trainer/Q Targets Min                                          -6.08156\n",
      "trainer/Bellman Errors Mean                                     0.0362941\n",
      "trainer/Bellman Errors Std                                      0.0967357\n",
      "trainer/Bellman Errors Max                                      0.965624\n",
      "trainer/Bellman Errors Min                                      2.22489e-10\n",
      "trainer/Policy Action Mean                                     -0.206806\n",
      "trainer/Policy Action Std                                       0.63207\n",
      "trainer/Policy Action Max                                       0.999991\n",
      "trainer/Policy Action Min                                      -0.999999\n",
      "exploration/num steps total                                  7106\n",
      "exploration/num paths total                                   145\n",
      "exploration/path length Mean                                   46.9545\n",
      "exploration/path length Std                                     9.66003\n",
      "exploration/path length Max                                    50\n",
      "exploration/path length Min                                    14\n",
      "exploration/Rewards Mean                                       -0.998064\n",
      "exploration/Rewards Std                                         0.0439586\n",
      "exploration/Rewards Max                                        -0\n",
      "exploration/Rewards Min                                        -1\n",
      "exploration/Returns Mean                                      -46.8636\n",
      "exploration/Returns Std                                         9.94665\n",
      "exploration/Returns Max                                       -13\n",
      "exploration/Returns Min                                       -50\n",
      "exploration/Actions Mean                                       -0.227573\n",
      "exploration/Actions Std                                         0.556332\n",
      "exploration/Actions Max                                         1\n",
      "exploration/Actions Min                                        -1\n",
      "exploration/Num Paths                                          22\n",
      "exploration/Average Returns                                   -46.8636\n",
      "exploration/env_infos/final/is_success Mean                     0.0909091\n",
      "exploration/env_infos/final/is_success Std                      0.28748\n",
      "exploration/env_infos/final/is_success Max                      1\n",
      "exploration/env_infos/final/is_success Min                      0\n",
      "exploration/env_infos/initial/is_success Mean                   0\n",
      "exploration/env_infos/initial/is_success Std                    0\n",
      "exploration/env_infos/initial/is_success Max                    0\n",
      "exploration/env_infos/initial/is_success Min                    0\n",
      "exploration/env_infos/is_success Mean                           0.00193611\n",
      "exploration/env_infos/is_success Std                            0.0439586\n",
      "exploration/env_infos/is_success Max                            1\n",
      "exploration/env_infos/is_success Min                            0\n",
      "evaluation/num steps total                                   3548\n",
      "evaluation/num paths total                                     76\n",
      "evaluation/path length Mean                                    50\n",
      "evaluation/path length Std                                      0\n",
      "evaluation/path length Max                                     50\n",
      "evaluation/path length Min                                     50\n",
      "evaluation/Rewards Mean                                        -1\n",
      "evaluation/Rewards Std                                          0\n",
      "evaluation/Rewards Max                                         -1\n",
      "evaluation/Rewards Min                                         -1\n",
      "evaluation/Returns Mean                                       -50\n",
      "evaluation/Returns Std                                          0\n",
      "evaluation/Returns Max                                        -50\n",
      "evaluation/Returns Min                                        -50\n",
      "evaluation/Actions Mean                                        -0.364306\n",
      "evaluation/Actions Std                                          0.559525\n",
      "evaluation/Actions Max                                          0.997802\n",
      "evaluation/Actions Min                                         -0.999976\n",
      "evaluation/Num Paths                                           10\n",
      "evaluation/Average Returns                                    -50\n",
      "evaluation/env_infos/final/is_success Mean                      0\n",
      "evaluation/env_infos/final/is_success Std                       0\n",
      "evaluation/env_infos/final/is_success Max                       0\n",
      "evaluation/env_infos/final/is_success Min                       0\n",
      "evaluation/env_infos/initial/is_success Mean                    0\n",
      "evaluation/env_infos/initial/is_success Std                     0\n",
      "evaluation/env_infos/initial/is_success Max                     0\n",
      "evaluation/env_infos/initial/is_success Min                     0\n",
      "evaluation/env_infos/is_success Mean                            0\n",
      "evaluation/env_infos/is_success Std                             0\n",
      "evaluation/env_infos/is_success Max                             0\n",
      "evaluation/env_infos/is_success Min                             0\n",
      "evaluation/demonstrations/Rewards Mean                         -0.971264\n",
      "evaluation/demonstrations/Rewards Std                           0.167063\n",
      "evaluation/demonstrations/Rewards Max                          -0\n",
      "evaluation/demonstrations/Rewards Min                          -1\n",
      "evaluation/demonstrations/Returns Mean                        -33.8\n",
      "evaluation/demonstrations/Returns Std                           5.97997\n",
      "evaluation/demonstrations/Returns Max                         -28\n",
      "evaluation/demonstrations/Returns Min                         -47\n",
      "evaluation/demonstrations/Actions Mean                         -0.0799319\n",
      "evaluation/demonstrations/Actions Std                           0.291659\n",
      "evaluation/demonstrations/Actions Max                           0.522945\n",
      "evaluation/demonstrations/Actions Min                          -0.779109\n",
      "evaluation/demonstrations/Num Paths                            10\n",
      "evaluation/demonstrations/Average Returns                     -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean       1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std        0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min        1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean     0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min      0\n",
      "evaluation/demonstrations/env_infos/is_success Mean             0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std              0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max              1\n",
      "evaluation/demonstrations/env_infos/is_success Min              0\n",
      "time/data storing (s)                                           0.110517\n",
      "time/evaluation sampling (s)                                   16.1982\n",
      "time/exploration sampling (s)                                  32.0965\n",
      "time/logging (s)                                                0.00705069\n",
      "time/saving (s)                                                 0.0717598\n",
      "time/training (s)                                             198.321\n",
      "time/epoch (s)                                                246.805\n",
      "time/total (s)                                               2130.46\n",
      "Epoch                                                           6\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 7\n",
      "\n",
      " Cycle 0 7\n",
      "Added episode 50\n",
      "Replay buf 7156\n",
      "Soft update 5600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 7\n",
      "Added episode 50\n",
      "Replay buf 7206\n",
      "Soft update 5640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 7\n",
      "Added episode 50\n",
      "Replay buf 7256\n",
      "Soft update 5680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 7\n",
      "Added episode 50\n",
      "Replay buf 7306\n",
      "Soft update 5720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 7\n",
      "Added episode 50\n",
      "Replay buf 7356\n",
      "Soft update 5760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 7\n",
      "Added episode 50\n",
      "Replay buf 7406\n",
      "Soft update 5800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 7\n",
      "Added episode 50\n",
      "Replay buf 7456\n",
      "Soft update 5840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 7\n",
      "Added episode 50\n",
      "Replay buf 7506\n",
      "Soft update 5880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 7\n",
      "Added episode 50\n",
      "Replay buf 7556\n",
      "Soft update 5920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 7\n",
      "Added episode 50\n",
      "Replay buf 7606\n",
      "Soft update 5960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 7\n",
      "Added episode 50\n",
      "Replay buf 7656\n",
      "Soft update 6000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 7\n",
      "Added episode 50\n",
      "Replay buf 7706\n",
      "Soft update 6040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 7\n",
      "Added episode 50\n",
      "Replay buf 7756\n",
      "Soft update 6080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 7\n",
      "Added episode 50\n",
      "Replay buf 7806\n",
      "Soft update 6120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 7\n",
      "Added episode 50\n",
      "Replay buf 7856\n",
      "Soft update 6160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 7\n",
      "Added episode 50\n",
      "Replay buf 7906\n",
      "Soft update 6200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 7\n",
      "Added episode 50\n",
      "Replay buf 7956\n",
      "Soft update 6240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 7\n",
      "Added episode 50\n",
      "Replay buf 8006\n",
      "Soft update 6280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 7\n",
      "Added episode 50\n",
      "Replay buf 8056\n",
      "Soft update 6320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 7\n",
      "Added episode 50\n",
      "Replay buf 8106\n",
      "Soft update 6360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:32:19.130746 EEST | [final-sideways-pixels-final-31] Epoch 7 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                 0.0728397\n",
      "trainer/Policy Loss                                           nan\n",
      "trainer/Raw Policy Loss                                       nan\n",
      "trainer/State estimation loss                                   0.00467734\n",
      "trainer/Preactivation Policy Loss                             nan\n",
      "trainer/Q Predictions Mean                                     -3.45582\n",
      "trainer/Q Predictions Std                                       2.33434\n",
      "trainer/Q Predictions Max                                       0.0778145\n",
      "trainer/Q Predictions Min                                      -6.97667\n",
      "trainer/Q Targets Mean                                         -3.47341\n",
      "trainer/Q Targets Std                                           2.37757\n",
      "trainer/Q Targets Max                                           0.0655396\n",
      "trainer/Q Targets Min                                          -7.00484\n",
      "trainer/Bellman Errors Mean                                     0.0728397\n",
      "trainer/Bellman Errors Std                                      0.232794\n",
      "trainer/Bellman Errors Max                                      3.42567\n",
      "trainer/Bellman Errors Min                                      1.01688e-09\n",
      "trainer/Policy Action Mean                                     -0.217506\n",
      "trainer/Policy Action Std                                       0.662486\n",
      "trainer/Policy Action Max                                       1\n",
      "trainer/Policy Action Min                                      -1\n",
      "exploration/num steps total                                  8106\n",
      "exploration/num paths total                                   165\n",
      "exploration/path length Mean                                   50\n",
      "exploration/path length Std                                     0\n",
      "exploration/path length Max                                    50\n",
      "exploration/path length Min                                    50\n",
      "exploration/Rewards Mean                                       -1\n",
      "exploration/Rewards Std                                         0\n",
      "exploration/Rewards Max                                        -1\n",
      "exploration/Rewards Min                                        -1\n",
      "exploration/Returns Mean                                      -50\n",
      "exploration/Returns Std                                         0\n",
      "exploration/Returns Max                                       -50\n",
      "exploration/Returns Min                                       -50\n",
      "exploration/Actions Mean                                       -0.247906\n",
      "exploration/Actions Std                                         0.615322\n",
      "exploration/Actions Max                                         1\n",
      "exploration/Actions Min                                        -1\n",
      "exploration/Num Paths                                          20\n",
      "exploration/Average Returns                                   -50\n",
      "exploration/env_infos/final/is_success Mean                     0\n",
      "exploration/env_infos/final/is_success Std                      0\n",
      "exploration/env_infos/final/is_success Max                      0\n",
      "exploration/env_infos/final/is_success Min                      0\n",
      "exploration/env_infos/initial/is_success Mean                   0\n",
      "exploration/env_infos/initial/is_success Std                    0\n",
      "exploration/env_infos/initial/is_success Max                    0\n",
      "exploration/env_infos/initial/is_success Min                    0\n",
      "exploration/env_infos/is_success Mean                           0\n",
      "exploration/env_infos/is_success Std                            0\n",
      "exploration/env_infos/is_success Max                            0\n",
      "exploration/env_infos/is_success Min                            0\n",
      "evaluation/num steps total                                   4048\n",
      "evaluation/num paths total                                     86\n",
      "evaluation/path length Mean                                    50\n",
      "evaluation/path length Std                                      0\n",
      "evaluation/path length Max                                     50\n",
      "evaluation/path length Min                                     50\n",
      "evaluation/Rewards Mean                                        -1\n",
      "evaluation/Rewards Std                                          0\n",
      "evaluation/Rewards Max                                         -1\n",
      "evaluation/Rewards Min                                         -1\n",
      "evaluation/Returns Mean                                       -50\n",
      "evaluation/Returns Std                                          0\n",
      "evaluation/Returns Max                                        -50\n",
      "evaluation/Returns Min                                        -50\n",
      "evaluation/Actions Mean                                        -0.353415\n",
      "evaluation/Actions Std                                          0.491009\n",
      "evaluation/Actions Max                                          0.996168\n",
      "evaluation/Actions Min                                         -1\n",
      "evaluation/Num Paths                                           10\n",
      "evaluation/Average Returns                                    -50\n",
      "evaluation/env_infos/final/is_success Mean                      0\n",
      "evaluation/env_infos/final/is_success Std                       0\n",
      "evaluation/env_infos/final/is_success Max                       0\n",
      "evaluation/env_infos/final/is_success Min                       0\n",
      "evaluation/env_infos/initial/is_success Mean                    0\n",
      "evaluation/env_infos/initial/is_success Std                     0\n",
      "evaluation/env_infos/initial/is_success Max                     0\n",
      "evaluation/env_infos/initial/is_success Min                     0\n",
      "evaluation/env_infos/is_success Mean                            0\n",
      "evaluation/env_infos/is_success Std                             0\n",
      "evaluation/env_infos/is_success Max                             0\n",
      "evaluation/env_infos/is_success Min                             0\n",
      "evaluation/demonstrations/Rewards Mean                         -0.971264\n",
      "evaluation/demonstrations/Rewards Std                           0.167063\n",
      "evaluation/demonstrations/Rewards Max                          -0\n",
      "evaluation/demonstrations/Rewards Min                          -1\n",
      "evaluation/demonstrations/Returns Mean                        -33.8\n",
      "evaluation/demonstrations/Returns Std                           5.97997\n",
      "evaluation/demonstrations/Returns Max                         -28\n",
      "evaluation/demonstrations/Returns Min                         -47\n",
      "evaluation/demonstrations/Actions Mean                         -0.0799319\n",
      "evaluation/demonstrations/Actions Std                           0.291659\n",
      "evaluation/demonstrations/Actions Max                           0.522945\n",
      "evaluation/demonstrations/Actions Min                          -0.779109\n",
      "evaluation/demonstrations/Num Paths                            10\n",
      "evaluation/demonstrations/Average Returns                     -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean       1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std        0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min        1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean     0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min      0\n",
      "evaluation/demonstrations/env_infos/is_success Mean             0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std              0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max              1\n",
      "evaluation/demonstrations/env_infos/is_success Min              0\n",
      "time/data storing (s)                                           0.10683\n",
      "time/evaluation sampling (s)                                   16.2626\n",
      "time/exploration sampling (s)                                  32.3972\n",
      "time/logging (s)                                                0.0069149\n",
      "time/saving (s)                                                 0.0721777\n",
      "time/training (s)                                             198.146\n",
      "time/epoch (s)                                                246.992\n",
      "time/total (s)                                               2377.46\n",
      "Epoch                                                           7\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 8\n",
      "\n",
      " Cycle 0 8\n",
      "Added episode 50\n",
      "Replay buf 8156\n",
      "Soft update 6400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 8\n",
      "Added episode 50\n",
      "Replay buf 8206\n",
      "Soft update 6440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 8\n",
      "Added episode 50\n",
      "Replay buf 8256\n",
      "Soft update 6480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 8\n",
      "Added episode 50\n",
      "Replay buf 8306\n",
      "Soft update 6520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 8\n",
      "Added episode 50\n",
      "Replay buf 8356\n",
      "Soft update 6560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 8\n",
      "Added episode 50\n",
      "Replay buf 8406\n",
      "Soft update 6600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 8\n",
      "Added episode 50\n",
      "Replay buf 8456\n",
      "Soft update 6640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 8\n",
      "Added episode 50\n",
      "Replay buf 8506\n",
      "Soft update 6680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 8\n",
      "Added episode 50\n",
      "Replay buf 8556\n",
      "Soft update 6720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 8\n",
      "Added episode 50\n",
      "Replay buf 8606\n",
      "Soft update 6760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 8\n",
      "Added episode 50\n",
      "Replay buf 8656\n",
      "Soft update 6800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 8\n",
      "Added episode 50\n",
      "Replay buf 8706\n",
      "Soft update 6840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 8\n",
      "Added episode 50\n",
      "Replay buf 8756\n",
      "Soft update 6880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 8\n",
      "Added episode 50\n",
      "Replay buf 8806\n",
      "Soft update 6920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 8\n",
      "Added episode 50\n",
      "Replay buf 8856\n",
      "Soft update 6960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 8\n",
      "Added episode 50\n",
      "Replay buf 8906\n",
      "Soft update 7000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 8\n",
      "Added episode 50\n",
      "Replay buf 8956\n",
      "Soft update 7040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 8\n",
      "Added episode 50\n",
      "Replay buf 9006\n",
      "Soft update 7080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 8\n",
      "Added episode 50\n",
      "Replay buf 9056\n",
      "Soft update 7120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 8\n",
      "Added episode 50\n",
      "Replay buf 9106\n",
      "Soft update 7160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:36:24.542527 EEST | [final-sideways-pixels-final-31] Epoch 8 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                 0.0603213\n",
      "trainer/Policy Loss                                             0.0037298\n",
      "trainer/Raw Policy Loss                                         0.0037298\n",
      "trainer/State estimation loss                                   0.00389147\n",
      "trainer/Preactivation Policy Loss                               0\n",
      "trainer/Q Predictions Mean                                     -3.89302\n",
      "trainer/Q Predictions Std                                       2.6761\n",
      "trainer/Q Predictions Max                                       0.21726\n",
      "trainer/Q Predictions Min                                      -7.97705\n",
      "trainer/Q Targets Mean                                         -3.89647\n",
      "trainer/Q Targets Std                                           2.68839\n",
      "trainer/Q Targets Max                                           0.157687\n",
      "trainer/Q Targets Min                                          -8.02379\n",
      "trainer/Bellman Errors Mean                                     0.0603213\n",
      "trainer/Bellman Errors Std                                      0.141573\n",
      "trainer/Bellman Errors Max                                      1.3833\n",
      "trainer/Bellman Errors Min                                      1.79537e-08\n",
      "trainer/Policy Action Mean                                     -0.158317\n",
      "trainer/Policy Action Std                                       0.687378\n",
      "trainer/Policy Action Max                                       1\n",
      "trainer/Policy Action Min                                      -1\n",
      "exploration/num steps total                                  9106\n",
      "exploration/num paths total                                   185\n",
      "exploration/path length Mean                                   50\n",
      "exploration/path length Std                                     0\n",
      "exploration/path length Max                                    50\n",
      "exploration/path length Min                                    50\n",
      "exploration/Rewards Mean                                       -1\n",
      "exploration/Rewards Std                                         0\n",
      "exploration/Rewards Max                                        -1\n",
      "exploration/Rewards Min                                        -1\n",
      "exploration/Returns Mean                                      -50\n",
      "exploration/Returns Std                                         0\n",
      "exploration/Returns Max                                       -50\n",
      "exploration/Returns Min                                       -50\n",
      "exploration/Actions Mean                                       -0.185348\n",
      "exploration/Actions Std                                         0.568221\n",
      "exploration/Actions Max                                         1\n",
      "exploration/Actions Min                                        -1\n",
      "exploration/Num Paths                                          20\n",
      "exploration/Average Returns                                   -50\n",
      "exploration/env_infos/final/is_success Mean                     0\n",
      "exploration/env_infos/final/is_success Std                      0\n",
      "exploration/env_infos/final/is_success Max                      0\n",
      "exploration/env_infos/final/is_success Min                      0\n",
      "exploration/env_infos/initial/is_success Mean                   0\n",
      "exploration/env_infos/initial/is_success Std                    0\n",
      "exploration/env_infos/initial/is_success Max                    0\n",
      "exploration/env_infos/initial/is_success Min                    0\n",
      "exploration/env_infos/is_success Mean                           0\n",
      "exploration/env_infos/is_success Std                            0\n",
      "exploration/env_infos/is_success Max                            0\n",
      "exploration/env_infos/is_success Min                            0\n",
      "evaluation/num steps total                                   4548\n",
      "evaluation/num paths total                                     96\n",
      "evaluation/path length Mean                                    50\n",
      "evaluation/path length Std                                      0\n",
      "evaluation/path length Max                                     50\n",
      "evaluation/path length Min                                     50\n",
      "evaluation/Rewards Mean                                        -1\n",
      "evaluation/Rewards Std                                          0\n",
      "evaluation/Rewards Max                                         -1\n",
      "evaluation/Rewards Min                                         -1\n",
      "evaluation/Returns Mean                                       -50\n",
      "evaluation/Returns Std                                          0\n",
      "evaluation/Returns Max                                        -50\n",
      "evaluation/Returns Min                                        -50\n",
      "evaluation/Actions Mean                                        -0.371229\n",
      "evaluation/Actions Std                                          0.59714\n",
      "evaluation/Actions Max                                          0.999531\n",
      "evaluation/Actions Min                                         -1\n",
      "evaluation/Num Paths                                           10\n",
      "evaluation/Average Returns                                    -50\n",
      "evaluation/env_infos/final/is_success Mean                      0\n",
      "evaluation/env_infos/final/is_success Std                       0\n",
      "evaluation/env_infos/final/is_success Max                       0\n",
      "evaluation/env_infos/final/is_success Min                       0\n",
      "evaluation/env_infos/initial/is_success Mean                    0\n",
      "evaluation/env_infos/initial/is_success Std                     0\n",
      "evaluation/env_infos/initial/is_success Max                     0\n",
      "evaluation/env_infos/initial/is_success Min                     0\n",
      "evaluation/env_infos/is_success Mean                            0\n",
      "evaluation/env_infos/is_success Std                             0\n",
      "evaluation/env_infos/is_success Max                             0\n",
      "evaluation/env_infos/is_success Min                             0\n",
      "evaluation/demonstrations/Rewards Mean                         -0.971264\n",
      "evaluation/demonstrations/Rewards Std                           0.167063\n",
      "evaluation/demonstrations/Rewards Max                          -0\n",
      "evaluation/demonstrations/Rewards Min                          -1\n",
      "evaluation/demonstrations/Returns Mean                        -33.8\n",
      "evaluation/demonstrations/Returns Std                           5.97997\n",
      "evaluation/demonstrations/Returns Max                         -28\n",
      "evaluation/demonstrations/Returns Min                         -47\n",
      "evaluation/demonstrations/Actions Mean                         -0.0799319\n",
      "evaluation/demonstrations/Actions Std                           0.291659\n",
      "evaluation/demonstrations/Actions Max                           0.522945\n",
      "evaluation/demonstrations/Actions Min                          -0.779109\n",
      "evaluation/demonstrations/Num Paths                            10\n",
      "evaluation/demonstrations/Average Returns                     -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean       1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std        0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min        1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean     0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min      0\n",
      "evaluation/demonstrations/env_infos/is_success Mean             0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std              0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max              1\n",
      "evaluation/demonstrations/env_infos/is_success Min              0\n",
      "time/data storing (s)                                           0.104233\n",
      "time/evaluation sampling (s)                                   15.1678\n",
      "time/exploration sampling (s)                                  31.5537\n",
      "time/logging (s)                                                0.00684392\n",
      "time/saving (s)                                                 0.0715856\n",
      "time/training (s)                                             198.503\n",
      "time/epoch (s)                                                245.407\n",
      "time/total (s)                                               2622.87\n",
      "Epoch                                                           8\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 9\n",
      "\n",
      " Cycle 0 9\n",
      "Added episode 50\n",
      "Replay buf 9156\n",
      "Soft update 7200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 9\n",
      "Added episode 50\n",
      "Replay buf 9206\n",
      "Soft update 7240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 9\n",
      "Added episode 50\n",
      "Replay buf 9256\n",
      "Soft update 7280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 9\n",
      "Added episode 50\n",
      "Replay buf 9306\n",
      "Soft update 7320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 9\n",
      "Added episode 50\n",
      "Replay buf 9356\n",
      "Soft update 7360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 9\n",
      "Added episode 50\n",
      "Replay buf 9406\n",
      "Soft update 7400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 9\n",
      "Added episode 50\n",
      "Replay buf 9456\n",
      "Soft update 7440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 9\n",
      "Added episode 50\n",
      "Replay buf 9506\n",
      "Soft update 7480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 9\n",
      "Added episode 50\n",
      "Replay buf 9556\n",
      "Soft update 7520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 9\n",
      "Added episode 50\n",
      "Replay buf 9606\n",
      "Soft update 7560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 9\n",
      "Added episode 50\n",
      "Replay buf 9656\n",
      "Soft update 7600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 9\n",
      "Added episode 50\n",
      "Replay buf 9706\n",
      "Soft update 7640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 9\n",
      "Added episode 50\n",
      "Replay buf 9756\n",
      "Soft update 7680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 9\n",
      "Added episode 50\n",
      "Replay buf 9806\n",
      "Soft update 7720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 9\n",
      "Added episode 50\n",
      "Replay buf 9856\n",
      "Soft update 7760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 9\n",
      "Added episode 50\n",
      "Replay buf 9906\n",
      "Soft update 7800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 9\n",
      "Added episode 50\n",
      "Replay buf 9956\n",
      "Soft update 7840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 9\n",
      "Added episode 50\n",
      "Replay buf 10006\n",
      "Soft update 7880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 9\n",
      "Added episode 50\n",
      "Replay buf 10056\n",
      "Soft update 7920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 9\n",
      "Added episode 50\n",
      "Replay buf 10106\n",
      "Soft update 7960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:40:29.619053 EEST | [final-sideways-pixels-final-31] Epoch 9 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.0586973\n",
      "trainer/Policy Loss                                              0.00419773\n",
      "trainer/Raw Policy Loss                                          0.00419773\n",
      "trainer/State estimation loss                                    0.0047118\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -4.22892\n",
      "trainer/Q Predictions Std                                        2.98537\n",
      "trainer/Q Predictions Max                                        0.169413\n",
      "trainer/Q Predictions Min                                       -8.81241\n",
      "trainer/Q Targets Mean                                          -4.2658\n",
      "trainer/Q Targets Std                                            2.99572\n",
      "trainer/Q Targets Max                                            0.188266\n",
      "trainer/Q Targets Min                                           -8.71047\n",
      "trainer/Bellman Errors Mean                                      0.0586973\n",
      "trainer/Bellman Errors Std                                       0.148109\n",
      "trainer/Bellman Errors Max                                       1.83963\n",
      "trainer/Bellman Errors Min                                       2.27374e-11\n",
      "trainer/Policy Action Mean                                      -0.111892\n",
      "trainer/Policy Action Std                                        0.698007\n",
      "trainer/Policy Action Max                                        0.999998\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  10106\n",
      "exploration/num paths total                                    205\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.220453\n",
      "exploration/Actions Std                                          0.637689\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                    5048\n",
      "evaluation/num paths total                                     106\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.26381\n",
      "evaluation/Actions Std                                           0.704955\n",
      "evaluation/Actions Max                                           0.997744\n",
      "evaluation/Actions Min                                          -0.99998\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.105451\n",
      "time/evaluation sampling (s)                                    15.8225\n",
      "time/exploration sampling (s)                                   31.7023\n",
      "time/logging (s)                                                 0.00684561\n",
      "time/saving (s)                                                  0.0708636\n",
      "time/training (s)                                              197.364\n",
      "time/epoch (s)                                                 245.072\n",
      "time/total (s)                                                2867.94\n",
      "Epoch                                                            9\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 10\n",
      "\n",
      " Cycle 0 10\n",
      "Added episode 50\n",
      "Replay buf 10156\n",
      "Soft update 8000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 10\n",
      "Added episode 50\n",
      "Replay buf 10206\n",
      "Soft update 8040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 10\n",
      "Added episode 50\n",
      "Replay buf 10256\n",
      "Soft update 8080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 10\n",
      "Added episode 50\n",
      "Replay buf 10306\n",
      "Soft update 8120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 10\n",
      "Added episode 50\n",
      "Replay buf 10356\n",
      "Soft update 8160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 10\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 10418\n",
      "Soft update 8200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 10\n",
      "Added episode 50\n",
      "Replay buf 10468\n",
      "Soft update 8240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 10\n",
      "Added episode 50\n",
      "Replay buf 10518\n",
      "Soft update 8280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 10\n",
      "Added episode 50\n",
      "Replay buf 10568\n",
      "Soft update 8320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 10\n",
      "Added episode 50\n",
      "Replay buf 10618\n",
      "Soft update 8360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 10\n",
      "Added episode 50\n",
      "Replay buf 10668\n",
      "Soft update 8400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 10\n",
      "Added episode 50\n",
      "Replay buf 10718\n",
      "Soft update 8440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 10\n",
      "Added episode 50\n",
      "Replay buf 10768\n",
      "Soft update 8480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 10\n",
      "Added episode 50\n",
      "Replay buf 10818\n",
      "Soft update 8520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 10\n",
      "Added episode 50\n",
      "Replay buf 10868\n",
      "Soft update 8560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 10\n",
      "Added episode 50\n",
      "Replay buf 10918\n",
      "Soft update 8600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 10\n",
      "Added episode 50\n",
      "Replay buf 10968\n",
      "Soft update 8640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 10\n",
      "Added episode 50\n",
      "Replay buf 11018\n",
      "Soft update 8680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 10\n",
      "Added episode 50\n",
      "Replay buf 11068\n",
      "Soft update 8720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 10\n",
      "Added episode 50\n",
      "Replay buf 11118\n",
      "Soft update 8760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:44:36.267474 EEST | [final-sideways-pixels-final-31] Epoch 10 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.0759661\n",
      "trainer/Policy Loss                                              0.00444521\n",
      "trainer/Raw Policy Loss                                          0.00444521\n",
      "trainer/State estimation loss                                    0.00523605\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -4.57035\n",
      "trainer/Q Predictions Std                                        3.28627\n",
      "trainer/Q Predictions Max                                        0.371858\n",
      "trainer/Q Predictions Min                                      -10.053\n",
      "trainer/Q Targets Mean                                          -4.51511\n",
      "trainer/Q Targets Std                                            3.32179\n",
      "trainer/Q Targets Max                                            0.407853\n",
      "trainer/Q Targets Min                                           -9.86887\n",
      "trainer/Bellman Errors Mean                                      0.0759661\n",
      "trainer/Bellman Errors Std                                       0.193356\n",
      "trainer/Bellman Errors Max                                       2.36717\n",
      "trainer/Bellman Errors Min                                       4.01087e-08\n",
      "trainer/Policy Action Mean                                      -0.105196\n",
      "trainer/Policy Action Std                                        0.691173\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  11118\n",
      "exploration/num paths total                                    226\n",
      "exploration/path length Mean                                    48.1905\n",
      "exploration/path length Std                                      8.09244\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     12\n",
      "exploration/Rewards Mean                                        -0.999012\n",
      "exploration/Rewards Std                                          0.0314192\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -48.1429\n",
      "exploration/Returns Std                                          8.3054\n",
      "exploration/Returns Max                                        -11\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.241975\n",
      "exploration/Actions Std                                          0.702847\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           21\n",
      "exploration/Average Returns                                    -48.1429\n",
      "exploration/env_infos/final/is_success Mean                      0.0476191\n",
      "exploration/env_infos/final/is_success Std                       0.212959\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.000988142\n",
      "exploration/env_infos/is_success Std                             0.0314192\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                    5561\n",
      "evaluation/num paths total                                     117\n",
      "evaluation/path length Mean                                     46.6364\n",
      "evaluation/path length Std                                      10.6368\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      13\n",
      "evaluation/Rewards Mean                                         -0.998051\n",
      "evaluation/Rewards Std                                           0.044108\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -46.5455\n",
      "evaluation/Returns Std                                          10.9242\n",
      "evaluation/Returns Max                                         -12\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.125442\n",
      "evaluation/Actions Std                                           0.722465\n",
      "evaluation/Actions Max                                           0.999985\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            11\n",
      "evaluation/Average Returns                                     -46.5455\n",
      "evaluation/env_infos/final/is_success Mean                       0.0909091\n",
      "evaluation/env_infos/final/is_success Std                        0.28748\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00194932\n",
      "evaluation/env_infos/is_success Std                              0.044108\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.109387\n",
      "time/evaluation sampling (s)                                    15.9138\n",
      "time/exploration sampling (s)                                   32.2856\n",
      "time/logging (s)                                                 0.00692873\n",
      "time/saving (s)                                                  0.0707368\n",
      "time/training (s)                                              198.257\n",
      "time/epoch (s)                                                 246.644\n",
      "time/total (s)                                                3114.59\n",
      "Epoch                                                           10\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 11\n",
      "\n",
      " Cycle 0 11\n",
      "Added episode 50\n",
      "Replay buf 11168\n",
      "Soft update 8800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 11\n",
      "Added episode 50\n",
      "Replay buf 11218\n",
      "Soft update 8840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 11\n",
      "Added episode 50\n",
      "Replay buf 11268\n",
      "Soft update 8880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 11\n",
      "Added episode 50\n",
      "Replay buf 11318\n",
      "Soft update 8920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 11\n",
      "Added episode 50\n",
      "Replay buf 11368\n",
      "Soft update 8960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 11\n",
      "Added episode 50\n",
      "Replay buf 11418\n",
      "Soft update 9000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 11\n",
      "Added episode 50\n",
      "Replay buf 11468\n",
      "Soft update 9040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 11\n",
      "Added episode 50\n",
      "Replay buf 11518\n",
      "Soft update 9080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 11\n",
      "Added episode 50\n",
      "Replay buf 11568\n",
      "Soft update 9120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 11\n",
      "Added episode 50\n",
      "Replay buf 11618\n",
      "Soft update 9160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 11\n",
      "Added episode 50\n",
      "Replay buf 11668\n",
      "Soft update 9200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 11\n",
      "Added episode 50\n",
      "Replay buf 11718\n",
      "Soft update 9240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 11\n",
      "Added episode 50\n",
      "Replay buf 11768\n",
      "Soft update 9280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 11\n",
      "Added episode 50\n",
      "Replay buf 11818\n",
      "Soft update 9320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 11\n",
      "Added episode 50\n",
      "Replay buf 11868\n",
      "Soft update 9360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 11\n",
      "Added episode 50\n",
      "Replay buf 11918\n",
      "Soft update 9400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 11\n",
      "Added episode 50\n",
      "Replay buf 11968\n",
      "Soft update 9440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 11\n",
      "Added episode 50\n",
      "Replay buf 12018\n",
      "Soft update 9480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 11\n",
      "Added episode 50\n",
      "Replay buf 12068\n",
      "Soft update 9520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 11\n",
      "Added episode 50\n",
      "Replay buf 12118\n",
      "Soft update 9560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:48:43.005748 EEST | [final-sideways-pixels-final-31] Epoch 11 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.0761928\n",
      "trainer/Policy Loss                                              0.00459197\n",
      "trainer/Raw Policy Loss                                          0.00459197\n",
      "trainer/State estimation loss                                    0.00398837\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -4.73073\n",
      "trainer/Q Predictions Std                                        3.58843\n",
      "trainer/Q Predictions Max                                        0.298014\n",
      "trainer/Q Predictions Min                                      -11.0776\n",
      "trainer/Q Targets Mean                                          -4.71655\n",
      "trainer/Q Targets Std                                            3.57934\n",
      "trainer/Q Targets Max                                            0.338787\n",
      "trainer/Q Targets Min                                          -10.9295\n",
      "trainer/Bellman Errors Mean                                      0.0761928\n",
      "trainer/Bellman Errors Std                                       0.189093\n",
      "trainer/Bellman Errors Max                                       3.55587\n",
      "trainer/Bellman Errors Min                                       1.29878e-08\n",
      "trainer/Policy Action Mean                                      -0.190971\n",
      "trainer/Policy Action Std                                        0.719162\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  12118\n",
      "exploration/num paths total                                    246\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.257144\n",
      "exploration/Actions Std                                          0.650293\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                    6061\n",
      "evaluation/num paths total                                     127\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.302349\n",
      "evaluation/Actions Std                                           0.636609\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.106741\n",
      "time/evaluation sampling (s)                                    16.3182\n",
      "time/exploration sampling (s)                                   32.9666\n",
      "time/logging (s)                                                 0.00676011\n",
      "time/saving (s)                                                  0.0725243\n",
      "time/training (s)                                              197.262\n",
      "time/epoch (s)                                                 246.733\n",
      "time/total (s)                                                3361.33\n",
      "Epoch                                                           11\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 12\n",
      "\n",
      " Cycle 0 12\n",
      "Added episode 50\n",
      "Replay buf 12168\n",
      "Soft update 9600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 12\n",
      "Added episode 50\n",
      "Replay buf 12218\n",
      "Soft update 9640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 12\n",
      "Added episode 50\n",
      "Replay buf 12268\n",
      "Soft update 9680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 12\n",
      "Added episode 50\n",
      "Replay buf 12318\n",
      "Soft update 9720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 12\n",
      "Added episode 50\n",
      "Replay buf 12368\n",
      "Soft update 9760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 12\n",
      "Added episode 50\n",
      "Replay buf 12418\n",
      "Soft update 9800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 12\n",
      "Added episode 50\n",
      "Replay buf 12468\n",
      "Soft update 9840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 12\n",
      "Added episode 50\n",
      "Replay buf 12518\n",
      "Soft update 9880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 12\n",
      "Added episode 50\n",
      "Replay buf 12568\n",
      "Soft update 9920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 12\n",
      "Added episode 50\n",
      "Replay buf 12618\n",
      "Soft update 9960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 12\n",
      "Added episode 50\n",
      "Replay buf 12668\n",
      "Soft update 10000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 12\n",
      "Added episode 50\n",
      "Replay buf 12718\n",
      "Soft update 10040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 12\n",
      "Added episode 50\n",
      "Replay buf 12768\n",
      "Soft update 10080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 12\n",
      "Added episode 50\n",
      "Replay buf 12818\n",
      "Soft update 10120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 12\n",
      "Added episode 50\n",
      "Replay buf 12868\n",
      "Soft update 10160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 12\n",
      "Added episode 50\n",
      "Replay buf 12918\n",
      "Soft update 10200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 12\n",
      "Added episode 50\n",
      "Replay buf 12968\n",
      "Soft update 10240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 12\n",
      "Added episode 50\n",
      "Replay buf 13018\n",
      "Soft update 10280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 12\n",
      "Added episode 50\n",
      "Replay buf 13068\n",
      "Soft update 10320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 12\n",
      "Added episode 50\n",
      "Replay buf 13118\n",
      "Soft update 10360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:52:49.281343 EEST | [final-sideways-pixels-final-31] Epoch 12 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.114651\n",
      "trainer/Policy Loss                                              0.00467509\n",
      "trainer/Raw Policy Loss                                          0.00467509\n",
      "trainer/State estimation loss                                    0.00363417\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -4.90247\n",
      "trainer/Q Predictions Std                                        3.78793\n",
      "trainer/Q Predictions Max                                        0.532924\n",
      "trainer/Q Predictions Min                                      -12.5934\n",
      "trainer/Q Targets Mean                                          -4.96664\n",
      "trainer/Q Targets Std                                            3.81514\n",
      "trainer/Q Targets Max                                            0.460959\n",
      "trainer/Q Targets Min                                          -12.3347\n",
      "trainer/Bellman Errors Mean                                      0.114651\n",
      "trainer/Bellman Errors Std                                       0.35619\n",
      "trainer/Bellman Errors Max                                       7.41146\n",
      "trainer/Bellman Errors Min                                       1.78891e-07\n",
      "trainer/Policy Action Mean                                      -0.199495\n",
      "trainer/Policy Action Std                                        0.713429\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  13118\n",
      "exploration/num paths total                                    266\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.276616\n",
      "exploration/Actions Std                                          0.626708\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                    6561\n",
      "evaluation/num paths total                                     137\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.339081\n",
      "evaluation/Actions Std                                           0.679662\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.107359\n",
      "time/evaluation sampling (s)                                    14.8702\n",
      "time/exploration sampling (s)                                   33.6461\n",
      "time/logging (s)                                                 0.00695154\n",
      "time/saving (s)                                                  0.070585\n",
      "time/training (s)                                              197.57\n",
      "time/epoch (s)                                                 246.271\n",
      "time/total (s)                                                3607.6\n",
      "Epoch                                                           12\n",
      "-----------------------------------------------------------  ---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation sampling\n",
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 13\n",
      "\n",
      " Cycle 0 13\n",
      "Added episode 50\n",
      "Replay buf 13168\n",
      "Soft update 10400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 13\n",
      "Added episode 50\n",
      "Replay buf 13218\n",
      "Soft update 10440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 13\n",
      "Added episode 50\n",
      "Replay buf 13268\n",
      "Soft update 10480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 13\n",
      "Added episode 50\n",
      "Replay buf 13318\n",
      "Soft update 10520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 13\n",
      "Added episode 50\n",
      "Replay buf 13368\n",
      "Soft update 10560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 13\n",
      "Added episode 50\n",
      "Replay buf 13418\n",
      "Soft update 10600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 13\n",
      "Added episode 50\n",
      "Replay buf 13468\n",
      "Soft update 10640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 13\n",
      "Added episode 50\n",
      "Replay buf 13518\n",
      "Soft update 10680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 13\n",
      "Added episode 50\n",
      "Replay buf 13568\n",
      "Soft update 10720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 13\n",
      "Added episode 50\n",
      "Replay buf 13618\n",
      "Soft update 10760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 13\n",
      "Added episode 50\n",
      "Replay buf 13668\n",
      "Soft update 10800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 13\n",
      "Added episode 50\n",
      "Replay buf 13718\n",
      "Soft update 10840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 13\n",
      "Added episode 50\n",
      "Replay buf 13768\n",
      "Soft update 10880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 13\n",
      "Added episode 50\n",
      "Replay buf 13818\n",
      "Soft update 10920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 13\n",
      "Added episode 50\n",
      "Replay buf 13868\n",
      "Soft update 10960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 13\n",
      "Added episode 50\n",
      "Replay buf 13918\n",
      "Soft update 11000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 13\n",
      "Added episode 50\n",
      "Replay buf 13968\n",
      "Soft update 11040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 13\n",
      "Added episode 50\n",
      "Replay buf 14018\n",
      "Soft update 11080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 13\n",
      "Added episode 50\n",
      "Replay buf 14068\n",
      "Soft update 11120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 13\n",
      "Added episode 50\n",
      "Replay buf 14118\n",
      "Soft update 11160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 09:56:59.344599 EEST | [final-sideways-pixels-final-31] Epoch 13 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.111015\n",
      "trainer/Policy Loss                                              0.00480347\n",
      "trainer/Raw Policy Loss                                          0.00480347\n",
      "trainer/State estimation loss                                    0.00392476\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -5.00448\n",
      "trainer/Q Predictions Std                                        4.06995\n",
      "trainer/Q Predictions Max                                        0.556628\n",
      "trainer/Q Predictions Min                                      -12.0685\n",
      "trainer/Q Targets Mean                                          -5.04714\n",
      "trainer/Q Targets Std                                            4.08189\n",
      "trainer/Q Targets Max                                            0.388377\n",
      "trainer/Q Targets Min                                          -12.2806\n",
      "trainer/Bellman Errors Mean                                      0.111015\n",
      "trainer/Bellman Errors Std                                       0.317382\n",
      "trainer/Bellman Errors Max                                       7.45654\n",
      "trainer/Bellman Errors Min                                       2.92735e-08\n",
      "trainer/Policy Action Mean                                      -0.207055\n",
      "trainer/Policy Action Std                                        0.698495\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  14118\n",
      "exploration/num paths total                                    286\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.210698\n",
      "exploration/Actions Std                                          0.623414\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                    7061\n",
      "evaluation/num paths total                                     147\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.298742\n",
      "evaluation/Actions Std                                           0.661305\n",
      "evaluation/Actions Max                                           0.99999\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.10553\n",
      "time/evaluation sampling (s)                                    18.5242\n",
      "time/exploration sampling (s)                                   33.5568\n",
      "time/logging (s)                                                 0.00685931\n",
      "time/saving (s)                                                  0.0712012\n",
      "time/training (s)                                              197.793\n",
      "time/epoch (s)                                                 250.058\n",
      "time/total (s)                                                3857.67\n",
      "Epoch                                                           13\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 14\n",
      "\n",
      " Cycle 0 14\n",
      "Added episode 50\n",
      "Replay buf 14168\n",
      "Soft update 11200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 14\n",
      "Added episode 50\n",
      "Replay buf 14218\n",
      "Soft update 11240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 14\n",
      "Added episode 50\n",
      "Replay buf 14268\n",
      "Soft update 11280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 14\n",
      "Added episode 50\n",
      "Replay buf 14318\n",
      "Soft update 11320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 14\n",
      "Added episode 50\n",
      "Replay buf 14368\n",
      "Soft update 11360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 14\n",
      "Added episode 50\n",
      "Replay buf 14418\n",
      "Soft update 11400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 14\n",
      "Added episode 50\n",
      "Replay buf 14468\n",
      "Soft update 11440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 14\n",
      "Added episode 50\n",
      "Replay buf 14518\n",
      "Soft update 11480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 14\n",
      "Added episode 50\n",
      "Replay buf 14568\n",
      "Soft update 11520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 14\n",
      "Added episode 50\n",
      "Replay buf 14618\n",
      "Soft update 11560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 14\n",
      "Added episode 50\n",
      "Replay buf 14668\n",
      "Soft update 11600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 14\n",
      "Added episode 50\n",
      "Replay buf 14718\n",
      "Soft update 11640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 14\n",
      "Added episode 50\n",
      "Replay buf 14768\n",
      "Soft update 11680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 14\n",
      "Added episode 50\n",
      "Replay buf 14818\n",
      "Soft update 11720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 14\n",
      "Added episode 50\n",
      "Replay buf 14868\n",
      "Soft update 11760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 14\n",
      "Added episode 50\n",
      "Replay buf 14918\n",
      "Soft update 11800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 14\n",
      "Added episode 50\n",
      "Replay buf 14968\n",
      "Soft update 11840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 14\n",
      "Added episode 50\n",
      "Replay buf 15018\n",
      "Soft update 11880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 14\n",
      "Added episode 50\n",
      "Replay buf 15068\n",
      "Soft update 11920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 14\n",
      "Added episode 50\n",
      "Replay buf 15118\n",
      "Soft update 11960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:01:07.006678 EEST | [final-sideways-pixels-final-31] Epoch 14 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.109994\n",
      "trainer/Policy Loss                                              0.00519263\n",
      "trainer/Raw Policy Loss                                          0.00519263\n",
      "trainer/State estimation loss                                    0.0043597\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -5.38403\n",
      "trainer/Q Predictions Std                                        4.44203\n",
      "trainer/Q Predictions Max                                        0.691452\n",
      "trainer/Q Predictions Min                                      -12.7898\n",
      "trainer/Q Targets Mean                                          -5.42124\n",
      "trainer/Q Targets Std                                            4.49\n",
      "trainer/Q Targets Max                                            0.873381\n",
      "trainer/Q Targets Min                                          -12.6059\n",
      "trainer/Bellman Errors Mean                                      0.109993\n",
      "trainer/Bellman Errors Std                                       0.268776\n",
      "trainer/Bellman Errors Max                                       3.66038\n",
      "trainer/Bellman Errors Min                                       2.49678e-08\n",
      "trainer/Policy Action Mean                                      -0.205446\n",
      "trainer/Policy Action Std                                        0.666022\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  15118\n",
      "exploration/num paths total                                    306\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.185038\n",
      "exploration/Actions Std                                          0.616448\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                    7561\n",
      "evaluation/num paths total                                     157\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.171261\n",
      "evaluation/Actions Std                                           0.6236\n",
      "evaluation/Actions Max                                           0.999988\n",
      "evaluation/Actions Min                                          -0.999997\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.10676\n",
      "time/evaluation sampling (s)                                    17.0329\n",
      "time/exploration sampling (s)                                   32.7736\n",
      "time/logging (s)                                                 0.0124556\n",
      "time/saving (s)                                                  0.0729499\n",
      "time/training (s)                                              197.664\n",
      "time/epoch (s)                                                 247.663\n",
      "time/total (s)                                                4105.33\n",
      "Epoch                                                           14\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 15\n",
      "\n",
      " Cycle 0 15\n",
      "Added episode 50\n",
      "Replay buf 15168\n",
      "Soft update 12000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 15\n",
      "Added episode 50\n",
      "Replay buf 15218\n",
      "Soft update 12040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 15\n",
      "Added episode 50\n",
      "Replay buf 15268\n",
      "Soft update 12080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 15\n",
      "Added episode 50\n",
      "Replay buf 15318\n",
      "Soft update 12120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 15\n",
      "Added episode 50\n",
      "Replay buf 15368\n",
      "Soft update 12160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 15\n",
      "Added episode 50\n",
      "Replay buf 15418\n",
      "Soft update 12200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 15\n",
      "Added episode 50\n",
      "Replay buf 15468\n",
      "Soft update 12240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 15\n",
      "Added episode 50\n",
      "Replay buf 15518\n",
      "Soft update 12280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 15\n",
      "Added episode 50\n",
      "Replay buf 15568\n",
      "Soft update 12320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 15\n",
      "Added episode 50\n",
      "Replay buf 15618\n",
      "Soft update 12360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 15\n",
      "Added episode 50\n",
      "Replay buf 15668\n",
      "Soft update 12400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 15\n",
      "Added episode 50\n",
      "Replay buf 15718\n",
      "Soft update 12440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 15\n",
      "Added episode 50\n",
      "Replay buf 15768\n",
      "Soft update 12480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 15\n",
      "Added episode 50\n",
      "Replay buf 15818\n",
      "Soft update 12520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 15\n",
      "Added episode 50\n",
      "Replay buf 15868\n",
      "Soft update 12560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 15\n",
      "Added episode 50\n",
      "Replay buf 15918\n",
      "Soft update 12600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 15\n",
      "Added episode 50\n",
      "Replay buf 15968\n",
      "Soft update 12640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 15\n",
      "Added episode 50\n",
      "Replay buf 16018\n",
      "Soft update 12680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 15\n",
      "Added episode 50\n",
      "Replay buf 16068\n",
      "Soft update 12720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 15\n",
      "Added episode 50\n",
      "Replay buf 16118\n",
      "Soft update 12760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:05:17.852482 EEST | [final-sideways-pixels-final-31] Epoch 15 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.110905\n",
      "trainer/Policy Loss                                              0.00530252\n",
      "trainer/Raw Policy Loss                                          0.00530252\n",
      "trainer/State estimation loss                                    0.00398712\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -5.50642\n",
      "trainer/Q Predictions Std                                        4.71643\n",
      "trainer/Q Predictions Max                                        1.22342\n",
      "trainer/Q Predictions Min                                      -13.4891\n",
      "trainer/Q Targets Mean                                          -5.49653\n",
      "trainer/Q Targets Std                                            4.74683\n",
      "trainer/Q Targets Max                                            0.993712\n",
      "trainer/Q Targets Min                                          -13.5647\n",
      "trainer/Bellman Errors Mean                                      0.110905\n",
      "trainer/Bellman Errors Std                                       0.268452\n",
      "trainer/Bellman Errors Max                                       3.45652\n",
      "trainer/Bellman Errors Min                                       2.04636e-10\n",
      "trainer/Policy Action Mean                                      -0.170224\n",
      "trainer/Policy Action Std                                        0.663497\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -0.999999\n",
      "exploration/num steps total                                  16118\n",
      "exploration/num paths total                                    326\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.148866\n",
      "exploration/Actions Std                                          0.641229\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                    8061\n",
      "evaluation/num paths total                                     167\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.0538606\n",
      "evaluation/Actions Std                                           0.643917\n",
      "evaluation/Actions Max                                           0.99988\n",
      "evaluation/Actions Min                                          -0.999889\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.110801\n",
      "time/evaluation sampling (s)                                    17.3262\n",
      "time/exploration sampling (s)                                   34.3126\n",
      "time/logging (s)                                                 0.0068994\n",
      "time/saving (s)                                                  0.0715709\n",
      "time/training (s)                                              199.006\n",
      "time/epoch (s)                                                 250.834\n",
      "time/total (s)                                                4356.17\n",
      "Epoch                                                           15\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 16\n",
      "\n",
      " Cycle 0 16\n",
      "Added episode 50\n",
      "Replay buf 16168\n",
      "Soft update 12800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 16\n",
      "Added episode 50\n",
      "Replay buf 16218\n",
      "Soft update 12840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 16\n",
      "Added episode 50\n",
      "Replay buf 16268\n",
      "Soft update 12880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 16\n",
      "Added episode 50\n",
      "Replay buf 16318\n",
      "Soft update 12920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 16\n",
      "Added episode 50\n",
      "Replay buf 16368\n",
      "Soft update 12960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 16\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 23\n",
      "Added episode 50\n",
      "Replay buf 16441\n",
      "Soft update 13000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 16\n",
      "Added episode 50\n",
      "Replay buf 16491\n",
      "Soft update 13040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 16\n",
      "Added episode 50\n",
      "Replay buf 16541\n",
      "Soft update 13080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 16\n",
      "Added episode 50\n",
      "Replay buf 16591\n",
      "Soft update 13120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 16\n",
      "Added episode 50\n",
      "Replay buf 16641\n",
      "Soft update 13160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 16\n",
      "Added episode 50\n",
      "Replay buf 16691\n",
      "Soft update 13200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 16\n",
      "Added episode 50\n",
      "Replay buf 16741\n",
      "Soft update 13240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 16\n",
      "Added episode 50\n",
      "Replay buf 16791\n",
      "Soft update 13280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 16\n",
      "Added episode 50\n",
      "Replay buf 16841\n",
      "Soft update 13320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 16\n",
      "Added episode 50\n",
      "Replay buf 16891\n",
      "Soft update 13360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 16\n",
      "Added episode 50\n",
      "Replay buf 16941\n",
      "Soft update 13400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 16\n",
      "Added episode 50\n",
      "Replay buf 16991\n",
      "Soft update 13440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 16\n",
      "Added episode 50\n",
      "Replay buf 17041\n",
      "Soft update 13480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 16\n",
      "Added episode 50\n",
      "Replay buf 17091\n",
      "Soft update 13520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 16\n",
      "Added episode 50\n",
      "Replay buf 17141\n",
      "Soft update 13560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:09:26.697640 EEST | [final-sideways-pixels-final-31] Epoch 16 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.11728\n",
      "trainer/Policy Loss                                              0.00569398\n",
      "trainer/Raw Policy Loss                                          0.00569398\n",
      "trainer/State estimation loss                                    0.00381823\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -5.87264\n",
      "trainer/Q Predictions Std                                        5.06069\n",
      "trainer/Q Predictions Max                                        0.929802\n",
      "trainer/Q Predictions Min                                      -14.2397\n",
      "trainer/Q Targets Mean                                          -5.83931\n",
      "trainer/Q Targets Std                                            5.03605\n",
      "trainer/Q Targets Max                                            0.924767\n",
      "trainer/Q Targets Min                                          -14.1685\n",
      "trainer/Bellman Errors Mean                                      0.11728\n",
      "trainer/Bellman Errors Std                                       0.307402\n",
      "trainer/Bellman Errors Max                                       5.04468\n",
      "trainer/Bellman Errors Min                                       9.42634e-08\n",
      "trainer/Policy Action Mean                                      -0.183051\n",
      "trainer/Policy Action Std                                        0.656868\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  17141\n",
      "exploration/num paths total                                    347\n",
      "exploration/path length Mean                                    48.7143\n",
      "exploration/path length Std                                      5.74989\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     23\n",
      "exploration/Rewards Mean                                        -0.999023\n",
      "exploration/Rewards Std                                          0.03125\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -48.6667\n",
      "exploration/Returns Std                                          5.96285\n",
      "exploration/Returns Max                                        -22\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.181441\n",
      "exploration/Actions Std                                          0.620012\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           21\n",
      "exploration/Average Returns                                    -48.6667\n",
      "exploration/env_infos/final/is_success Mean                      0.0476191\n",
      "exploration/env_infos/final/is_success Std                       0.212959\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.000977517\n",
      "exploration/env_infos/is_success Std                             0.03125\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                    8561\n",
      "evaluation/num paths total                                     177\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.248952\n",
      "evaluation/Actions Std                                           0.654442\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.114962\n",
      "time/evaluation sampling (s)                                    17.0882\n",
      "time/exploration sampling (s)                                   33.443\n",
      "time/logging (s)                                                 0.00697303\n",
      "time/saving (s)                                                  0.0706819\n",
      "time/training (s)                                              198.116\n",
      "time/epoch (s)                                                 248.84\n",
      "time/total (s)                                                4605.02\n",
      "Epoch                                                           16\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 17\n",
      "\n",
      " Cycle 0 17\n",
      "Added episode 50\n",
      "Replay buf 17191\n",
      "Soft update 13600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 17\n",
      "Added episode 50\n",
      "Replay buf 17241\n",
      "Soft update 13640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 17\n",
      "Added episode 50\n",
      "Replay buf 17291\n",
      "Soft update 13680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 17\n",
      "Added episode 50\n",
      "Replay buf 17341\n",
      "Soft update 13720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 17\n",
      "Added episode 50\n",
      "Replay buf 17391\n",
      "Soft update 13760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 17\n",
      "Added episode 50\n",
      "Replay buf 17441\n",
      "Soft update 13800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 17\n",
      "Added episode 50\n",
      "Replay buf 17491\n",
      "Soft update 13840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 17\n",
      "Added episode 50\n",
      "Replay buf 17541\n",
      "Soft update 13880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 17\n",
      "Added episode 50\n",
      "Replay buf 17591\n",
      "Soft update 13920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 17\n",
      "Added episode 50\n",
      "Replay buf 17641\n",
      "Soft update 13960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 17\n",
      "Added episode 50\n",
      "Replay buf 17691\n",
      "Soft update 14000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 17\n",
      "Added episode 50\n",
      "Replay buf 17741\n",
      "Soft update 14040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 17\n",
      "Added episode 50\n",
      "Replay buf 17791\n",
      "Soft update 14080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 17\n",
      "Added episode 50\n",
      "Replay buf 17841\n",
      "Soft update 14120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 17\n",
      "Added episode 50\n",
      "Replay buf 17891\n",
      "Soft update 14160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 17\n",
      "Added episode 50\n",
      "Replay buf 17941\n",
      "Soft update 14200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 17\n",
      "Added episode 50\n",
      "Replay buf 17991\n",
      "Soft update 14240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 17\n",
      "Added episode 50\n",
      "Replay buf 18041\n",
      "Soft update 14280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 17\n",
      "Added episode 50\n",
      "Replay buf 18091\n",
      "Soft update 14320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 17\n",
      "Added episode 50\n",
      "Replay buf 18141\n",
      "Soft update 14360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:13:33.493570 EEST | [final-sideways-pixels-final-31] Epoch 17 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.144492\n",
      "trainer/Policy Loss                                              0.00581357\n",
      "trainer/Raw Policy Loss                                          0.00581357\n",
      "trainer/State estimation loss                                    0.00411953\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -5.99606\n",
      "trainer/Q Predictions Std                                        5.3177\n",
      "trainer/Q Predictions Max                                        1.24113\n",
      "trainer/Q Predictions Min                                      -16.5278\n",
      "trainer/Q Targets Mean                                          -5.96974\n",
      "trainer/Q Targets Std                                            5.29444\n",
      "trainer/Q Targets Max                                            1.45748\n",
      "trainer/Q Targets Min                                          -16.5397\n",
      "trainer/Bellman Errors Mean                                      0.144492\n",
      "trainer/Bellman Errors Std                                       0.322847\n",
      "trainer/Bellman Errors Max                                       4.1443\n",
      "trainer/Bellman Errors Min                                       2.84936e-08\n",
      "trainer/Policy Action Mean                                      -0.102571\n",
      "trainer/Policy Action Std                                        0.680369\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -0.999999\n",
      "exploration/num steps total                                  18141\n",
      "exploration/num paths total                                    367\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.18045\n",
      "exploration/Actions Std                                          0.63648\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                    9061\n",
      "evaluation/num paths total                                     187\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.0924751\n",
      "evaluation/Actions Std                                           0.690983\n",
      "evaluation/Actions Max                                           0.999999\n",
      "evaluation/Actions Min                                          -0.999999\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.10663\n",
      "time/evaluation sampling (s)                                    17.6295\n",
      "time/exploration sampling (s)                                   31.4578\n",
      "time/logging (s)                                                 0.00678738\n",
      "time/saving (s)                                                  0.0705299\n",
      "time/training (s)                                              197.52\n",
      "time/epoch (s)                                                 246.791\n",
      "time/total (s)                                                4851.81\n",
      "Epoch                                                           17\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 18\n",
      "\n",
      " Cycle 0 18\n",
      "Added episode 50\n",
      "Replay buf 18191\n",
      "Soft update 14400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 18\n",
      "Added episode 50\n",
      "Replay buf 18241\n",
      "Soft update 14440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 18\n",
      "Added episode 50\n",
      "Replay buf 18291\n",
      "Soft update 14480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 18\n",
      "Added episode 50\n",
      "Replay buf 18341\n",
      "Soft update 14520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 18\n",
      "Added episode 50\n",
      "Replay buf 18391\n",
      "Soft update 14560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 18\n",
      "Added episode 50\n",
      "Replay buf 18441\n",
      "Soft update 14600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 18\n",
      "Added episode 50\n",
      "Replay buf 18491\n",
      "Soft update 14640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 18\n",
      "Added episode 50\n",
      "Replay buf 18541\n",
      "Soft update 14680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 18\n",
      "Added episode 50\n",
      "Replay buf 18591\n",
      "Soft update 14720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 18\n",
      "Added episode 50\n",
      "Replay buf 18641\n",
      "Soft update 14760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 18\n",
      "Added episode 50\n",
      "Replay buf 18691\n",
      "Soft update 14800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 18\n",
      "Added episode 50\n",
      "Replay buf 18741\n",
      "Soft update 14840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 18\n",
      "Added episode 50\n",
      "Replay buf 18791\n",
      "Soft update 14880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 18\n",
      "Added episode 50\n",
      "Replay buf 18841\n",
      "Soft update 14920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 18\n",
      "Added episode 50\n",
      "Replay buf 18891\n",
      "Soft update 14960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 18\n",
      "Added episode 50\n",
      "Replay buf 18941\n",
      "Soft update 15000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 18\n",
      "Added episode 50\n",
      "Replay buf 18991\n",
      "Soft update 15040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 18\n",
      "Added episode 50\n",
      "Replay buf 19041\n",
      "Soft update 15080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 18\n",
      "Added episode 50\n",
      "Replay buf 19091\n",
      "Soft update 15120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 18\n",
      "Added episode 50\n",
      "Replay buf 19141\n",
      "Soft update 15160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:17:39.571708 EEST | [final-sideways-pixels-final-31] Epoch 18 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.149487\n",
      "trainer/Policy Loss                                              0.00589414\n",
      "trainer/Raw Policy Loss                                          0.00589414\n",
      "trainer/State estimation loss                                    0.00394839\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -5.98863\n",
      "trainer/Q Predictions Std                                        5.54033\n",
      "trainer/Q Predictions Max                                        1.23387\n",
      "trainer/Q Predictions Min                                      -16.6487\n",
      "trainer/Q Targets Mean                                          -6.04891\n",
      "trainer/Q Targets Std                                            5.61443\n",
      "trainer/Q Targets Max                                            1.15383\n",
      "trainer/Q Targets Min                                          -16.9236\n",
      "trainer/Bellman Errors Mean                                      0.149487\n",
      "trainer/Bellman Errors Std                                       0.394749\n",
      "trainer/Bellman Errors Max                                       5.26234\n",
      "trainer/Bellman Errors Min                                       1.83068e-10\n",
      "trainer/Policy Action Mean                                      -0.183882\n",
      "trainer/Policy Action Std                                        0.660005\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  19141\n",
      "exploration/num paths total                                    387\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.217703\n",
      "exploration/Actions Std                                          0.638309\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                    9561\n",
      "evaluation/num paths total                                     197\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.232153\n",
      "evaluation/Actions Std                                           0.584042\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.109189\n",
      "time/evaluation sampling (s)                                    15.6692\n",
      "time/exploration sampling (s)                                   32.3025\n",
      "time/logging (s)                                                 0.00680206\n",
      "time/saving (s)                                                  0.0714005\n",
      "time/training (s)                                              197.914\n",
      "time/epoch (s)                                                 246.073\n",
      "time/total (s)                                                5097.89\n",
      "Epoch                                                           18\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 19\n",
      "\n",
      " Cycle 0 19\n",
      "Added episode 50\n",
      "Replay buf 19191\n",
      "Soft update 15200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 19\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 19254\n",
      "Soft update 15240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 19\n",
      "Added episode 50\n",
      "Replay buf 19304\n",
      "Soft update 15280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 19\n",
      "Added episode 50\n",
      "Replay buf 19354\n",
      "Soft update 15320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 19\n",
      "Added episode 50\n",
      "Replay buf 19404\n",
      "Soft update 15360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 19\n",
      "Added episode 50\n",
      "Replay buf 19454\n",
      "Soft update 15400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 19\n",
      "Added episode 50\n",
      "Replay buf 19504\n",
      "Soft update 15440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 19\n",
      "Added episode 50\n",
      "Replay buf 19554\n",
      "Soft update 15480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 19\n",
      "Added episode 50\n",
      "Replay buf 19604\n",
      "Soft update 15520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 19\n",
      "Added episode 50\n",
      "Replay buf 19654\n",
      "Soft update 15560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 19\n",
      "Added episode 50\n",
      "Replay buf 19704\n",
      "Soft update 15600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 19\n",
      "Added episode 50\n",
      "Replay buf 19754\n",
      "Soft update 15640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 19\n",
      "Added episode 50\n",
      "Replay buf 19804\n",
      "Soft update 15680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 19\n",
      "Added episode 50\n",
      "Replay buf 19854\n",
      "Soft update 15720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 19\n",
      "Added episode 50\n",
      "Replay buf 19904\n",
      "Soft update 15760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 19\n",
      "Added episode 50\n",
      "Replay buf 19954\n",
      "Soft update 15800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 19\n",
      "Added episode 50\n",
      "Replay buf 20004\n",
      "Soft update 15840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 19\n",
      "Added episode 50\n",
      "Replay buf 20054\n",
      "Soft update 15880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 19\n",
      "Added episode 50\n",
      "Replay buf 20104\n",
      "Soft update 15920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 19\n",
      "Added episode 50\n",
      "Replay buf 20154\n",
      "Soft update 15960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:21:47.171573 EEST | [final-sideways-pixels-final-31] Epoch 19 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.153577\n",
      "trainer/Policy Loss                                              0.00597685\n",
      "trainer/Raw Policy Loss                                          0.00597685\n",
      "trainer/State estimation loss                                    0.00436418\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -6.1118\n",
      "trainer/Q Predictions Std                                        5.74142\n",
      "trainer/Q Predictions Max                                        1.28792\n",
      "trainer/Q Predictions Min                                      -17.6197\n",
      "trainer/Q Targets Mean                                          -6.02531\n",
      "trainer/Q Targets Std                                            5.76346\n",
      "trainer/Q Targets Max                                            1.24957\n",
      "trainer/Q Targets Min                                          -18.3493\n",
      "trainer/Bellman Errors Mean                                      0.153577\n",
      "trainer/Bellman Errors Std                                       0.360036\n",
      "trainer/Bellman Errors Max                                       3.82463\n",
      "trainer/Bellman Errors Min                                       6.95329e-08\n",
      "trainer/Policy Action Mean                                      -0.142585\n",
      "trainer/Policy Action Std                                        0.629349\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -0.99999\n",
      "exploration/num steps total                                  20154\n",
      "exploration/num paths total                                    408\n",
      "exploration/path length Mean                                    48.2381\n",
      "exploration/path length Std                                      7.87948\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     13\n",
      "exploration/Rewards Mean                                        -0.999013\n",
      "exploration/Rewards Std                                          0.0314037\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -48.1905\n",
      "exploration/Returns Std                                          8.09244\n",
      "exploration/Returns Max                                        -12\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.214421\n",
      "exploration/Actions Std                                          0.656236\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           21\n",
      "exploration/Average Returns                                    -48.1905\n",
      "exploration/env_infos/final/is_success Mean                      0.0476191\n",
      "exploration/env_infos/final/is_success Std                       0.212959\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.000987167\n",
      "exploration/env_infos/is_success Std                             0.0314037\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   10061\n",
      "evaluation/num paths total                                     207\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.287154\n",
      "evaluation/Actions Std                                           0.652039\n",
      "evaluation/Actions Max                                           0.999943\n",
      "evaluation/Actions Min                                          -0.999949\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.110125\n",
      "time/evaluation sampling (s)                                    16.6363\n",
      "time/exploration sampling (s)                                   33.198\n",
      "time/logging (s)                                                 0.00684653\n",
      "time/saving (s)                                                  0.0709203\n",
      "time/training (s)                                              197.573\n",
      "time/epoch (s)                                                 247.595\n",
      "time/total (s)                                                5345.49\n",
      "Epoch                                                           19\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 20\n",
      "\n",
      " Cycle 0 20\n",
      "Added episode 50\n",
      "Replay buf 20204\n",
      "Soft update 16000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 20\n",
      "Added episode 50\n",
      "Replay buf 20254\n",
      "Soft update 16040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 20\n",
      "Added episode 50\n",
      "Replay buf 20304\n",
      "Soft update 16080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 20\n",
      "Added episode 50\n",
      "Replay buf 20354\n",
      "Soft update 16120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 20\n",
      "Added episode 50\n",
      "Replay buf 20404\n",
      "Soft update 16160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 20\n",
      "Added episode 50\n",
      "Replay buf 20454\n",
      "Soft update 16200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 20\n",
      "Added episode 50\n",
      "Replay buf 20504\n",
      "Soft update 16240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 20\n",
      "Added episode 50\n",
      "Replay buf 20554\n",
      "Soft update 16280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 20\n",
      "Added episode 50\n",
      "Replay buf 20604\n",
      "Soft update 16320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 20\n",
      "Added episode 50\n",
      "Replay buf 20654\n",
      "Soft update 16360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 20\n",
      "Added episode 50\n",
      "Replay buf 20704\n",
      "Soft update 16400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 20\n",
      "Added episode 50\n",
      "Replay buf 20754\n",
      "Soft update 16440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 20\n",
      "Added episode 50\n",
      "Replay buf 20804\n",
      "Soft update 16480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 20\n",
      "Added episode 50\n",
      "Replay buf 20854\n",
      "Soft update 16520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 20\n",
      "Added episode 50\n",
      "Replay buf 20904\n",
      "Soft update 16560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 20\n",
      "Added episode 50\n",
      "Replay buf 20954\n",
      "Soft update 16600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 20\n",
      "Added episode 50\n",
      "Replay buf 21004\n",
      "Soft update 16640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 20\n",
      "Added episode 50\n",
      "Replay buf 21054\n",
      "Soft update 16680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 20\n",
      "Added episode 50\n",
      "Replay buf 21104\n",
      "Soft update 16720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 20\n",
      "Added episode 50\n",
      "Replay buf 21154\n",
      "Soft update 16760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:25:53.112143 EEST | [final-sideways-pixels-final-31] Epoch 20 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.172108\n",
      "trainer/Policy Loss                                              0.00612427\n",
      "trainer/Raw Policy Loss                                          0.00612427\n",
      "trainer/State estimation loss                                    0.0035976\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -6.33332\n",
      "trainer/Q Predictions Std                                        6.00464\n",
      "trainer/Q Predictions Max                                        1.3332\n",
      "trainer/Q Predictions Min                                      -17.9254\n",
      "trainer/Q Targets Mean                                          -6.36843\n",
      "trainer/Q Targets Std                                            6.09229\n",
      "trainer/Q Targets Max                                            1.46796\n",
      "trainer/Q Targets Min                                          -18.2187\n",
      "trainer/Bellman Errors Mean                                      0.172108\n",
      "trainer/Bellman Errors Std                                       0.484977\n",
      "trainer/Bellman Errors Max                                       5.52576\n",
      "trainer/Bellman Errors Min                                       1.53705e-10\n",
      "trainer/Policy Action Mean                                      -0.166132\n",
      "trainer/Policy Action Std                                        0.667741\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  21154\n",
      "exploration/num paths total                                    428\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.168587\n",
      "exploration/Actions Std                                          0.626371\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   10561\n",
      "evaluation/num paths total                                     217\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.21266\n",
      "evaluation/Actions Std                                           0.627451\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.106953\n",
      "time/evaluation sampling (s)                                    15.796\n",
      "time/exploration sampling (s)                                   32.2082\n",
      "time/logging (s)                                                 0.00683464\n",
      "time/saving (s)                                                  0.0707803\n",
      "time/training (s)                                              197.745\n",
      "time/epoch (s)                                                 245.933\n",
      "time/total (s)                                                5591.43\n",
      "Epoch                                                           20\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 21\n",
      "\n",
      " Cycle 0 21\n",
      "Added episode 50\n",
      "Replay buf 21204\n",
      "Soft update 16800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 21\n",
      "Added episode 50\n",
      "Replay buf 21254\n",
      "Soft update 16840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 21\n",
      "Added episode 50\n",
      "Replay buf 21304\n",
      "Soft update 16880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 21\n",
      "Added episode 50\n",
      "Replay buf 21354\n",
      "Soft update 16920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 21\n",
      "Added episode 50\n",
      "Replay buf 21404\n",
      "Soft update 16960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 21\n",
      "Added episode 50\n",
      "Replay buf 21454\n",
      "Soft update 17000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 21\n",
      "Added episode 50\n",
      "Replay buf 21504\n",
      "Soft update 17040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 21\n",
      "Added episode 50\n",
      "Replay buf 21554\n",
      "Soft update 17080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 21\n",
      "Added episode 50\n",
      "Replay buf 21604\n",
      "Soft update 17120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 21\n",
      "Added episode 50\n",
      "Replay buf 21654\n",
      "Soft update 17160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 21\n",
      "Added episode 50\n",
      "Replay buf 21704\n",
      "Soft update 17200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 21\n",
      "Added episode 50\n",
      "Replay buf 21754\n",
      "Soft update 17240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 21\n",
      "Added episode 50\n",
      "Replay buf 21804\n",
      "Soft update 17280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 21\n",
      "Added episode 50\n",
      "Replay buf 21854\n",
      "Soft update 17320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 21\n",
      "Added episode 50\n",
      "Replay buf 21904\n",
      "Soft update 17360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 21\n",
      "Added episode 50\n",
      "Replay buf 21954\n",
      "Soft update 17400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 21\n",
      "Added episode 50\n",
      "Replay buf 22004\n",
      "Soft update 17440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 21\n",
      "Added episode 50\n",
      "Replay buf 22054\n",
      "Soft update 17480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 21\n",
      "Added episode 50\n",
      "Replay buf 22104\n",
      "Soft update 17520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 21\n",
      "Added episode 50\n",
      "Replay buf 22154\n",
      "Soft update 17560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:30:01.015091 EEST | [final-sideways-pixels-final-31] Epoch 21 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.159082\n",
      "trainer/Policy Loss                                              0.00628896\n",
      "trainer/Raw Policy Loss                                          0.00628896\n",
      "trainer/State estimation loss                                    0.00384783\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -6.46077\n",
      "trainer/Q Predictions Std                                        6.33137\n",
      "trainer/Q Predictions Max                                        1.60019\n",
      "trainer/Q Predictions Min                                      -18.8888\n",
      "trainer/Q Targets Mean                                          -6.53842\n",
      "trainer/Q Targets Std                                            6.35271\n",
      "trainer/Q Targets Max                                            1.70065\n",
      "trainer/Q Targets Min                                          -18.8747\n",
      "trainer/Bellman Errors Mean                                      0.159082\n",
      "trainer/Bellman Errors Std                                       0.434563\n",
      "trainer/Bellman Errors Max                                       5.84898\n",
      "trainer/Bellman Errors Min                                       3.63798e-08\n",
      "trainer/Policy Action Mean                                      -0.133722\n",
      "trainer/Policy Action Std                                        0.681362\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -0.999999\n",
      "exploration/num steps total                                  22154\n",
      "exploration/num paths total                                    448\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.160236\n",
      "exploration/Actions Std                                          0.659643\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   11061\n",
      "evaluation/num paths total                                     227\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.216014\n",
      "evaluation/Actions Std                                           0.71591\n",
      "evaluation/Actions Max                                           0.999977\n",
      "evaluation/Actions Min                                          -0.999983\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.103232\n",
      "time/evaluation sampling (s)                                    18.2798\n",
      "time/exploration sampling (s)                                   31.7918\n",
      "time/logging (s)                                                 0.00684498\n",
      "time/saving (s)                                                  0.0722954\n",
      "time/training (s)                                              197.644\n",
      "time/epoch (s)                                                 247.898\n",
      "time/total (s)                                                5839.33\n",
      "Epoch                                                           21\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 18\n",
      "Evaluation done\n",
      "Epoch 22\n",
      "\n",
      " Cycle 0 22\n",
      "Added episode 50\n",
      "Replay buf 22204\n",
      "Soft update 17600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 22\n",
      "Added episode 50\n",
      "Replay buf 22254\n",
      "Soft update 17640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 22\n",
      "Added episode 50\n",
      "Replay buf 22304\n",
      "Soft update 17680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 22\n",
      "Added episode 50\n",
      "Replay buf 22354\n",
      "Soft update 17720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 22\n",
      "Added episode 50\n",
      "Replay buf 22404\n",
      "Soft update 17760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 22\n",
      "Added episode 50\n",
      "Replay buf 22454\n",
      "Soft update 17800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 22\n",
      "Added episode 50\n",
      "Replay buf 22504\n",
      "Soft update 17840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 22\n",
      "Added episode 50\n",
      "Replay buf 22554\n",
      "Soft update 17880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 22\n",
      "Added episode 50\n",
      "Replay buf 22604\n",
      "Soft update 17920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 22\n",
      "Added episode 50\n",
      "Replay buf 22654\n",
      "Soft update 17960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 22\n",
      "Added episode 50\n",
      "Replay buf 22704\n",
      "Soft update 18000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 22\n",
      "Added episode 50\n",
      "Replay buf 22754\n",
      "Soft update 18040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 22\n",
      "Added episode 50\n",
      "Replay buf 22804\n",
      "Soft update 18080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 22\n",
      "Added episode 50\n",
      "Replay buf 22854\n",
      "Soft update 18120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 22\n",
      "Added episode 50\n",
      "Replay buf 22904\n",
      "Soft update 18160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 22\n",
      "Added episode 50\n",
      "Replay buf 22954\n",
      "Soft update 18200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 22\n",
      "Added episode 50\n",
      "Replay buf 23004\n",
      "Soft update 18240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 22\n",
      "Added episode 50\n",
      "Replay buf 23054\n",
      "Soft update 18280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 22\n",
      "Added episode 50\n",
      "Replay buf 23104\n",
      "Soft update 18320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 22\n",
      "Added episode 50\n",
      "Replay buf 23154\n",
      "Soft update 18360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:34:08.532179 EEST | [final-sideways-pixels-final-31] Epoch 22 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                  0.175327\n",
      "trainer/Policy Loss                                              0.00648967\n",
      "trainer/Raw Policy Loss                                          0.00648967\n",
      "trainer/State estimation loss                                    0.0040642\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -6.61491\n",
      "trainer/Q Predictions Std                                        6.49599\n",
      "trainer/Q Predictions Max                                        2.87766\n",
      "trainer/Q Predictions Min                                      -19.8495\n",
      "trainer/Q Targets Mean                                          -6.74397\n",
      "trainer/Q Targets Std                                            6.54369\n",
      "trainer/Q Targets Max                                            2.11742\n",
      "trainer/Q Targets Min                                          -20.518\n",
      "trainer/Bellman Errors Mean                                      0.175327\n",
      "trainer/Bellman Errors Std                                       0.441445\n",
      "trainer/Bellman Errors Max                                       5.4644\n",
      "trainer/Bellman Errors Min                                       8.0641e-07\n",
      "trainer/Policy Action Mean                                      -0.161375\n",
      "trainer/Policy Action Std                                        0.653825\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -0.999996\n",
      "exploration/num steps total                                  23154\n",
      "exploration/num paths total                                    468\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.175415\n",
      "exploration/Actions Std                                          0.624638\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   11580\n",
      "evaluation/num paths total                                     238\n",
      "evaluation/path length Mean                                     47.1818\n",
      "evaluation/path length Std                                       8.91187\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      19\n",
      "evaluation/Rewards Mean                                         -0.998073\n",
      "evaluation/Rewards Std                                           0.0438528\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -47.0909\n",
      "evaluation/Returns Std                                           9.19935\n",
      "evaluation/Returns Max                                         -18\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.120618\n",
      "evaluation/Actions Std                                           0.676266\n",
      "evaluation/Actions Max                                           0.999987\n",
      "evaluation/Actions Min                                          -0.99997\n",
      "evaluation/Num Paths                                            11\n",
      "evaluation/Average Returns                                     -47.0909\n",
      "evaluation/env_infos/final/is_success Mean                       0.0909091\n",
      "evaluation/env_infos/final/is_success Std                        0.28748\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00192678\n",
      "evaluation/env_infos/is_success Std                              0.0438528\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.109121\n",
      "time/evaluation sampling (s)                                    16.8902\n",
      "time/exploration sampling (s)                                   32.6731\n",
      "time/logging (s)                                                 0.0069261\n",
      "time/saving (s)                                                  0.0714639\n",
      "time/training (s)                                              197.761\n",
      "time/epoch (s)                                                 247.512\n",
      "time/total (s)                                                6086.84\n",
      "Epoch                                                           22\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 23\n",
      "\n",
      " Cycle 0 23\n",
      "Added episode 50\n",
      "Replay buf 23204\n",
      "Soft update 18400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 23\n",
      "Added episode 50\n",
      "Replay buf 23254\n",
      "Soft update 18440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 23\n",
      "Added episode 50\n",
      "Replay buf 23304\n",
      "Soft update 18480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 23\n",
      "Added episode 50\n",
      "Replay buf 23354\n",
      "Soft update 18520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 23\n",
      "Added episode 50\n",
      "Replay buf 23404\n",
      "Soft update 18560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 23\n",
      "Added episode 50\n",
      "Replay buf 23454\n",
      "Soft update 18600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 23\n",
      "Added episode 50\n",
      "Replay buf 23504\n",
      "Soft update 18640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 23\n",
      "Added episode 50\n",
      "Replay buf 23554\n",
      "Soft update 18680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 23\n",
      "Added episode 50\n",
      "Replay buf 23604\n",
      "Soft update 18720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 23\n",
      "Added episode 50\n",
      "Replay buf 23654\n",
      "Soft update 18760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 23\n",
      "Added episode 50\n",
      "Replay buf 23704\n",
      "Soft update 18800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 23\n",
      "Added episode 50\n",
      "Replay buf 23754\n",
      "Soft update 18840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 23\n",
      "Added episode 50\n",
      "Replay buf 23804\n",
      "Soft update 18880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 23\n",
      "Added episode 50\n",
      "Replay buf 23854\n",
      "Soft update 18920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 23\n",
      "Added episode 50\n",
      "Replay buf 23904\n",
      "Soft update 18960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 23\n",
      "Added episode 50\n",
      "Replay buf 23954\n",
      "Soft update 19000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 23\n",
      "Added episode 50\n",
      "Replay buf 24004\n",
      "Soft update 19040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 23\n",
      "Added episode 50\n",
      "Replay buf 24054\n",
      "Soft update 19080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 23\n",
      "Added episode 50\n",
      "Replay buf 24104\n",
      "Soft update 19120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 23\n",
      "Added episode 50\n",
      "Replay buf 24154\n",
      "Soft update 19160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:38:16.171959 EEST | [final-sideways-pixels-final-31] Epoch 23 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.177604\n",
      "trainer/Policy Loss                                              0.00651771\n",
      "trainer/Raw Policy Loss                                          0.00651771\n",
      "trainer/State estimation loss                                    0.00404953\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -6.71482\n",
      "trainer/Q Predictions Std                                        6.86361\n",
      "trainer/Q Predictions Max                                        2.78111\n",
      "trainer/Q Predictions Min                                      -21.0405\n",
      "trainer/Q Targets Mean                                          -6.83693\n",
      "trainer/Q Targets Std                                            6.84222\n",
      "trainer/Q Targets Max                                            2.57493\n",
      "trainer/Q Targets Min                                          -20.2455\n",
      "trainer/Bellman Errors Mean                                      0.177604\n",
      "trainer/Bellman Errors Std                                       0.415526\n",
      "trainer/Bellman Errors Max                                       5.05463\n",
      "trainer/Bellman Errors Min                                       2.24181e-08\n",
      "trainer/Policy Action Mean                                      -0.166382\n",
      "trainer/Policy Action Std                                        0.669993\n",
      "trainer/Policy Action Max                                        0.999999\n",
      "trainer/Policy Action Min                                       -0.999999\n",
      "exploration/num steps total                                  24154\n",
      "exploration/num paths total                                    488\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.189622\n",
      "exploration/Actions Std                                          0.648685\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   12080\n",
      "evaluation/num paths total                                     248\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.170183\n",
      "evaluation/Actions Std                                           0.640688\n",
      "evaluation/Actions Max                                           0.999758\n",
      "evaluation/Actions Min                                          -0.999998\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.110117\n",
      "time/evaluation sampling (s)                                    16.6488\n",
      "time/exploration sampling (s)                                   32.853\n",
      "time/logging (s)                                                 0.00688199\n",
      "time/saving (s)                                                  0.0716186\n",
      "time/training (s)                                              197.944\n",
      "time/epoch (s)                                                 247.635\n",
      "time/total (s)                                                6334.48\n",
      "Epoch                                                           23\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 24\n",
      "\n",
      " Cycle 0 24\n",
      "Added episode 50\n",
      "Replay buf 24204\n",
      "Soft update 19200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 24\n",
      "Added episode 50\n",
      "Replay buf 24254\n",
      "Soft update 19240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 24\n",
      "Added episode 50\n",
      "Replay buf 24304\n",
      "Soft update 19280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 24\n",
      "Added episode 50\n",
      "Replay buf 24354\n",
      "Soft update 19320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 24\n",
      "Added episode 50\n",
      "Replay buf 24404\n",
      "Soft update 19360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 24\n",
      "Added episode 50\n",
      "Replay buf 24454\n",
      "Soft update 19400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 24\n",
      "Added episode 50\n",
      "Replay buf 24504\n",
      "Soft update 19440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 24\n",
      "Added episode 50\n",
      "Replay buf 24554\n",
      "Soft update 19480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 24\n",
      "Added episode 50\n",
      "Replay buf 24604\n",
      "Soft update 19520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 24\n",
      "Added episode 50\n",
      "Replay buf 24654\n",
      "Soft update 19560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 24\n",
      "Added episode 50\n",
      "Replay buf 24704\n",
      "Soft update 19600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 24\n",
      "Added episode 50\n",
      "Replay buf 24754\n",
      "Soft update 19640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 24\n",
      "Added episode 50\n",
      "Replay buf 24804\n",
      "Soft update 19680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 24\n",
      "Added episode 50\n",
      "Replay buf 24854\n",
      "Soft update 19720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 24\n",
      "Added episode 50\n",
      "Replay buf 24904\n",
      "Soft update 19760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 24\n",
      "Added episode 50\n",
      "Replay buf 24954\n",
      "Soft update 19800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 24\n",
      "Added episode 50\n",
      "Replay buf 25004\n",
      "Soft update 19840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 24\n",
      "Added episode 50\n",
      "Replay buf 25054\n",
      "Soft update 19880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 24\n",
      "Added episode 50\n",
      "Replay buf 25104\n",
      "Soft update 19920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 24\n",
      "Added episode 50\n",
      "Replay buf 25154\n",
      "Soft update 19960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:42:23.831222 EEST | [final-sideways-pixels-final-31] Epoch 24 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.163937\n",
      "trainer/Policy Loss                                              0.00662386\n",
      "trainer/Raw Policy Loss                                          0.00662386\n",
      "trainer/State estimation loss                                    0.00378343\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -6.81292\n",
      "trainer/Q Predictions Std                                        7.09313\n",
      "trainer/Q Predictions Max                                        3.38541\n",
      "trainer/Q Predictions Min                                      -21.5044\n",
      "trainer/Q Targets Mean                                          -6.81726\n",
      "trainer/Q Targets Std                                            7.04857\n",
      "trainer/Q Targets Max                                            3.05986\n",
      "trainer/Q Targets Min                                          -21.0774\n",
      "trainer/Bellman Errors Mean                                      0.163937\n",
      "trainer/Bellman Errors Std                                       0.431216\n",
      "trainer/Bellman Errors Max                                       8.98053\n",
      "trainer/Bellman Errors Min                                       2.38688e-08\n",
      "trainer/Policy Action Mean                                      -0.151669\n",
      "trainer/Policy Action Std                                        0.663905\n",
      "trainer/Policy Action Max                                        0.999997\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  25154\n",
      "exploration/num paths total                                    508\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.170535\n",
      "exploration/Actions Std                                          0.625\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   12580\n",
      "evaluation/num paths total                                     258\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.203487\n",
      "evaluation/Actions Std                                           0.592503\n",
      "evaluation/Actions Max                                           0.999531\n",
      "evaluation/Actions Min                                          -0.999999\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.110947\n",
      "time/evaluation sampling (s)                                    16.5177\n",
      "time/exploration sampling (s)                                   32.7872\n",
      "time/logging (s)                                                 0.0068894\n",
      "time/saving (s)                                                  0.0705027\n",
      "time/training (s)                                              198.161\n",
      "time/epoch (s)                                                 247.654\n",
      "time/total (s)                                                6582.14\n",
      "Epoch                                                           24\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 25\n",
      "\n",
      " Cycle 0 25\n",
      "Added episode 50\n",
      "Replay buf 25204\n",
      "Soft update 20000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 25\n",
      "Added episode 50\n",
      "Replay buf 25254\n",
      "Soft update 20040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 25\n",
      "Added episode 50\n",
      "Replay buf 25304\n",
      "Soft update 20080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 25\n",
      "Added episode 50\n",
      "Replay buf 25354\n",
      "Soft update 20120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 25\n",
      "Added episode 50\n",
      "Replay buf 25404\n",
      "Soft update 20160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 25\n",
      "Added episode 50\n",
      "Replay buf 25454\n",
      "Soft update 20200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 25\n",
      "Added episode 50\n",
      "Replay buf 25504\n",
      "Soft update 20240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 25\n",
      "Added episode 50\n",
      "Replay buf 25554\n",
      "Soft update 20280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 25\n",
      "Added episode 50\n",
      "Replay buf 25604\n",
      "Soft update 20320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 25\n",
      "Added episode 50\n",
      "Replay buf 25654\n",
      "Soft update 20360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 25\n",
      "Added episode 50\n",
      "Replay buf 25704\n",
      "Soft update 20400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 25\n",
      "Added episode 50\n",
      "Replay buf 25754\n",
      "Soft update 20440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 25\n",
      "Added episode 50\n",
      "Replay buf 25804\n",
      "Soft update 20480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 25\n",
      "Added episode 50\n",
      "Replay buf 25854\n",
      "Soft update 20520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 25\n",
      "Added episode 50\n",
      "Replay buf 25904\n",
      "Soft update 20560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 25\n",
      "Added episode 50\n",
      "Replay buf 25954\n",
      "Soft update 20600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 25\n",
      "Added episode 50\n",
      "Replay buf 26004\n",
      "Soft update 20640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 25\n",
      "Added episode 50\n",
      "Replay buf 26054\n",
      "Soft update 20680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 25\n",
      "Added episode 50\n",
      "Replay buf 26104\n",
      "Soft update 20720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 25\n",
      "Added episode 50\n",
      "Replay buf 26154\n",
      "Soft update 20760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:46:33.160598 EEST | [final-sideways-pixels-final-31] Epoch 25 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.222556\n",
      "trainer/Policy Loss                                              0.00674812\n",
      "trainer/Raw Policy Loss                                          0.00674812\n",
      "trainer/State estimation loss                                    0.0039706\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -6.97105\n",
      "trainer/Q Predictions Std                                        7.17571\n",
      "trainer/Q Predictions Max                                        3.03066\n",
      "trainer/Q Predictions Min                                      -21.5186\n",
      "trainer/Q Targets Mean                                          -6.88258\n",
      "trainer/Q Targets Std                                            7.19987\n",
      "trainer/Q Targets Max                                            3.05396\n",
      "trainer/Q Targets Min                                          -21.3891\n",
      "trainer/Bellman Errors Mean                                      0.222556\n",
      "trainer/Bellman Errors Std                                       0.799637\n",
      "trainer/Bellman Errors Max                                      19.9831\n",
      "trainer/Bellman Errors Min                                       2.27118e-07\n",
      "trainer/Policy Action Mean                                      -0.137998\n",
      "trainer/Policy Action Std                                        0.682026\n",
      "trainer/Policy Action Max                                        0.999999\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  26154\n",
      "exploration/num paths total                                    528\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.162592\n",
      "exploration/Actions Std                                          0.660178\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   13080\n",
      "evaluation/num paths total                                     268\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.0829907\n",
      "evaluation/Actions Std                                           0.671867\n",
      "evaluation/Actions Max                                           0.999978\n",
      "evaluation/Actions Min                                          -0.999999\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.107083\n",
      "time/evaluation sampling (s)                                    17.5964\n",
      "time/exploration sampling (s)                                   33.4222\n",
      "time/logging (s)                                                 0.00683185\n",
      "time/saving (s)                                                  0.0711516\n",
      "time/training (s)                                              198.121\n",
      "time/epoch (s)                                                 249.324\n",
      "time/total (s)                                                6831.47\n",
      "Epoch                                                           25\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 26\n",
      "\n",
      " Cycle 0 26\n",
      "Added episode 50\n",
      "Replay buf 26204\n",
      "Soft update 20800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 26\n",
      "Added episode 50\n",
      "Replay buf 26254\n",
      "Soft update 20840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 26\n",
      "Added episode 50\n",
      "Replay buf 26304\n",
      "Soft update 20880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 26\n",
      "Added episode 50\n",
      "Replay buf 26354\n",
      "Soft update 20920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 26\n",
      "Added episode 50\n",
      "Replay buf 26404\n",
      "Soft update 20960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 26\n",
      "Added episode 50\n",
      "Replay buf 26454\n",
      "Soft update 21000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 26\n",
      "Added episode 50\n",
      "Replay buf 26504\n",
      "Soft update 21040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 26\n",
      "Added episode 50\n",
      "Replay buf 26554\n",
      "Soft update 21080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 26\n",
      "Added episode 50\n",
      "Replay buf 26604\n",
      "Soft update 21120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 26\n",
      "Added episode 50\n",
      "Replay buf 26654\n",
      "Soft update 21160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 26\n",
      "Added episode 50\n",
      "Replay buf 26704\n",
      "Soft update 21200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 26\n",
      "Added episode 50\n",
      "Replay buf 26754\n",
      "Soft update 21240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 26\n",
      "Added episode 50\n",
      "Replay buf 26804\n",
      "Soft update 21280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 26\n",
      "Added episode 50\n",
      "Replay buf 26854\n",
      "Soft update 21320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 26\n",
      "Added episode 50\n",
      "Replay buf 26904\n",
      "Soft update 21360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 26\n",
      "Added episode 50\n",
      "Replay buf 26954\n",
      "Soft update 21400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 26\n",
      "Added episode 50\n",
      "Replay buf 27004\n",
      "Soft update 21440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 26\n",
      "Added episode 50\n",
      "Replay buf 27054\n",
      "Soft update 21480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 26\n",
      "Added episode 50\n",
      "Replay buf 27104\n",
      "Soft update 21520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 26\n",
      "Added episode 50\n",
      "Replay buf 27154\n",
      "Soft update 21560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:50:41.340970 EEST | [final-sideways-pixels-final-31] Epoch 26 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.162605\n",
      "trainer/Policy Loss                                              0.00683733\n",
      "trainer/Raw Policy Loss                                          0.00683733\n",
      "trainer/State estimation loss                                    0.00360191\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -6.96932\n",
      "trainer/Q Predictions Std                                        7.55483\n",
      "trainer/Q Predictions Max                                        2.60553\n",
      "trainer/Q Predictions Min                                      -22.7185\n",
      "trainer/Q Targets Mean                                          -6.95599\n",
      "trainer/Q Targets Std                                            7.60359\n",
      "trainer/Q Targets Max                                            2.71952\n",
      "trainer/Q Targets Min                                          -22.9056\n",
      "trainer/Bellman Errors Mean                                      0.162605\n",
      "trainer/Bellman Errors Std                                       0.511213\n",
      "trainer/Bellman Errors Max                                       9.71573\n",
      "trainer/Bellman Errors Min                                       6.76579e-11\n",
      "trainer/Policy Action Mean                                      -0.187161\n",
      "trainer/Policy Action Std                                        0.653152\n",
      "trainer/Policy Action Max                                        0.999999\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  27154\n",
      "exploration/num paths total                                    548\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.223491\n",
      "exploration/Actions Std                                          0.655819\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   13580\n",
      "evaluation/num paths total                                     278\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.126109\n",
      "evaluation/Actions Std                                           0.631654\n",
      "evaluation/Actions Max                                           0.999999\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.108765\n",
      "time/evaluation sampling (s)                                    17.1999\n",
      "time/exploration sampling (s)                                   32.5985\n",
      "time/logging (s)                                                 0.00672775\n",
      "time/saving (s)                                                  0.0706801\n",
      "time/training (s)                                              198.191\n",
      "time/epoch (s)                                                 248.175\n",
      "time/total (s)                                                7079.65\n",
      "Epoch                                                           26\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 27\n",
      "\n",
      " Cycle 0 27\n",
      "Added episode 50\n",
      "Replay buf 27204\n",
      "Soft update 21600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 27\n",
      "Added episode 50\n",
      "Replay buf 27254\n",
      "Soft update 21640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 27\n",
      "Added episode 50\n",
      "Replay buf 27304\n",
      "Soft update 21680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 27\n",
      "Added episode 50\n",
      "Replay buf 27354\n",
      "Soft update 21720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 27\n",
      "Added episode 50\n",
      "Replay buf 27404\n",
      "Soft update 21760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 27\n",
      "Added episode 50\n",
      "Replay buf 27454\n",
      "Soft update 21800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 27\n",
      "Added episode 50\n",
      "Replay buf 27504\n",
      "Soft update 21840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 27\n",
      "Added episode 50\n",
      "Replay buf 27554\n",
      "Soft update 21880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 27\n",
      "Added episode 50\n",
      "Replay buf 27604\n",
      "Soft update 21920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 27\n",
      "Added episode 50\n",
      "Replay buf 27654\n",
      "Soft update 21960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 27\n",
      "Added episode 50\n",
      "Replay buf 27704\n",
      "Soft update 22000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 27\n",
      "Added episode 50\n",
      "Replay buf 27754\n",
      "Soft update 22040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 27\n",
      "Added episode 50\n",
      "Replay buf 27804\n",
      "Soft update 22080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 27\n",
      "Added episode 50\n",
      "Replay buf 27854\n",
      "Soft update 22120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 27\n",
      "Added episode 50\n",
      "Replay buf 27904\n",
      "Soft update 22160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 27\n",
      "Added episode 50\n",
      "Replay buf 27954\n",
      "Soft update 22200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 27\n",
      "Added episode 50\n",
      "Replay buf 28004\n",
      "Soft update 22240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 27\n",
      "Added episode 50\n",
      "Replay buf 28054\n",
      "Soft update 22280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 27\n",
      "Added episode 50\n",
      "Replay buf 28104\n",
      "Soft update 22320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 27\n",
      "Added episode 50\n",
      "Replay buf 28154\n",
      "Soft update 22360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:54:47.655779 EEST | [final-sideways-pixels-final-31] Epoch 27 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.200861\n",
      "trainer/Policy Loss                                              0.00682276\n",
      "trainer/Raw Policy Loss                                          0.00682276\n",
      "trainer/State estimation loss                                    0.00372473\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -7.03835\n",
      "trainer/Q Predictions Std                                        7.70201\n",
      "trainer/Q Predictions Max                                        3.25254\n",
      "trainer/Q Predictions Min                                      -23.7007\n",
      "trainer/Q Targets Mean                                          -7.16826\n",
      "trainer/Q Targets Std                                            7.71365\n",
      "trainer/Q Targets Max                                            3.27375\n",
      "trainer/Q Targets Min                                          -23.8618\n",
      "trainer/Bellman Errors Mean                                      0.200861\n",
      "trainer/Bellman Errors Std                                       0.501874\n",
      "trainer/Bellman Errors Max                                       7.71523\n",
      "trainer/Bellman Errors Min                                       7.30564e-09\n",
      "trainer/Policy Action Mean                                      -0.163125\n",
      "trainer/Policy Action Std                                        0.652493\n",
      "trainer/Policy Action Max                                        0.999998\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  28154\n",
      "exploration/num paths total                                    568\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.210374\n",
      "exploration/Actions Std                                          0.630078\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   14080\n",
      "evaluation/num paths total                                     288\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.195311\n",
      "evaluation/Actions Std                                           0.635301\n",
      "evaluation/Actions Max                                           0.999997\n",
      "evaluation/Actions Min                                          -0.999999\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.10469\n",
      "time/evaluation sampling (s)                                    16.5826\n",
      "time/exploration sampling (s)                                   32.767\n",
      "time/logging (s)                                                 0.00676238\n",
      "time/saving (s)                                                  0.0711525\n",
      "time/training (s)                                              196.777\n",
      "time/epoch (s)                                                 246.31\n",
      "time/total (s)                                                7325.96\n",
      "Epoch                                                           27\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 28\n",
      "\n",
      " Cycle 0 28\n",
      "Added episode 50\n",
      "Replay buf 28204\n",
      "Soft update 22400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 28\n",
      "Added episode 50\n",
      "Replay buf 28254\n",
      "Soft update 22440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 28\n",
      "Added episode 50\n",
      "Replay buf 28304\n",
      "Soft update 22480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 28\n",
      "Added episode 50\n",
      "Replay buf 28354\n",
      "Soft update 22520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 28\n",
      "Added episode 50\n",
      "Replay buf 28404\n",
      "Soft update 22560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 28\n",
      "Added episode 50\n",
      "Replay buf 28454\n",
      "Soft update 22600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 28\n",
      "Added episode 50\n",
      "Replay buf 28504\n",
      "Soft update 22640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 28\n",
      "Added episode 50\n",
      "Replay buf 28554\n",
      "Soft update 22680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 28\n",
      "Added episode 50\n",
      "Replay buf 28604\n",
      "Soft update 22720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 28\n",
      "Added episode 50\n",
      "Replay buf 28654\n",
      "Soft update 22760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 28\n",
      "Added episode 50\n",
      "Replay buf 28704\n",
      "Soft update 22800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 28\n",
      "Added episode 50\n",
      "Replay buf 28754\n",
      "Soft update 22840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 28\n",
      "Added episode 50\n",
      "Replay buf 28804\n",
      "Soft update 22880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 28\n",
      "Added episode 50\n",
      "Replay buf 28854\n",
      "Soft update 22920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 28\n",
      "Added episode 50\n",
      "Replay buf 28904\n",
      "Soft update 22960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 28\n",
      "Added episode 50\n",
      "Replay buf 28954\n",
      "Soft update 23000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 28\n",
      "Added episode 50\n",
      "Replay buf 29004\n",
      "Soft update 23040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 28\n",
      "Added episode 50\n",
      "Replay buf 29054\n",
      "Soft update 23080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 28\n",
      "Added episode 50\n",
      "Replay buf 29104\n",
      "Soft update 23120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 28\n",
      "Added episode 50\n",
      "Replay buf 29154\n",
      "Soft update 23160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 10:58:54.076178 EEST | [final-sideways-pixels-final-31] Epoch 28 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.2782\n",
      "trainer/Policy Loss                                              0.00711659\n",
      "trainer/Raw Policy Loss                                          0.00711659\n",
      "trainer/State estimation loss                                    0.00394231\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -7.2999\n",
      "trainer/Q Predictions Std                                        8.10332\n",
      "trainer/Q Predictions Max                                        2.99493\n",
      "trainer/Q Predictions Min                                      -25.2568\n",
      "trainer/Q Targets Mean                                          -7.2701\n",
      "trainer/Q Targets Std                                            8.07755\n",
      "trainer/Q Targets Max                                            3.26312\n",
      "trainer/Q Targets Min                                          -25.342\n",
      "trainer/Bellman Errors Mean                                      0.2782\n",
      "trainer/Bellman Errors Std                                       2.78578\n",
      "trainer/Bellman Errors Max                                      91.2174\n",
      "trainer/Bellman Errors Min                                       8.80519e-07\n",
      "trainer/Policy Action Mean                                      -0.16031\n",
      "trainer/Policy Action Std                                        0.649702\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  29154\n",
      "exploration/num paths total                                    588\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.211035\n",
      "exploration/Actions Std                                          0.621472\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   14580\n",
      "evaluation/num paths total                                     298\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.177754\n",
      "evaluation/Actions Std                                           0.678349\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.106283\n",
      "time/evaluation sampling (s)                                    17.0292\n",
      "time/exploration sampling (s)                                   31.7923\n",
      "time/logging (s)                                                 0.00681973\n",
      "time/saving (s)                                                  0.0717635\n",
      "time/training (s)                                              197.409\n",
      "time/epoch (s)                                                 246.415\n",
      "time/total (s)                                                7572.38\n",
      "Epoch                                                           28\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 29\n",
      "\n",
      " Cycle 0 29\n",
      "Added episode 50\n",
      "Replay buf 29204\n",
      "Soft update 23200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 29\n",
      "Added episode 50\n",
      "Replay buf 29254\n",
      "Soft update 23240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 29\n",
      "Added episode 50\n",
      "Replay buf 29304\n",
      "Soft update 23280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 29\n",
      "Added episode 50\n",
      "Replay buf 29354\n",
      "Soft update 23320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 29\n",
      "Added episode 50\n",
      "Replay buf 29404\n",
      "Soft update 23360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 29\n",
      "Added episode 50\n",
      "Replay buf 29454\n",
      "Soft update 23400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 29\n",
      "Added episode 50\n",
      "Replay buf 29504\n",
      "Soft update 23440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 29\n",
      "Added episode 50\n",
      "Replay buf 29554\n",
      "Soft update 23480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 29\n",
      "Added episode 50\n",
      "Replay buf 29604\n",
      "Soft update 23520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 29\n",
      "Added episode 50\n",
      "Replay buf 29654\n",
      "Soft update 23560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 29\n",
      "Added episode 50\n",
      "Replay buf 29704\n",
      "Soft update 23600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 29\n",
      "Added episode 50\n",
      "Replay buf 29754\n",
      "Soft update 23640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 29\n",
      "Added episode 50\n",
      "Replay buf 29804\n",
      "Soft update 23680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 29\n",
      "Added episode 50\n",
      "Replay buf 29854\n",
      "Soft update 23720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 29\n",
      "Added episode 50\n",
      "Replay buf 29904\n",
      "Soft update 23760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 29\n",
      "Added episode 50\n",
      "Replay buf 29954\n",
      "Soft update 23800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 29\n",
      "Added episode 50\n",
      "Replay buf 30004\n",
      "Soft update 23840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 29\n",
      "Added episode 50\n",
      "Replay buf 30054\n",
      "Soft update 23880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 29\n",
      "Added episode 50\n",
      "Replay buf 30104\n",
      "Soft update 23920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 29\n",
      "Added episode 50\n",
      "Replay buf 30154\n",
      "Soft update 23960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:03:00.019553 EEST | [final-sideways-pixels-final-31] Epoch 29 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.242764\n",
      "trainer/Policy Loss                                              0.00711853\n",
      "trainer/Raw Policy Loss                                          0.00711853\n",
      "trainer/State estimation loss                                    0.00361514\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -7.32733\n",
      "trainer/Q Predictions Std                                        8.30299\n",
      "trainer/Q Predictions Max                                        2.27638\n",
      "trainer/Q Predictions Min                                      -27.1143\n",
      "trainer/Q Targets Mean                                          -7.36123\n",
      "trainer/Q Targets Std                                            8.2682\n",
      "trainer/Q Targets Max                                            2.48465\n",
      "trainer/Q Targets Min                                          -26.8339\n",
      "trainer/Bellman Errors Mean                                      0.242764\n",
      "trainer/Bellman Errors Std                                       0.617885\n",
      "trainer/Bellman Errors Max                                       7.79909\n",
      "trainer/Bellman Errors Min                                       9.54751e-08\n",
      "trainer/Policy Action Mean                                      -0.142782\n",
      "trainer/Policy Action Std                                        0.653906\n",
      "trainer/Policy Action Max                                        0.999994\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  30154\n",
      "exploration/num paths total                                    608\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.176394\n",
      "exploration/Actions Std                                          0.634466\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   15080\n",
      "evaluation/num paths total                                     308\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.298067\n",
      "evaluation/Actions Std                                           0.556873\n",
      "evaluation/Actions Max                                           0.999998\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.103431\n",
      "time/evaluation sampling (s)                                    16.2428\n",
      "time/exploration sampling (s)                                   32.0581\n",
      "time/logging (s)                                                 0.00725205\n",
      "time/saving (s)                                                  0.073707\n",
      "time/training (s)                                              197.453\n",
      "time/epoch (s)                                                 245.939\n",
      "time/total (s)                                                7818.32\n",
      "Epoch                                                           29\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 30\n",
      "\n",
      " Cycle 0 30\n",
      "Added episode 50\n",
      "Replay buf 30204\n",
      "Soft update 24000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 30\n",
      "Added episode 50\n",
      "Replay buf 30254\n",
      "Soft update 24040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 30\n",
      "Added episode 50\n",
      "Replay buf 30304\n",
      "Soft update 24080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 30\n",
      "Added episode 50\n",
      "Replay buf 30354\n",
      "Soft update 24120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 30\n",
      "Added episode 50\n",
      "Replay buf 30404\n",
      "Soft update 24160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 30\n",
      "Added episode 50\n",
      "Replay buf 30454\n",
      "Soft update 24200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 30\n",
      "Added episode 50\n",
      "Replay buf 30504\n",
      "Soft update 24240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 30\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 30566\n",
      "Soft update 24280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 30\n",
      "Added episode 50\n",
      "Replay buf 30616\n",
      "Soft update 24320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 30\n",
      "Added episode 50\n",
      "Replay buf 30666\n",
      "Soft update 24360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 30\n",
      "Added episode 50\n",
      "Replay buf 30716\n",
      "Soft update 24400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 30\n",
      "Added episode 50\n",
      "Replay buf 30766\n",
      "Soft update 24440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 30\n",
      "Added episode 50\n",
      "Replay buf 30816\n",
      "Soft update 24480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 30\n",
      "Added episode 50\n",
      "Replay buf 30866\n",
      "Soft update 24520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 30\n",
      "Added episode 50\n",
      "Replay buf 30916\n",
      "Soft update 24560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 30\n",
      "Added episode 50\n",
      "Replay buf 30966\n",
      "Soft update 24600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 30\n",
      "Added episode 50\n",
      "Replay buf 31016\n",
      "Soft update 24640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 30\n",
      "Added episode 50\n",
      "Replay buf 31066\n",
      "Soft update 24680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 30\n",
      "Added episode 50\n",
      "Replay buf 31116\n",
      "Soft update 24720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 30\n",
      "Added episode 50\n",
      "Replay buf 31166\n",
      "Soft update 24760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:07:07.793947 EEST | [final-sideways-pixels-final-31] Epoch 30 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.266335\n",
      "trainer/Policy Loss                                              0.00715773\n",
      "trainer/Raw Policy Loss                                          0.00715773\n",
      "trainer/State estimation loss                                    0.00394749\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -7.34172\n",
      "trainer/Q Predictions Std                                        8.46079\n",
      "trainer/Q Predictions Max                                        2.58113\n",
      "trainer/Q Predictions Min                                      -26.7051\n",
      "trainer/Q Targets Mean                                          -7.36907\n",
      "trainer/Q Targets Std                                            8.50895\n",
      "trainer/Q Targets Max                                            2.87587\n",
      "trainer/Q Targets Min                                          -26.639\n",
      "trainer/Bellman Errors Mean                                      0.266335\n",
      "trainer/Bellman Errors Std                                       1.15209\n",
      "trainer/Bellman Errors Max                                      26.1047\n",
      "trainer/Bellman Errors Min                                       2.83976e-06\n",
      "trainer/Policy Action Mean                                      -0.142417\n",
      "trainer/Policy Action Std                                        0.642667\n",
      "trainer/Policy Action Max                                        0.999996\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  31166\n",
      "exploration/num paths total                                    629\n",
      "exploration/path length Mean                                    48.1905\n",
      "exploration/path length Std                                      8.09244\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     12\n",
      "exploration/Rewards Mean                                        -0.999012\n",
      "exploration/Rewards Std                                          0.0314192\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -48.1429\n",
      "exploration/Returns Std                                          8.3054\n",
      "exploration/Returns Max                                        -11\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.1601\n",
      "exploration/Actions Std                                          0.618269\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           21\n",
      "exploration/Average Returns                                    -48.1429\n",
      "exploration/env_infos/final/is_success Mean                      0.0476191\n",
      "exploration/env_infos/final/is_success Std                       0.212959\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.000988142\n",
      "exploration/env_infos/is_success Std                             0.0314192\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   15580\n",
      "evaluation/num paths total                                     318\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.186518\n",
      "evaluation/Actions Std                                           0.60602\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -0.999999\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.106288\n",
      "time/evaluation sampling (s)                                    16.3122\n",
      "time/exploration sampling (s)                                   33.0156\n",
      "time/logging (s)                                                 0.00684833\n",
      "time/saving (s)                                                  0.0709832\n",
      "time/training (s)                                              198.255\n",
      "time/epoch (s)                                                 247.767\n",
      "time/total (s)                                                8066.1\n",
      "Epoch                                                           30\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 31\n",
      "\n",
      " Cycle 0 31\n",
      "Added episode 50\n",
      "Replay buf 31216\n",
      "Soft update 24800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 31\n",
      "Added episode 50\n",
      "Replay buf 31266\n",
      "Soft update 24840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 31\n",
      "Added episode 50\n",
      "Replay buf 31316\n",
      "Soft update 24880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 31\n",
      "Added episode 50\n",
      "Replay buf 31366\n",
      "Soft update 24920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 31\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 31428\n",
      "Soft update 24960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 31\n",
      "Added episode 50\n",
      "Replay buf 31478\n",
      "Soft update 25000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 31\n",
      "Added episode 50\n",
      "Replay buf 31528\n",
      "Soft update 25040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 31\n",
      "Added episode 50\n",
      "Replay buf 31578\n",
      "Soft update 25080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 31\n",
      "Added episode 50\n",
      "Replay buf 31628\n",
      "Soft update 25120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 31\n",
      "Added episode 50\n",
      "Replay buf 31678\n",
      "Soft update 25160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 31\n",
      "Added episode 50\n",
      "Replay buf 31728\n",
      "Soft update 25200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 31\n",
      "Added episode 50\n",
      "Replay buf 31778\n",
      "Soft update 25240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 31\n",
      "Added episode 50\n",
      "Replay buf 31828\n",
      "Soft update 25280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 31\n",
      "Added episode 50\n",
      "Replay buf 31878\n",
      "Soft update 25320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 31\n",
      "Added episode 50\n",
      "Replay buf 31928\n",
      "Soft update 25360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 31\n",
      "Added episode 50\n",
      "Replay buf 31978\n",
      "Soft update 25400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 31\n",
      "Added episode 50\n",
      "Replay buf 32028\n",
      "Soft update 25440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 31\n",
      "Added episode 50\n",
      "Replay buf 32078\n",
      "Soft update 25480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 31\n",
      "Added episode 50\n",
      "Replay buf 32128\n",
      "Soft update 25520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 31\n",
      "Added episode 50\n",
      "Replay buf 32178\n",
      "Soft update 25560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:11:15.232721 EEST | [final-sideways-pixels-final-31] Epoch 31 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.255871\n",
      "trainer/Policy Loss                                              0.00715747\n",
      "trainer/Raw Policy Loss                                          0.00715747\n",
      "trainer/State estimation loss                                    0.00364606\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -7.36475\n",
      "trainer/Q Predictions Std                                        8.79283\n",
      "trainer/Q Predictions Max                                        3.55224\n",
      "trainer/Q Predictions Min                                      -26.5561\n",
      "trainer/Q Targets Mean                                          -7.3263\n",
      "trainer/Q Targets Std                                            8.79685\n",
      "trainer/Q Targets Max                                            3.70512\n",
      "trainer/Q Targets Min                                          -26.3412\n",
      "trainer/Bellman Errors Mean                                      0.255871\n",
      "trainer/Bellman Errors Std                                       0.715532\n",
      "trainer/Bellman Errors Max                                      11.5334\n",
      "trainer/Bellman Errors Min                                       1.49012e-08\n",
      "trainer/Policy Action Mean                                      -0.206229\n",
      "trainer/Policy Action Std                                        0.67059\n",
      "trainer/Policy Action Max                                        0.999998\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  32178\n",
      "exploration/num paths total                                    650\n",
      "exploration/path length Mean                                    48.1905\n",
      "exploration/path length Std                                      8.09244\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     12\n",
      "exploration/Rewards Mean                                        -0.999012\n",
      "exploration/Rewards Std                                          0.0314192\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -48.1429\n",
      "exploration/Returns Std                                          8.3054\n",
      "exploration/Returns Max                                        -11\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.180527\n",
      "exploration/Actions Std                                          0.64188\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           21\n",
      "exploration/Average Returns                                    -48.1429\n",
      "exploration/env_infos/final/is_success Mean                      0.0476191\n",
      "exploration/env_infos/final/is_success Std                       0.212959\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.000988142\n",
      "exploration/env_infos/is_success Std                             0.0314192\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   16080\n",
      "evaluation/num paths total                                     328\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.307522\n",
      "evaluation/Actions Std                                           0.630922\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.108264\n",
      "time/evaluation sampling (s)                                    16.3182\n",
      "time/exploration sampling (s)                                   32.7957\n",
      "time/logging (s)                                                 0.00684062\n",
      "time/saving (s)                                                  0.0710812\n",
      "time/training (s)                                              198.134\n",
      "time/epoch (s)                                                 247.434\n",
      "time/total (s)                                                8313.53\n",
      "Epoch                                                           31\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 32\n",
      "\n",
      " Cycle 0 32\n",
      "Added episode 50\n",
      "Replay buf 32228\n",
      "Soft update 25600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 32\n",
      "Added episode 50\n",
      "Replay buf 32278\n",
      "Soft update 25640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 32\n",
      "Added episode 50\n",
      "Replay buf 32328\n",
      "Soft update 25680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 32\n",
      "Added episode 50\n",
      "Replay buf 32378\n",
      "Soft update 25720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 32\n",
      "Added episode 50\n",
      "Replay buf 32428\n",
      "Soft update 25760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 32\n",
      "Added episode 50\n",
      "Replay buf 32478\n",
      "Soft update 25800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 32\n",
      "Added episode 50\n",
      "Replay buf 32528\n",
      "Soft update 25840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 32\n",
      "Added episode 50\n",
      "Replay buf 32578\n",
      "Soft update 25880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 32\n",
      "Added episode 50\n",
      "Replay buf 32628\n",
      "Soft update 25920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 32\n",
      "Added episode 50\n",
      "Replay buf 32678\n",
      "Soft update 25960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 32\n",
      "Added episode 50\n",
      "Replay buf 32728\n",
      "Soft update 26000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 32\n",
      "Added episode 50\n",
      "Replay buf 32778\n",
      "Soft update 26040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 32\n",
      "Added episode 50\n",
      "Replay buf 32828\n",
      "Soft update 26080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 32\n",
      "Added episode 50\n",
      "Replay buf 32878\n",
      "Soft update 26120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 32\n",
      "Added episode 50\n",
      "Replay buf 32928\n",
      "Soft update 26160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 32\n",
      "Added episode 50\n",
      "Replay buf 32978\n",
      "Soft update 26200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 32\n",
      "Added episode 50\n",
      "Replay buf 33028\n",
      "Soft update 26240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 32\n",
      "Added episode 50\n",
      "Replay buf 33078\n",
      "Soft update 26280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 32\n",
      "Added episode 50\n",
      "Replay buf 33128\n",
      "Soft update 26320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 32\n",
      "Added episode 50\n",
      "Replay buf 33178\n",
      "Soft update 26360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:15:22.702521 EEST | [final-sideways-pixels-final-31] Epoch 32 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                  0.274939\n",
      "trainer/Policy Loss                                              0.00747459\n",
      "trainer/Raw Policy Loss                                          0.00747459\n",
      "trainer/State estimation loss                                    0.00368461\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -7.72377\n",
      "trainer/Q Predictions Std                                        9.11855\n",
      "trainer/Q Predictions Max                                        3.34478\n",
      "trainer/Q Predictions Min                                      -28.4172\n",
      "trainer/Q Targets Mean                                          -7.60444\n",
      "trainer/Q Targets Std                                            9.05012\n",
      "trainer/Q Targets Max                                            3.56253\n",
      "trainer/Q Targets Min                                          -28.6291\n",
      "trainer/Bellman Errors Mean                                      0.274939\n",
      "trainer/Bellman Errors Std                                       0.912442\n",
      "trainer/Bellman Errors Max                                      22.7973\n",
      "trainer/Bellman Errors Min                                       1.4056e-07\n",
      "trainer/Policy Action Mean                                      -0.160727\n",
      "trainer/Policy Action Std                                        0.658805\n",
      "trainer/Policy Action Max                                        0.999999\n",
      "trainer/Policy Action Min                                       -0.999999\n",
      "exploration/num steps total                                  33178\n",
      "exploration/num paths total                                    670\n",
      "exploration/path length Mean                                    50\n",
      "exploration/path length Std                                      0\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     50\n",
      "exploration/Rewards Mean                                        -1\n",
      "exploration/Rewards Std                                          0\n",
      "exploration/Rewards Max                                         -1\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -50\n",
      "exploration/Returns Std                                          0\n",
      "exploration/Returns Max                                        -50\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.178258\n",
      "exploration/Actions Std                                          0.618183\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           20\n",
      "exploration/Average Returns                                    -50\n",
      "exploration/env_infos/final/is_success Mean                      0\n",
      "exploration/env_infos/final/is_success Std                       0\n",
      "exploration/env_infos/final/is_success Max                       0\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0\n",
      "exploration/env_infos/is_success Std                             0\n",
      "exploration/env_infos/is_success Max                             0\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   16580\n",
      "evaluation/num paths total                                     338\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.200248\n",
      "evaluation/Actions Std                                           0.611295\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -0.999999\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.104803\n",
      "time/evaluation sampling (s)                                    16.6863\n",
      "time/exploration sampling (s)                                   32.8819\n",
      "time/logging (s)                                                 0.00683465\n",
      "time/saving (s)                                                  0.0710778\n",
      "time/training (s)                                              197.714\n",
      "time/epoch (s)                                                 247.465\n",
      "time/total (s)                                                8561\n",
      "Epoch                                                           32\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 33\n",
      "\n",
      " Cycle 0 33\n",
      "Added episode 50\n",
      "Replay buf 33228\n",
      "Soft update 26400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 33\n",
      "Added episode 50\n",
      "Replay buf 33278\n",
      "Soft update 26440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 33\n",
      "Added episode 50\n",
      "Replay buf 33328\n",
      "Soft update 26480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 33\n",
      "Added episode 50\n",
      "Replay buf 33378\n",
      "Soft update 26520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 33\n",
      "Added episode 50\n",
      "Replay buf 33428\n",
      "Soft update 26560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 33\n",
      "Added episode 50\n",
      "Replay buf 33478\n",
      "Soft update 26600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 33\n",
      "Added episode 50\n",
      "Replay buf 33528\n",
      "Soft update 26640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 33\n",
      "Added episode 50\n",
      "Replay buf 33578\n",
      "Soft update 26680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 33\n",
      "Added episode 50\n",
      "Replay buf 33628\n",
      "Soft update 26720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 33\n",
      "Added episode 50\n",
      "Replay buf 33678\n",
      "Soft update 26760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 33\n",
      "Added episode 50\n",
      "Replay buf 33728\n",
      "Soft update 26800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 33\n",
      "Added episode 50\n",
      "Replay buf 33778\n",
      "Soft update 26840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 33\n",
      "Added episode 50\n",
      "Replay buf 33828\n",
      "Soft update 26880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 33\n",
      "Added episode 50\n",
      "Replay buf 33878\n",
      "Soft update 26920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 33\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 21\n",
      "Added episode 50\n",
      "Replay buf 33949\n",
      "Soft update 26960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 33\n",
      "Added episode 50\n",
      "Replay buf 33999\n",
      "Soft update 27000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 33\n",
      "Added episode 50\n",
      "Replay buf 34049\n",
      "Soft update 27040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 33\n",
      "Added episode 50\n",
      "Replay buf 34099\n",
      "Soft update 27080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 33\n",
      "Added episode 50\n",
      "Replay buf 34149\n",
      "Soft update 27120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 33\n",
      "Added episode 50\n",
      "Replay buf 34199\n",
      "Soft update 27160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:19:30.132094 EEST | [final-sideways-pixels-final-31] Epoch 33 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.249242\n",
      "trainer/Policy Loss                                              0.00728142\n",
      "trainer/Raw Policy Loss                                          0.00728142\n",
      "trainer/State estimation loss                                    0.00382731\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -7.48316\n",
      "trainer/Q Predictions Std                                        9.20843\n",
      "trainer/Q Predictions Max                                        3.29507\n",
      "trainer/Q Predictions Min                                      -27.9204\n",
      "trainer/Q Targets Mean                                          -7.58056\n",
      "trainer/Q Targets Std                                            9.2272\n",
      "trainer/Q Targets Max                                            3.01313\n",
      "trainer/Q Targets Min                                          -27.825\n",
      "trainer/Bellman Errors Mean                                      0.249242\n",
      "trainer/Bellman Errors Std                                       0.807129\n",
      "trainer/Bellman Errors Max                                      18.9338\n",
      "trainer/Bellman Errors Min                                       7.26054e-08\n",
      "trainer/Policy Action Mean                                      -0.205465\n",
      "trainer/Policy Action Std                                        0.653603\n",
      "trainer/Policy Action Max                                        0.999998\n",
      "trainer/Policy Action Min                                       -0.999999\n",
      "exploration/num steps total                                  34199\n",
      "exploration/num paths total                                    691\n",
      "exploration/path length Mean                                    48.619\n",
      "exploration/path length Std                                      6.17581\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     21\n",
      "exploration/Rewards Mean                                        -0.999021\n",
      "exploration/Rewards Std                                          0.0312805\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -48.5714\n",
      "exploration/Returns Std                                          6.38877\n",
      "exploration/Returns Max                                        -20\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.165543\n",
      "exploration/Actions Std                                          0.617374\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           21\n",
      "exploration/Average Returns                                    -48.5714\n",
      "exploration/env_infos/final/is_success Mean                      0.0476191\n",
      "exploration/env_infos/final/is_success Std                       0.212959\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.000979432\n",
      "exploration/env_infos/is_success Std                             0.0312805\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   17080\n",
      "evaluation/num paths total                                     348\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.291502\n",
      "evaluation/Actions Std                                           0.596265\n",
      "evaluation/Actions Max                                           0.999999\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.107038\n",
      "time/evaluation sampling (s)                                    16.2463\n",
      "time/exploration sampling (s)                                   33.3328\n",
      "time/logging (s)                                                 0.00691665\n",
      "time/saving (s)                                                  0.070319\n",
      "time/training (s)                                              197.661\n",
      "time/epoch (s)                                                 247.424\n",
      "time/total (s)                                                8808.43\n",
      "Epoch                                                           33\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 34\n",
      "\n",
      " Cycle 0 34\n",
      "Added episode 50\n",
      "Replay buf 34249\n",
      "Soft update 27200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 34\n",
      "Added episode 50\n",
      "Replay buf 34299\n",
      "Soft update 27240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 34\n",
      "Added episode 50\n",
      "Replay buf 34349\n",
      "Soft update 27280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 34\n",
      "Added episode 50\n",
      "Replay buf 34399\n",
      "Soft update 27320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 34\n",
      "Added episode 50\n",
      "Replay buf 34449\n",
      "Soft update 27360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 34\n",
      "Added episode 50\n",
      "Replay buf 34499\n",
      "Soft update 27400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 34\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 34559\n",
      "Soft update 27440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 34\n",
      "Added episode 50\n",
      "Replay buf 34609\n",
      "Soft update 27480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 34\n",
      "Added episode 50\n",
      "Replay buf 34659\n",
      "Soft update 27520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 34\n",
      "Added episode 50\n",
      "Replay buf 34709\n",
      "Soft update 27560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 34\n",
      "Added episode 50\n",
      "Replay buf 34759\n",
      "Soft update 27600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 34\n",
      "Added episode 50\n",
      "Replay buf 34809\n",
      "Soft update 27640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 34\n",
      "Added episode 50\n",
      "Replay buf 34859\n",
      "Soft update 27680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 34\n",
      "Added episode 50\n",
      "Replay buf 34909\n",
      "Soft update 27720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 34\n",
      "Added episode 50\n",
      "Replay buf 34959\n",
      "Soft update 27760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 34\n",
      "Added episode 50\n",
      "Replay buf 35009\n",
      "Soft update 27800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 34\n",
      "Added episode 50\n",
      "Replay buf 35059\n",
      "Soft update 27840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 34\n",
      "Added episode 50\n",
      "Replay buf 35109\n",
      "Soft update 27880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 34\n",
      "Added episode 50\n",
      "Replay buf 35159\n",
      "Soft update 27920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 34\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 35219\n",
      "Soft update 27960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:23:38.564990 EEST | [final-sideways-pixels-final-31] Epoch 34 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.321243\n",
      "trainer/Policy Loss                                              0.00765257\n",
      "trainer/Raw Policy Loss                                          0.00765257\n",
      "trainer/State estimation loss                                    0.00395007\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -7.87273\n",
      "trainer/Q Predictions Std                                        9.44543\n",
      "trainer/Q Predictions Max                                        3.5962\n",
      "trainer/Q Predictions Min                                      -29.0365\n",
      "trainer/Q Targets Mean                                          -7.92962\n",
      "trainer/Q Targets Std                                            9.38986\n",
      "trainer/Q Targets Max                                            3.50597\n",
      "trainer/Q Targets Min                                          -28.7992\n",
      "trainer/Bellman Errors Mean                                      0.321243\n",
      "trainer/Bellman Errors Std                                       1.20017\n",
      "trainer/Bellman Errors Max                                      25.8184\n",
      "trainer/Bellman Errors Min                                       4.24334e-08\n",
      "trainer/Policy Action Mean                                      -0.10127\n",
      "trainer/Policy Action Std                                        0.676161\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  35219\n",
      "exploration/num paths total                                    713\n",
      "exploration/path length Mean                                    46.3636\n",
      "exploration/path length Std                                     11.4992\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.998039\n",
      "exploration/Rewards Std                                          0.0442373\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -46.2727\n",
      "exploration/Returns Std                                         11.7867\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.172148\n",
      "exploration/Actions Std                                          0.611352\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           22\n",
      "exploration/Average Returns                                    -46.2727\n",
      "exploration/env_infos/final/is_success Mean                      0.0909091\n",
      "exploration/env_infos/final/is_success Std                       0.28748\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00196078\n",
      "exploration/env_infos/is_success Std                             0.0442373\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   17580\n",
      "evaluation/num paths total                                     358\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.11234\n",
      "evaluation/Actions Std                                           0.605618\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.109396\n",
      "time/evaluation sampling (s)                                    16.8085\n",
      "time/exploration sampling (s)                                   33.6946\n",
      "time/logging (s)                                                 0.00692278\n",
      "time/saving (s)                                                  0.0702545\n",
      "time/training (s)                                              197.738\n",
      "time/epoch (s)                                                 248.428\n",
      "time/total (s)                                                9056.86\n",
      "Epoch                                                           34\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 35\n",
      "\n",
      " Cycle 0 35\n",
      "Added episode 50\n",
      "Replay buf 35269\n",
      "Soft update 28000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 35\n",
      "Added episode 50\n",
      "Replay buf 35319\n",
      "Soft update 28040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 35\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 50\n",
      "Replay buf 35385\n",
      "Soft update 28080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 35\n",
      "Added episode 50\n",
      "Replay buf 35435\n",
      "Soft update 28120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 35\n",
      "Added episode 50\n",
      "Replay buf 35485\n",
      "Soft update 28160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 35\n",
      "Added episode 50\n",
      "Replay buf 35535\n",
      "Soft update 28200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 35\n",
      "Added episode 50\n",
      "Replay buf 35585\n",
      "Soft update 28240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 35\n",
      "Added episode 50\n",
      "Replay buf 35635\n",
      "Soft update 28280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 35\n",
      "Added episode 50\n",
      "Replay buf 35685\n",
      "Soft update 28320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 35\n",
      "Added episode 50\n",
      "Replay buf 35735\n",
      "Soft update 28360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 35\n",
      "Added episode 50\n",
      "Replay buf 35785\n",
      "Soft update 28400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 35\n",
      "Added episode 50\n",
      "Replay buf 35835\n",
      "Soft update 28440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 35\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 35894\n",
      "Soft update 28480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 35\n",
      "Added episode 50\n",
      "Replay buf 35944\n",
      "Soft update 28520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 35\n",
      "Added episode 50\n",
      "Replay buf 35994\n",
      "Soft update 28560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 35\n",
      "Added episode 50\n",
      "Replay buf 36044\n",
      "Soft update 28600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 35\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 36105\n",
      "Soft update 28640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 35\n",
      "Added episode 50\n",
      "Replay buf 36155\n",
      "Soft update 28680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 35\n",
      "Added episode 50\n",
      "Replay buf 36205\n",
      "Soft update 28720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 35\n",
      "Added episode 50\n",
      "Replay buf 36255\n",
      "Soft update 28760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:27:46.235313 EEST | [final-sideways-pixels-final-31] Epoch 35 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.359322\n",
      "trainer/Policy Loss                                              0.00804126\n",
      "trainer/Raw Policy Loss                                          0.00804126\n",
      "trainer/State estimation loss                                    0.00383562\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.14914\n",
      "trainer/Q Predictions Std                                        9.68799\n",
      "trainer/Q Predictions Max                                        3.29906\n",
      "trainer/Q Predictions Min                                      -30.2143\n",
      "trainer/Q Targets Mean                                          -8.03597\n",
      "trainer/Q Targets Std                                            9.60537\n",
      "trainer/Q Targets Max                                            3.5952\n",
      "trainer/Q Targets Min                                          -29.7883\n",
      "trainer/Bellman Errors Mean                                      0.359322\n",
      "trainer/Bellman Errors Std                                       1.04325\n",
      "trainer/Bellman Errors Max                                      14.9829\n",
      "trainer/Bellman Errors Min                                       8.93872e-08\n",
      "trainer/Policy Action Mean                                      -0.173367\n",
      "trainer/Policy Action Std                                        0.638241\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  36255\n",
      "exploration/num paths total                                    736\n",
      "exploration/path length Mean                                    45.0435\n",
      "exploration/path length Std                                     12.8418\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.997104\n",
      "exploration/Rewards Std                                          0.0537342\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -44.913\n",
      "exploration/Returns Std                                         13.1774\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.184454\n",
      "exploration/Actions Std                                          0.599563\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           23\n",
      "exploration/Average Returns                                    -44.913\n",
      "exploration/env_infos/final/is_success Mean                      0.130435\n",
      "exploration/env_infos/final/is_success Std                       0.336781\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00289575\n",
      "exploration/env_infos/is_success Std                             0.0537342\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   18101\n",
      "evaluation/num paths total                                     370\n",
      "evaluation/path length Mean                                     43.4167\n",
      "evaluation/path length Std                                      14.7222\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.996161\n",
      "evaluation/Rewards Std                                           0.0618388\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -43.25\n",
      "evaluation/Returns Std                                          15.0948\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.256944\n",
      "evaluation/Actions Std                                           0.599869\n",
      "evaluation/Actions Max                                           0.99999\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            12\n",
      "evaluation/Average Returns                                     -43.25\n",
      "evaluation/env_infos/final/is_success Mean                       0.166667\n",
      "evaluation/env_infos/final/is_success Std                        0.372678\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00383877\n",
      "evaluation/env_infos/is_success Std                              0.0618388\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.110262\n",
      "time/evaluation sampling (s)                                    17.0234\n",
      "time/exploration sampling (s)                                   33.3763\n",
      "time/logging (s)                                                 0.00919396\n",
      "time/saving (s)                                                  0.0713481\n",
      "time/training (s)                                              197.077\n",
      "time/epoch (s)                                                 247.667\n",
      "time/total (s)                                                9304.53\n",
      "Epoch                                                           35\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 36\n",
      "\n",
      " Cycle 0 36\n",
      "Added episode 50\n",
      "Replay buf 36305\n",
      "Soft update 28800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 36\n",
      "Added episode 50\n",
      "Replay buf 36355\n",
      "Soft update 28840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 36\n",
      "Added episode 50\n",
      "Replay buf 36405\n",
      "Soft update 28880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 36\n",
      "Added episode 50\n",
      "Replay buf 36455\n",
      "Soft update 28920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 36\n",
      "Added episode 50\n",
      "Replay buf 36505\n",
      "Soft update 28960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 36\n",
      "Added episode 50\n",
      "Replay buf 36555\n",
      "Soft update 29000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 36\n",
      "Added episode 50\n",
      "Replay buf 36605\n",
      "Soft update 29040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 36\n",
      "Added episode 50\n",
      "Replay buf 36655\n",
      "Soft update 29080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 36\n",
      "Added episode 50\n",
      "Replay buf 36705\n",
      "Soft update 29120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 36\n",
      "Added episode 50\n",
      "Replay buf 36755\n",
      "Soft update 29160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 36\n",
      "Added episode 50\n",
      "Replay buf 36805\n",
      "Soft update 29200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 36\n",
      "Added episode 50\n",
      "Replay buf 36855\n",
      "Soft update 29240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 36\n",
      "Added episode 50\n",
      "Replay buf 36905\n",
      "Soft update 29280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 36\n",
      "Added episode 50\n",
      "Replay buf 36955\n",
      "Soft update 29320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 36\n",
      "Added episode 50\n",
      "Replay buf 37005\n",
      "Soft update 29360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 36\n",
      "Added episode 50\n",
      "Replay buf 37055\n",
      "Soft update 29400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 36\n",
      "Added episode 50\n",
      "Replay buf 37105\n",
      "Soft update 29440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 36\n",
      "Added episode 50\n",
      "Replay buf 37155\n",
      "Soft update 29480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 36\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 37216\n",
      "Soft update 29520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 36\n",
      "Added episode 50\n",
      "Replay buf 37266\n",
      "Soft update 29560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:31:54.175581 EEST | [final-sideways-pixels-final-31] Epoch 36 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                  0.281653\n",
      "trainer/Policy Loss                                              0.00796455\n",
      "trainer/Raw Policy Loss                                          0.00796455\n",
      "trainer/State estimation loss                                    0.00613451\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.2157\n",
      "trainer/Q Predictions Std                                        9.74437\n",
      "trainer/Q Predictions Max                                        3.88131\n",
      "trainer/Q Predictions Min                                      -30.239\n",
      "trainer/Q Targets Mean                                          -8.23962\n",
      "trainer/Q Targets Std                                            9.72184\n",
      "trainer/Q Targets Max                                            3.79942\n",
      "trainer/Q Targets Min                                          -30.2025\n",
      "trainer/Bellman Errors Mean                                      0.281653\n",
      "trainer/Bellman Errors Std                                       0.907113\n",
      "trainer/Bellman Errors Max                                      14.019\n",
      "trainer/Bellman Errors Min                                       1.9558e-07\n",
      "trainer/Policy Action Mean                                      -0.183175\n",
      "trainer/Policy Action Std                                        0.660305\n",
      "trainer/Policy Action Max                                        0.999999\n",
      "trainer/Policy Action Min                                       -0.999999\n",
      "exploration/num steps total                                  37266\n",
      "exploration/num paths total                                    757\n",
      "exploration/path length Mean                                    48.1429\n",
      "exploration/path length Std                                      8.3054\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     11\n",
      "exploration/Rewards Mean                                        -0.999011\n",
      "exploration/Rewards Std                                          0.0314347\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -48.0952\n",
      "exploration/Returns Std                                          8.51835\n",
      "exploration/Returns Max                                        -10\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.175514\n",
      "exploration/Actions Std                                          0.607309\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           21\n",
      "exploration/Average Returns                                    -48.0952\n",
      "exploration/env_infos/final/is_success Mean                      0.0476191\n",
      "exploration/env_infos/final/is_success Std                       0.212959\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00098912\n",
      "exploration/env_infos/is_success Std                             0.0314347\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   18618\n",
      "evaluation/num paths total                                     381\n",
      "evaluation/path length Mean                                     47\n",
      "evaluation/path length Std                                       9.48683\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      17\n",
      "evaluation/Rewards Mean                                         -0.998066\n",
      "evaluation/Rewards Std                                           0.0439374\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -46.9091\n",
      "evaluation/Returns Std                                           9.77431\n",
      "evaluation/Returns Max                                         -16\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.184899\n",
      "evaluation/Actions Std                                           0.625559\n",
      "evaluation/Actions Max                                           0.99993\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            11\n",
      "evaluation/Average Returns                                     -46.9091\n",
      "evaluation/env_infos/final/is_success Mean                       0.0909091\n",
      "evaluation/env_infos/final/is_success Std                        0.28748\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00193424\n",
      "evaluation/env_infos/is_success Std                              0.0439374\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.107858\n",
      "time/evaluation sampling (s)                                    16.6657\n",
      "time/exploration sampling (s)                                   33.1674\n",
      "time/logging (s)                                                 0.00697845\n",
      "time/saving (s)                                                  0.0704455\n",
      "time/training (s)                                              197.914\n",
      "time/epoch (s)                                                 247.932\n",
      "time/total (s)                                                9552.47\n",
      "Epoch                                                           36\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 37\n",
      "\n",
      " Cycle 0 37\n",
      "Added episode 50\n",
      "Replay buf 37316\n",
      "Soft update 29600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 37\n",
      "Added episode 50\n",
      "Replay buf 37366\n",
      "Soft update 29640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 37\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 37426\n",
      "Soft update 29680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 37\n",
      "Added episode 50\n",
      "Replay buf 37476\n",
      "Soft update 29720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 37\n",
      "Added episode 50\n",
      "Replay buf 37526\n",
      "Soft update 29760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 37\n",
      "Added episode 50\n",
      "Replay buf 37576\n",
      "Soft update 29800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 37\n",
      "Added episode 50\n",
      "Replay buf 37626\n",
      "Soft update 29840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 37\n",
      "Added episode 50\n",
      "Replay buf 37676\n",
      "Soft update 29880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 37\n",
      "Added episode 50\n",
      "Replay buf 37726\n",
      "Soft update 29920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 37\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 37794\n",
      "Soft update 29960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 37\n",
      "Added episode 50\n",
      "Replay buf 37844\n",
      "Soft update 30000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 37\n",
      "Added episode 50\n",
      "Replay buf 37894\n",
      "Soft update 30040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 37\n",
      "Added episode 50\n",
      "Replay buf 37944\n",
      "Soft update 30080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 37\n",
      "Added episode 50\n",
      "Replay buf 37994\n",
      "Soft update 30120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 37\n",
      "Added episode 50\n",
      "Replay buf 38044\n",
      "Soft update 30160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 37\n",
      "Added episode 50\n",
      "Replay buf 38094\n",
      "Soft update 30200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 37\n",
      "Added episode 50\n",
      "Replay buf 38144\n",
      "Soft update 30240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 37\n",
      "Added episode 50\n",
      "Replay buf 38194\n",
      "Soft update 30280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 37\n",
      "Added episode 50\n",
      "Replay buf 38244\n",
      "Soft update 30320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 37\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 38318\n",
      "Soft update 30360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:36:02.180303 EEST | [final-sideways-pixels-final-31] Epoch 37 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.38839\n",
      "trainer/Policy Loss                                              0.00773032\n",
      "trainer/Raw Policy Loss                                          0.00773032\n",
      "trainer/State estimation loss                                    0.00450428\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.04168\n",
      "trainer/Q Predictions Std                                        9.91227\n",
      "trainer/Q Predictions Max                                        3.38661\n",
      "trainer/Q Predictions Min                                      -33.246\n",
      "trainer/Q Targets Mean                                          -8.04055\n",
      "trainer/Q Targets Std                                            9.94188\n",
      "trainer/Q Targets Max                                            3.70609\n",
      "trainer/Q Targets Min                                          -33.2169\n",
      "trainer/Bellman Errors Mean                                      0.38839\n",
      "trainer/Bellman Errors Std                                       2.26925\n",
      "trainer/Bellman Errors Max                                      65.5535\n",
      "trainer/Bellman Errors Min                                       2.77122e-07\n",
      "trainer/Policy Action Mean                                      -0.124196\n",
      "trainer/Policy Action Std                                        0.668315\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  38318\n",
      "exploration/num paths total                                    781\n",
      "exploration/path length Mean                                    43.8333\n",
      "exploration/path length Std                                     13.8554\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.996198\n",
      "exploration/Rewards Std                                          0.0615453\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -43.6667\n",
      "exploration/Returns Std                                         14.2263\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.191563\n",
      "exploration/Actions Std                                          0.605228\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           24\n",
      "exploration/Average Returns                                    -43.6667\n",
      "exploration/env_infos/final/is_success Mean                      0.166667\n",
      "exploration/env_infos/final/is_success Std                       0.372678\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00380228\n",
      "exploration/env_infos/is_success Std                             0.0615453\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   19118\n",
      "evaluation/num paths total                                     391\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.0782714\n",
      "evaluation/Actions Std                                           0.615519\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.108588\n",
      "time/evaluation sampling (s)                                    16.0547\n",
      "time/exploration sampling (s)                                   34.7242\n",
      "time/logging (s)                                                 0.00708994\n",
      "time/saving (s)                                                  0.0711598\n",
      "time/training (s)                                              197.034\n",
      "time/epoch (s)                                                 247.999\n",
      "time/total (s)                                                9800.48\n",
      "Epoch                                                           37\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 38\n",
      "\n",
      " Cycle 0 38\n",
      "Added episode 50\n",
      "Replay buf 38368\n",
      "Soft update 30400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 38\n",
      "Added episode 50\n",
      "Replay buf 38418\n",
      "Soft update 30440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 38\n",
      "Added episode 50\n",
      "Replay buf 38468\n",
      "Soft update 30480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 38\n",
      "Added episode 50\n",
      "Replay buf 38518\n",
      "Soft update 30520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 38\n",
      "Added episode 50\n",
      "Replay buf 38568\n",
      "Soft update 30560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 38\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 38628\n",
      "Soft update 30600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 38\n",
      "Added episode 50\n",
      "Replay buf 38678\n",
      "Soft update 30640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 38\n",
      "Added episode 50\n",
      "Replay buf 38728\n",
      "Soft update 30680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 38\n",
      "Added episode 50\n",
      "Replay buf 38778\n",
      "Soft update 30720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 38\n",
      "Added episode 50\n",
      "Replay buf 38828\n",
      "Soft update 30760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 38\n",
      "Added episode 50\n",
      "Replay buf 38878\n",
      "Soft update 30800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 38\n",
      "Added episode 50\n",
      "Replay buf 38928\n",
      "Soft update 30840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 38\n",
      "Added episode 50\n",
      "Replay buf 38978\n",
      "Soft update 30880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 38\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 39039\n",
      "Soft update 30920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 38\n",
      "Added episode 50\n",
      "Replay buf 39089\n",
      "Soft update 30960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 38\n",
      "Added episode 50\n",
      "Replay buf 39139\n",
      "Soft update 31000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 38\n",
      "Added episode 50\n",
      "Replay buf 39189\n",
      "Soft update 31040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 38\n",
      "Added episode 50\n",
      "Replay buf 39239\n",
      "Soft update 31080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 38\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 39298\n",
      "Soft update 31120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 38\n",
      "Added episode 50\n",
      "Replay buf 39348\n",
      "Soft update 31160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:40:09.005863 EEST | [final-sideways-pixels-final-31] Epoch 38 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                  0.388703\n",
      "trainer/Policy Loss                                              0.00798088\n",
      "trainer/Raw Policy Loss                                          0.00798088\n",
      "trainer/State estimation loss                                    0.00427941\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.16644\n",
      "trainer/Q Predictions Std                                       10.0504\n",
      "trainer/Q Predictions Max                                        3.8563\n",
      "trainer/Q Predictions Min                                      -37.1831\n",
      "trainer/Q Targets Mean                                          -8.24753\n",
      "trainer/Q Targets Std                                           10.131\n",
      "trainer/Q Targets Max                                            3.78493\n",
      "trainer/Q Targets Min                                          -36.1668\n",
      "trainer/Bellman Errors Mean                                      0.388703\n",
      "trainer/Bellman Errors Std                                       2.16334\n",
      "trainer/Bellman Errors Max                                      60.8066\n",
      "trainer/Bellman Errors Min                                       9.6771e-08\n",
      "trainer/Policy Action Mean                                      -0.141362\n",
      "trainer/Policy Action Std                                        0.646086\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  39348\n",
      "exploration/num paths total                                    804\n",
      "exploration/path length Mean                                    44.7826\n",
      "exploration/path length Std                                     13.4745\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.997087\n",
      "exploration/Rewards Std                                          0.0538901\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -44.6522\n",
      "exploration/Returns Std                                         13.8112\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.134443\n",
      "exploration/Actions Std                                          0.612244\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           23\n",
      "exploration/Average Returns                                    -44.6522\n",
      "exploration/env_infos/final/is_success Mean                      0.130435\n",
      "exploration/env_infos/final/is_success Std                       0.336781\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00291262\n",
      "exploration/env_infos/is_success Std                             0.0538901\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   19636\n",
      "evaluation/num paths total                                     402\n",
      "evaluation/path length Mean                                     47.0909\n",
      "evaluation/path length Std                                       9.19935\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      18\n",
      "evaluation/Rewards Mean                                         -0.99807\n",
      "evaluation/Rewards Std                                           0.0438951\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -47\n",
      "evaluation/Returns Std                                           9.48683\n",
      "evaluation/Returns Max                                         -17\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.177878\n",
      "evaluation/Actions Std                                           0.610052\n",
      "evaluation/Actions Max                                           0.999988\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            11\n",
      "evaluation/Average Returns                                     -47\n",
      "evaluation/env_infos/final/is_success Mean                       0.0909091\n",
      "evaluation/env_infos/final/is_success Std                        0.28748\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0019305\n",
      "evaluation/env_infos/is_success Std                              0.0438951\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.109926\n",
      "time/evaluation sampling (s)                                    16.5551\n",
      "time/exploration sampling (s)                                   32.5991\n",
      "time/logging (s)                                                 0.00708542\n",
      "time/saving (s)                                                  0.0706934\n",
      "time/training (s)                                              197.479\n",
      "time/epoch (s)                                                 246.82\n",
      "time/total (s)                                               10047.3\n",
      "Epoch                                                           38\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 39\n",
      "\n",
      " Cycle 0 39\n",
      "Added episode 50\n",
      "Replay buf 39398\n",
      "Soft update 31200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 39\n",
      "Added episode 50\n",
      "Replay buf 39448\n",
      "Soft update 31240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 39\n",
      "Added episode 50\n",
      "Replay buf 39498\n",
      "Soft update 31280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 39\n",
      "Added episode 50\n",
      "Replay buf 39548\n",
      "Soft update 31320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 39\n",
      "Added episode 50\n",
      "Replay buf 39598\n",
      "Soft update 31360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 39\n",
      "Added episode 50\n",
      "Replay buf 39648\n",
      "Soft update 31400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 39\n",
      "Added episode 50\n",
      "Replay buf 39698\n",
      "Soft update 31440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 39\n",
      "Added episode 50\n",
      "Replay buf 39748\n",
      "Soft update 31480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 39\n",
      "Added episode 50\n",
      "Replay buf 39798\n",
      "Soft update 31520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 39\n",
      "Added episode 50\n",
      "Replay buf 39848\n",
      "Soft update 31560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 39\n",
      "Added episode 50\n",
      "Replay buf 39898\n",
      "Soft update 31600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 39\n",
      "Added episode 50\n",
      "Replay buf 39948\n",
      "Soft update 31640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 39\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 40010\n",
      "Soft update 31680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 39\n",
      "Added episode 50\n",
      "Replay buf 40060\n",
      "Soft update 31720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 39\n",
      "Added episode 50\n",
      "Replay buf 40110\n",
      "Soft update 31760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 39\n",
      "Added episode 50\n",
      "Replay buf 40160\n",
      "Soft update 31800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 39\n",
      "Added episode 50\n",
      "Replay buf 40210\n",
      "Soft update 31840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 39\n",
      "Added episode 50\n",
      "Replay buf 40260\n",
      "Soft update 31880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 39\n",
      "Added episode 50\n",
      "Replay buf 40310\n",
      "Soft update 31920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 39\n",
      "Added episode 50\n",
      "Replay buf 40360\n",
      "Soft update 31960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:44:17.041941 EEST | [final-sideways-pixels-final-31] Epoch 39 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.362406\n",
      "trainer/Policy Loss                                              0.00809067\n",
      "trainer/Raw Policy Loss                                          0.00809067\n",
      "trainer/State estimation loss                                    0.00427549\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.26786\n",
      "trainer/Q Predictions Std                                       10.3228\n",
      "trainer/Q Predictions Max                                        3.86742\n",
      "trainer/Q Predictions Min                                      -33.9343\n",
      "trainer/Q Targets Mean                                          -8.19108\n",
      "trainer/Q Targets Std                                           10.2954\n",
      "trainer/Q Targets Max                                            3.86804\n",
      "trainer/Q Targets Min                                          -33.1997\n",
      "trainer/Bellman Errors Mean                                      0.362406\n",
      "trainer/Bellman Errors Std                                       1.2758\n",
      "trainer/Bellman Errors Max                                      20.3274\n",
      "trainer/Bellman Errors Min                                       5.59605e-08\n",
      "trainer/Policy Action Mean                                      -0.159728\n",
      "trainer/Policy Action Std                                        0.651106\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  40360\n",
      "exploration/num paths total                                    825\n",
      "exploration/path length Mean                                    48.1905\n",
      "exploration/path length Std                                      8.09244\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     12\n",
      "exploration/Rewards Mean                                        -0.999012\n",
      "exploration/Rewards Std                                          0.0314192\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -48.1429\n",
      "exploration/Returns Std                                          8.3054\n",
      "exploration/Returns Max                                        -11\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.132719\n",
      "exploration/Actions Std                                          0.637025\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           21\n",
      "exploration/Average Returns                                    -48.1429\n",
      "exploration/env_infos/final/is_success Mean                      0.0476191\n",
      "exploration/env_infos/final/is_success Std                       0.212959\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.000988142\n",
      "exploration/env_infos/is_success Std                             0.0314192\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   20145\n",
      "evaluation/num paths total                                     413\n",
      "evaluation/path length Mean                                     46.2727\n",
      "evaluation/path length Std                                      11.7867\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.998035\n",
      "evaluation/Rewards Std                                           0.0442807\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -46.1818\n",
      "evaluation/Returns Std                                          12.0741\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.258323\n",
      "evaluation/Actions Std                                           0.602821\n",
      "evaluation/Actions Max                                           0.999915\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            11\n",
      "evaluation/Average Returns                                     -46.1818\n",
      "evaluation/env_infos/final/is_success Mean                       0.0909091\n",
      "evaluation/env_infos/final/is_success Std                        0.28748\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00196464\n",
      "evaluation/env_infos/is_success Std                              0.0442807\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.1056\n",
      "time/evaluation sampling (s)                                    17.1471\n",
      "time/exploration sampling (s)                                   32.7471\n",
      "time/logging (s)                                                 0.00712628\n",
      "time/saving (s)                                                  0.0726136\n",
      "time/training (s)                                              197.951\n",
      "time/epoch (s)                                                 248.03\n",
      "time/total (s)                                               10295.3\n",
      "Epoch                                                           39\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 40\n",
      "\n",
      " Cycle 0 40\n",
      "Added episode 50\n",
      "Replay buf 40410\n",
      "Soft update 32000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 40\n",
      "Added episode 50\n",
      "Replay buf 40460\n",
      "Soft update 32040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 40\n",
      "Added episode 50\n",
      "Replay buf 40510\n",
      "Soft update 32080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 40\n",
      "Added episode 50\n",
      "Replay buf 40560\n",
      "Soft update 32120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 40\n",
      "Added episode 50\n",
      "Replay buf 40610\n",
      "Soft update 32160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 40\n",
      "Added episode 50\n",
      "Replay buf 40660\n",
      "Soft update 32200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 40\n",
      "Added episode 50\n",
      "Replay buf 40710\n",
      "Soft update 32240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 40\n",
      "Added episode 50\n",
      "Replay buf 40760\n",
      "Soft update 32280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 40\n",
      "Added episode 50\n",
      "Replay buf 40810\n",
      "Soft update 32320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 40\n",
      "Added episode 50\n",
      "Replay buf 40860\n",
      "Soft update 32360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 40\n",
      "Added episode 50\n",
      "Replay buf 40910\n",
      "Soft update 32400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 40\n",
      "Added episode 50\n",
      "Replay buf 40960\n",
      "Soft update 32440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 40\n",
      "Added episode 50\n",
      "Replay buf 41010\n",
      "Soft update 32480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 40\n",
      "Added episode 50\n",
      "Replay buf 41060\n",
      "Soft update 32520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 40\n",
      "Added episode 50\n",
      "Replay buf 41110\n",
      "Soft update 32560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 40\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 50\n",
      "Replay buf 41177\n",
      "Soft update 32600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 40\n",
      "Added episode 50\n",
      "Replay buf 41227\n",
      "Soft update 32640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 40\n",
      "Added episode 50\n",
      "Replay buf 41277\n",
      "Soft update 32680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 40\n",
      "Added episode 50\n",
      "Replay buf 41327\n",
      "Soft update 32720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 40\n",
      "Added episode 50\n",
      "Replay buf 41377\n",
      "Soft update 32760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:48:23.022679 EEST | [final-sideways-pixels-final-31] Epoch 40 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.462171\n",
      "trainer/Policy Loss                                              0.00840405\n",
      "trainer/Raw Policy Loss                                          0.00840405\n",
      "trainer/State estimation loss                                    0.00422967\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.68182\n",
      "trainer/Q Predictions Std                                       10.2473\n",
      "trainer/Q Predictions Max                                        4.67435\n",
      "trainer/Q Predictions Min                                      -33.5537\n",
      "trainer/Q Targets Mean                                          -8.69364\n",
      "trainer/Q Targets Std                                           10.3568\n",
      "trainer/Q Targets Max                                            4.44079\n",
      "trainer/Q Targets Min                                          -34.4228\n",
      "trainer/Bellman Errors Mean                                      0.462171\n",
      "trainer/Bellman Errors Std                                       3.52799\n",
      "trainer/Bellman Errors Max                                     113.507\n",
      "trainer/Bellman Errors Min                                       2.80127e-08\n",
      "trainer/Policy Action Mean                                      -0.15716\n",
      "trainer/Policy Action Std                                        0.67034\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  41377\n",
      "exploration/num paths total                                    846\n",
      "exploration/path length Mean                                    48.4286\n",
      "exploration/path length Std                                      7.02764\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     17\n",
      "exploration/Rewards Mean                                        -0.999017\n",
      "exploration/Rewards Std                                          0.0313419\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -48.3809\n",
      "exploration/Returns Std                                          7.2406\n",
      "exploration/Returns Max                                        -16\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.193326\n",
      "exploration/Actions Std                                          0.624572\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           21\n",
      "exploration/Average Returns                                    -48.3809\n",
      "exploration/env_infos/final/is_success Mean                      0.0476191\n",
      "exploration/env_infos/final/is_success Std                       0.212959\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.000983284\n",
      "exploration/env_infos/is_success Std                             0.0313419\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   20645\n",
      "evaluation/num paths total                                     423\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.276959\n",
      "evaluation/Actions Std                                           0.591463\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.105573\n",
      "time/evaluation sampling (s)                                    16.4369\n",
      "time/exploration sampling (s)                                   32.2058\n",
      "time/logging (s)                                                 0.00686596\n",
      "time/saving (s)                                                  0.0712468\n",
      "time/training (s)                                              197.149\n",
      "time/epoch (s)                                                 245.975\n",
      "time/total (s)                                               10541.3\n",
      "Epoch                                                           40\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 41\n",
      "\n",
      " Cycle 0 41\n",
      "Added episode 50\n",
      "Replay buf 41427\n",
      "Soft update 32800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 41\n",
      "Added episode 50\n",
      "Replay buf 41477\n",
      "Soft update 32840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 41\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 41541\n",
      "Soft update 32880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 41\n",
      "Added episode 50\n",
      "Replay buf 41591\n",
      "Soft update 32920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 41\n",
      "Added episode 50\n",
      "Replay buf 41641\n",
      "Soft update 32960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 41\n",
      "Added episode 50\n",
      "Replay buf 41691\n",
      "Soft update 33000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 41\n",
      "Added episode 50\n",
      "Replay buf 41741\n",
      "Soft update 33040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 41\n",
      "Added episode 50\n",
      "Replay buf 41791\n",
      "Soft update 33080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 41\n",
      "Added episode 50\n",
      "Replay buf 41841\n",
      "Soft update 33120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 41\n",
      "Added episode 50\n",
      "Replay buf 41891\n",
      "Soft update 33160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 41\n",
      "Added episode 50\n",
      "Replay buf 41941\n",
      "Soft update 33200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 41\n",
      "Added episode 50\n",
      "Replay buf 41991\n",
      "Soft update 33240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 41\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 42052\n",
      "Soft update 33280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 41\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 50\n",
      "Replay buf 42119\n",
      "Soft update 33320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 41\n",
      "Added episode 50\n",
      "Replay buf 42169\n",
      "Soft update 33360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 41\n",
      "Added episode 50\n",
      "Replay buf 42219\n",
      "Soft update 33400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 41\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 42282\n",
      "Soft update 33440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 41\n",
      "Added episode 50\n",
      "Replay buf 42332\n",
      "Soft update 33480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 41\n",
      "Added episode 50\n",
      "Replay buf 42382\n",
      "Soft update 33520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 41\n",
      "Added episode 50\n",
      "Replay buf 42432\n",
      "Soft update 33560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:52:32.892243 EEST | [final-sideways-pixels-final-31] Epoch 41 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.599308\n",
      "trainer/Policy Loss                                              0.00816988\n",
      "trainer/Raw Policy Loss                                          0.00816988\n",
      "trainer/State estimation loss                                    0.00432153\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.41456\n",
      "trainer/Q Predictions Std                                       10.7195\n",
      "trainer/Q Predictions Max                                        3.85742\n",
      "trainer/Q Predictions Min                                      -33.6271\n",
      "trainer/Q Targets Mean                                          -8.28938\n",
      "trainer/Q Targets Std                                           10.7032\n",
      "trainer/Q Targets Max                                            3.88694\n",
      "trainer/Q Targets Min                                          -33.6647\n",
      "trainer/Bellman Errors Mean                                      0.599308\n",
      "trainer/Bellman Errors Std                                       4.30535\n",
      "trainer/Bellman Errors Max                                     115.8\n",
      "trainer/Bellman Errors Min                                       6.04758e-07\n",
      "trainer/Policy Action Mean                                      -0.126246\n",
      "trainer/Policy Action Std                                        0.671378\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  42432\n",
      "exploration/num paths total                                    870\n",
      "exploration/path length Mean                                    43.9583\n",
      "exploration/path length Std                                     13.5385\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     11\n",
      "exploration/Rewards Mean                                        -0.996209\n",
      "exploration/Rewards Std                                          0.0614581\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -43.7917\n",
      "exploration/Returns Std                                         13.9104\n",
      "exploration/Returns Max                                        -10\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.199369\n",
      "exploration/Actions Std                                          0.612818\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           24\n",
      "exploration/Average Returns                                    -43.7917\n",
      "exploration/env_infos/final/is_success Mean                      0.166667\n",
      "exploration/env_infos/final/is_success Std                       0.372678\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00379147\n",
      "exploration/env_infos/is_success Std                             0.0614581\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   21180\n",
      "evaluation/num paths total                                     435\n",
      "evaluation/path length Mean                                     44.5833\n",
      "evaluation/path length Std                                      12.4931\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.996262\n",
      "evaluation/Rewards Std                                           0.0610274\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -44.4167\n",
      "evaluation/Returns Std                                          12.8547\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.240322\n",
      "evaluation/Actions Std                                           0.610532\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            12\n",
      "evaluation/Average Returns                                     -44.4167\n",
      "evaluation/env_infos/final/is_success Mean                       0.166667\n",
      "evaluation/env_infos/final/is_success Std                        0.372678\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00373832\n",
      "evaluation/env_infos/is_success Std                              0.0610274\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.110004\n",
      "time/evaluation sampling (s)                                    17.9459\n",
      "time/exploration sampling (s)                                   34.35\n",
      "time/logging (s)                                                 0.00710469\n",
      "time/saving (s)                                                  0.0705127\n",
      "time/training (s)                                              197.381\n",
      "time/epoch (s)                                                 249.864\n",
      "time/total (s)                                               10791.2\n",
      "Epoch                                                           41\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 42\n",
      "\n",
      " Cycle 0 42\n",
      "Added episode 50\n",
      "Replay buf 42482\n",
      "Soft update 33600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 42\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 42544\n",
      "Soft update 33640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 42\n",
      "Added episode 50\n",
      "Replay buf 42594\n",
      "Soft update 33680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 42\n",
      "Added episode 50\n",
      "Replay buf 42644\n",
      "Soft update 33720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 42\n",
      "Added episode 50\n",
      "Replay buf 42694\n",
      "Soft update 33760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 42\n",
      "Added episode 50\n",
      "Replay buf 42744\n",
      "Soft update 33800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 42\n",
      "Added episode 50\n",
      "Replay buf 42794\n",
      "Soft update 33840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 42\n",
      "Added episode 50\n",
      "Replay buf 42844\n",
      "Soft update 33880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 42\n",
      "Added episode 50\n",
      "Replay buf 42894\n",
      "Soft update 33920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 42\n",
      "Added episode 50\n",
      "Replay buf 42944\n",
      "Soft update 33960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 42\n",
      "Added episode 50\n",
      "Replay buf 42994\n",
      "Soft update 34000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 42\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 43054\n",
      "Soft update 34040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 42\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 24\n",
      "Added episode 50\n",
      "Replay buf 43128\n",
      "Soft update 34080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 42\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 26\n",
      "Added episode 50\n",
      "Replay buf 43204\n",
      "Soft update 34120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 42\n",
      "Added episode 50\n",
      "Replay buf 43254\n",
      "Soft update 34160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 42\n",
      "Added episode 50\n",
      "Replay buf 43304\n",
      "Soft update 34200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 42\n",
      "Added episode 50\n",
      "Replay buf 43354\n",
      "Soft update 34240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 42\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 43432\n",
      "Soft update 34280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 42\n",
      "Added episode 50\n",
      "Replay buf 43482\n",
      "Soft update 34320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 42\n",
      "Added episode 50\n",
      "Replay buf 43532\n",
      "Soft update 34360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 11:56:45.528218 EEST | [final-sideways-pixels-final-31] Epoch 42 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.537646\n",
      "trainer/Policy Loss                                              0.00830816\n",
      "trainer/Raw Policy Loss                                          0.00830816\n",
      "trainer/State estimation loss                                    0.00408887\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.62675\n",
      "trainer/Q Predictions Std                                       10.6468\n",
      "trainer/Q Predictions Max                                        3.5908\n",
      "trainer/Q Predictions Min                                      -34.1474\n",
      "trainer/Q Targets Mean                                          -8.63344\n",
      "trainer/Q Targets Std                                           10.6419\n",
      "trainer/Q Targets Max                                            4.00959\n",
      "trainer/Q Targets Min                                          -34.2999\n",
      "trainer/Bellman Errors Mean                                      0.537646\n",
      "trainer/Bellman Errors Std                                       4.7018\n",
      "trainer/Bellman Errors Max                                     137.929\n",
      "trainer/Bellman Errors Min                                       9.75862e-08\n",
      "trainer/Policy Action Mean                                      -0.135651\n",
      "trainer/Policy Action Std                                        0.661767\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  43532\n",
      "exploration/num paths total                                    896\n",
      "exploration/path length Mean                                    42.3077\n",
      "exploration/path length Std                                     14.3467\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.994545\n",
      "exploration/Rewards Std                                          0.0736532\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -42.0769\n",
      "exploration/Returns Std                                         14.7594\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.182702\n",
      "exploration/Actions Std                                          0.620364\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           26\n",
      "exploration/Average Returns                                    -42.0769\n",
      "exploration/env_infos/final/is_success Mean                      0.230769\n",
      "exploration/env_infos/final/is_success Std                       0.421325\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00545455\n",
      "exploration/env_infos/is_success Std                             0.0736532\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   21692\n",
      "evaluation/num paths total                                     446\n",
      "evaluation/path length Mean                                     46.5455\n",
      "evaluation/path length Std                                      10.9242\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      12\n",
      "evaluation/Rewards Mean                                         -0.998047\n",
      "evaluation/Rewards Std                                           0.044151\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -46.4545\n",
      "evaluation/Returns Std                                          11.2117\n",
      "evaluation/Returns Max                                         -11\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.216199\n",
      "evaluation/Actions Std                                           0.57462\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            11\n",
      "evaluation/Average Returns                                     -46.4545\n",
      "evaluation/env_infos/final/is_success Mean                       0.0909091\n",
      "evaluation/env_infos/final/is_success Std                        0.28748\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00195312\n",
      "evaluation/env_infos/is_success Std                              0.044151\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.114894\n",
      "time/evaluation sampling (s)                                    17.0913\n",
      "time/exploration sampling (s)                                   37.4128\n",
      "time/logging (s)                                                 0.00707915\n",
      "time/saving (s)                                                  0.0705655\n",
      "time/training (s)                                              197.934\n",
      "time/epoch (s)                                                 252.631\n",
      "time/total (s)                                               11043.8\n",
      "Epoch                                                           42\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 16\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 43\n",
      "\n",
      " Cycle 0 43\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 17\n",
      "Added episode 50\n",
      "Replay buf 43615\n",
      "Soft update 34400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 43\n",
      "Added episode 50\n",
      "Replay buf 43665\n",
      "Soft update 34440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 43\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 43726\n",
      "Soft update 34480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 43\n",
      "Added episode 50\n",
      "Replay buf 43776\n",
      "Soft update 34520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 43\n",
      "Added episode 50\n",
      "Replay buf 43826\n",
      "Soft update 34560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 43\n",
      "Added episode 50\n",
      "Replay buf 43876\n",
      "Soft update 34600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 43\n",
      "Added episode 50\n",
      "Replay buf 43926\n",
      "Soft update 34640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 43\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 43988\n",
      "Soft update 34680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 43\n",
      "Added episode 50\n",
      "Replay buf 44038\n",
      "Soft update 34720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 43\n",
      "Added episode 50\n",
      "Replay buf 44088\n",
      "Soft update 34760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 43\n",
      "Added episode 50\n",
      "Replay buf 44138\n",
      "Soft update 34800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 43\n",
      "Added episode 50\n",
      "Replay buf 44188\n",
      "Soft update 34840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 43\n",
      "Added episode 50\n",
      "Replay buf 44238\n",
      "Soft update 34880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 43\n",
      "Added episode 50\n",
      "Replay buf 44288\n",
      "Soft update 34920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 43\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 44349\n",
      "Soft update 34960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 43\n",
      "Added episode 50\n",
      "Replay buf 44399\n",
      "Soft update 35000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 43\n",
      "Added episode 50\n",
      "Replay buf 44449\n",
      "Soft update 35040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 43\n",
      "Added episode 50\n",
      "Replay buf 44499\n",
      "Soft update 35080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 43\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 44571\n",
      "Soft update 35120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 43\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 44635\n",
      "Soft update 35160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:00:55.415815 EEST | [final-sideways-pixels-final-31] Epoch 43 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.408125\n",
      "trainer/Policy Loss                                              0.0083549\n",
      "trainer/Raw Policy Loss                                          0.0083549\n",
      "trainer/State estimation loss                                    0.00473742\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.48823\n",
      "trainer/Q Predictions Std                                       10.975\n",
      "trainer/Q Predictions Max                                        4.81892\n",
      "trainer/Q Predictions Min                                      -36.1156\n",
      "trainer/Q Targets Mean                                          -8.51839\n",
      "trainer/Q Targets Std                                           11.0521\n",
      "trainer/Q Targets Max                                            4.61191\n",
      "trainer/Q Targets Min                                          -36.0393\n",
      "trainer/Bellman Errors Mean                                      0.408125\n",
      "trainer/Bellman Errors Std                                       3.40111\n",
      "trainer/Bellman Errors Max                                     106.55\n",
      "trainer/Bellman Errors Min                                       3.91836e-07\n",
      "trainer/Policy Action Mean                                      -0.132784\n",
      "trainer/Policy Action Std                                        0.591553\n",
      "trainer/Policy Action Max                                        0.999994\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  44635\n",
      "exploration/num paths total                                    924\n",
      "exploration/path length Mean                                    39.3929\n",
      "exploration/path length Std                                     16.817\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     11\n",
      "exploration/Rewards Mean                                        -0.992747\n",
      "exploration/Rewards Std                                          0.0848548\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -39.1071\n",
      "exploration/Returns Std                                         17.2675\n",
      "exploration/Returns Max                                        -10\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.18527\n",
      "exploration/Actions Std                                          0.607231\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           28\n",
      "exploration/Average Returns                                    -39.1071\n",
      "exploration/env_infos/final/is_success Mean                      0.285714\n",
      "exploration/env_infos/final/is_success Std                       0.451754\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00725295\n",
      "exploration/env_infos/is_success Std                             0.0848548\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   22205\n",
      "evaluation/num paths total                                     460\n",
      "evaluation/path length Mean                                     36.6429\n",
      "evaluation/path length Std                                      16.3646\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      12\n",
      "evaluation/Rewards Mean                                         -0.988304\n",
      "evaluation/Rewards Std                                           0.107513\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -36.2143\n",
      "evaluation/Returns Std                                          16.8319\n",
      "evaluation/Returns Max                                         -11\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.17524\n",
      "evaluation/Actions Std                                           0.495955\n",
      "evaluation/Actions Max                                           0.998606\n",
      "evaluation/Actions Min                                          -0.999997\n",
      "evaluation/Num Paths                                            14\n",
      "evaluation/Average Returns                                     -36.2143\n",
      "evaluation/env_infos/final/is_success Mean                       0.428571\n",
      "evaluation/env_infos/final/is_success Std                        0.494872\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0116959\n",
      "evaluation/env_infos/is_success Std                              0.107513\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.114136\n",
      "time/evaluation sampling (s)                                    16.5606\n",
      "time/exploration sampling (s)                                   35.8044\n",
      "time/logging (s)                                                 0.00714014\n",
      "time/saving (s)                                                  0.0711157\n",
      "time/training (s)                                              197.325\n",
      "time/epoch (s)                                                 249.882\n",
      "time/total (s)                                               11293.7\n",
      "Epoch                                                           43\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 44\n",
      "\n",
      " Cycle 0 44\n",
      "Added episode 50\n",
      "Replay buf 44685\n",
      "Soft update 35200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 44\n",
      "Added episode 50\n",
      "Replay buf 44735\n",
      "Soft update 35240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 44\n",
      "Added episode 50\n",
      "Replay buf 44785\n",
      "Soft update 35280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 44\n",
      "Added episode 50\n",
      "Replay buf 44835\n",
      "Soft update 35320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 44\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 24\n",
      "Added episode 50\n",
      "Replay buf 44909\n",
      "Soft update 35360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 44\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 30\n",
      "Added episode 50\n",
      "Replay buf 44989\n",
      "Soft update 35400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 44\n",
      "Added episode 50\n",
      "Replay buf 45039\n",
      "Soft update 35440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 44\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 21\n",
      "Added episode 50\n",
      "Replay buf 45110\n",
      "Soft update 35480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 44\n",
      "Added episode 50\n",
      "Replay buf 45160\n",
      "Soft update 35520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 44\n",
      "Added episode 50\n",
      "Replay buf 45210\n",
      "Soft update 35560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 44\n",
      "Added episode 50\n",
      "Replay buf 45260\n",
      "Soft update 35600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 44\n",
      "Added episode 50\n",
      "Replay buf 45310\n",
      "Soft update 35640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 44\n",
      "Added episode 50\n",
      "Replay buf 45360\n",
      "Soft update 35680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 44\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 45420\n",
      "Soft update 35720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 44\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 45498\n",
      "Soft update 35760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 44\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 45566\n",
      "Soft update 35800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 44\n",
      "Added episode 50\n",
      "Replay buf 45616\n",
      "Soft update 35840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 44\n",
      "Added episode 50\n",
      "Replay buf 45666\n",
      "Soft update 35880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 44\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 45726\n",
      "Soft update 35920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 44\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 45790\n",
      "Soft update 35960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:05:07.742928 EEST | [final-sideways-pixels-final-31] Epoch 44 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.549951\n",
      "trainer/Policy Loss                                              0.00840049\n",
      "trainer/Raw Policy Loss                                          0.00840049\n",
      "trainer/State estimation loss                                    0.00397165\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.7059\n",
      "trainer/Q Predictions Std                                       11.093\n",
      "trainer/Q Predictions Max                                        4.99545\n",
      "trainer/Q Predictions Min                                      -35.6372\n",
      "trainer/Q Targets Mean                                          -8.6747\n",
      "trainer/Q Targets Std                                           11.142\n",
      "trainer/Q Targets Max                                            5.06124\n",
      "trainer/Q Targets Min                                          -35.6743\n",
      "trainer/Bellman Errors Mean                                      0.549951\n",
      "trainer/Bellman Errors Std                                       3.24416\n",
      "trainer/Bellman Errors Max                                      75.6091\n",
      "trainer/Bellman Errors Min                                       1.05912e-09\n",
      "trainer/Policy Action Mean                                      -0.140969\n",
      "trainer/Policy Action Std                                        0.697168\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  45790\n",
      "exploration/num paths total                                    953\n",
      "exploration/path length Mean                                    39.8276\n",
      "exploration/path length Std                                     15.5676\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.992208\n",
      "exploration/Rewards Std                                          0.0879289\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -39.5172\n",
      "exploration/Returns Std                                         16.0186\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.206169\n",
      "exploration/Actions Std                                          0.604957\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           29\n",
      "exploration/Average Returns                                    -39.5172\n",
      "exploration/env_infos/final/is_success Mean                      0.310345\n",
      "exploration/env_infos/final/is_success Std                       0.462635\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00779221\n",
      "exploration/env_infos/is_success Std                             0.0879289\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   22720\n",
      "evaluation/num paths total                                     475\n",
      "evaluation/path length Mean                                     34.3333\n",
      "evaluation/path length Std                                      19.1891\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.988349\n",
      "evaluation/Rewards Std                                           0.107307\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -33.9333\n",
      "evaluation/Returns Std                                          19.679\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.262827\n",
      "evaluation/Actions Std                                           0.650192\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            15\n",
      "evaluation/Average Returns                                     -33.9333\n",
      "evaluation/env_infos/final/is_success Mean                       0.4\n",
      "evaluation/env_infos/final/is_success Std                        0.489898\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0116505\n",
      "evaluation/env_infos/is_success Std                              0.107307\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.120506\n",
      "time/evaluation sampling (s)                                    16.6644\n",
      "time/exploration sampling (s)                                   38.1565\n",
      "time/logging (s)                                                 0.00729054\n",
      "time/saving (s)                                                  0.0705707\n",
      "time/training (s)                                              197.303\n",
      "time/epoch (s)                                                 252.322\n",
      "time/total (s)                                               11546\n",
      "Epoch                                                           44\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 13\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 45\n",
      "\n",
      " Cycle 0 45\n",
      "Added episode 50\n",
      "Replay buf 45840\n",
      "Soft update 36000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 45\n",
      "Added episode 50\n",
      "Replay buf 45890\n",
      "Soft update 36040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 45\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 29\n",
      "Added episode 50\n",
      "Replay buf 45969\n",
      "Soft update 36080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 45\n",
      "Added episode 50\n",
      "Replay buf 46019\n",
      "Soft update 36120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 45\n",
      "Added episode 50\n",
      "Replay buf 46069\n",
      "Soft update 36160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 45\n",
      "Added episode 50\n",
      "Replay buf 46119\n",
      "Soft update 36200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 45\n",
      "Added episode 50\n",
      "Replay buf 46169\n",
      "Soft update 36240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 45\n",
      "Added episode 50\n",
      "Replay buf 46219\n",
      "Soft update 36280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 45\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 46292\n",
      "Soft update 36320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 45\n",
      "Added episode 50\n",
      "Replay buf 46342\n",
      "Soft update 36360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 45\n",
      "Added episode 50\n",
      "Replay buf 46392\n",
      "Soft update 36400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 45\n",
      "Added episode 50\n",
      "Replay buf 46442\n",
      "Soft update 36440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 45\n",
      "Added episode 50\n",
      "Replay buf 46492\n",
      "Soft update 36480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 45\n",
      "Added episode 50\n",
      "Replay buf 46542\n",
      "Soft update 36520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 45\n",
      "Added episode 50\n",
      "Replay buf 46592\n",
      "Soft update 36560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 45\n",
      "Added episode 50\n",
      "Replay buf 46642\n",
      "Soft update 36600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 45\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 46706\n",
      "Soft update 36640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 45\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 46780\n",
      "Soft update 36680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 45\n",
      "Added episode 50\n",
      "Replay buf 46830\n",
      "Soft update 36720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 45\n",
      "Added episode 50\n",
      "Replay buf 46880\n",
      "Soft update 36760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:09:19.687482 EEST | [final-sideways-pixels-final-31] Epoch 45 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.576802\n",
      "trainer/Policy Loss                                              0.00868385\n",
      "trainer/Raw Policy Loss                                          0.00868385\n",
      "trainer/State estimation loss                                    0.0048846\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.89114\n",
      "trainer/Q Predictions Std                                       11.3871\n",
      "trainer/Q Predictions Max                                        5.69694\n",
      "trainer/Q Predictions Min                                      -42.87\n",
      "trainer/Q Targets Mean                                          -9.01127\n",
      "trainer/Q Targets Std                                           11.3859\n",
      "trainer/Q Targets Max                                            5.88213\n",
      "trainer/Q Targets Min                                          -41.9576\n",
      "trainer/Bellman Errors Mean                                      0.576802\n",
      "trainer/Bellman Errors Std                                       3.32944\n",
      "trainer/Bellman Errors Max                                      89.5233\n",
      "trainer/Bellman Errors Min                                       3.82915e-08\n",
      "trainer/Policy Action Mean                                      -0.1431\n",
      "trainer/Policy Action Std                                        0.650499\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  46880\n",
      "exploration/num paths total                                    979\n",
      "exploration/path length Mean                                    41.9231\n",
      "exploration/path length Std                                     15.0638\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.994495\n",
      "exploration/Rewards Std                                          0.0739884\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -41.6923\n",
      "exploration/Returns Std                                         15.4765\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.173802\n",
      "exploration/Actions Std                                          0.616886\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           26\n",
      "exploration/Average Returns                                    -41.6923\n",
      "exploration/env_infos/final/is_success Mean                      0.230769\n",
      "exploration/env_infos/final/is_success Std                       0.421325\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00550459\n",
      "exploration/env_infos/is_success Std                             0.0739884\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   23254\n",
      "evaluation/num paths total                                     494\n",
      "evaluation/path length Mean                                     28.1053\n",
      "evaluation/path length Std                                      18.7192\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.979401\n",
      "evaluation/Rewards Std                                           0.142038\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -27.5263\n",
      "evaluation/Returns Std                                          19.2118\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.237324\n",
      "evaluation/Actions Std                                           0.598698\n",
      "evaluation/Actions Max                                           0.999925\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            19\n",
      "evaluation/Average Returns                                     -27.5263\n",
      "evaluation/env_infos/final/is_success Mean                       0.578947\n",
      "evaluation/env_infos/final/is_success Std                        0.493728\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0205993\n",
      "evaluation/env_infos/is_success Std                              0.142038\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.114719\n",
      "time/evaluation sampling (s)                                    17.7095\n",
      "time/exploration sampling (s)                                   36.6719\n",
      "time/logging (s)                                                 0.0072294\n",
      "time/saving (s)                                                  0.0713201\n",
      "time/training (s)                                              197.364\n",
      "time/epoch (s)                                                 251.939\n",
      "time/total (s)                                               11798\n",
      "Epoch                                                           45\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 46\n",
      "\n",
      " Cycle 0 46\n",
      "Added episode 50\n",
      "Replay buf 46930\n",
      "Soft update 36800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 46\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 30\n",
      "Added episode 16\n",
      "Added episode 23\n",
      "Replay buf 46999\n",
      "Soft update 36840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 46\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 47071\n",
      "Soft update 36880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 46\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 47131\n",
      "Soft update 36920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 46\n",
      "Added episode 50\n",
      "Replay buf 47181\n",
      "Soft update 36960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 46\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 47241\n",
      "Soft update 37000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 46\n",
      "Added episode 50\n",
      "Replay buf 47291\n",
      "Soft update 37040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 46\n",
      "Added episode 50\n",
      "Replay buf 47341\n",
      "Soft update 37080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 46\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 47403\n",
      "Soft update 37120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 46\n",
      "Added episode 50\n",
      "Replay buf 47453\n",
      "Soft update 37160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 46\n",
      "Added episode 50\n",
      "Replay buf 47503\n",
      "Soft update 37200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 46\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 20\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Replay buf 47555\n",
      "Soft update 37240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 46\n",
      "Added episode 50\n",
      "Replay buf 47605\n",
      "Soft update 37280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 46\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 47665\n",
      "Soft update 37320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 46\n",
      "Added episode 50\n",
      "Replay buf 47715\n",
      "Soft update 37360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 46\n",
      "Added episode 50\n",
      "Replay buf 47765\n",
      "Soft update 37400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 46\n",
      "Added episode 50\n",
      "Replay buf 47815\n",
      "Soft update 37440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 46\n",
      "Added episode 50\n",
      "Replay buf 47865\n",
      "Soft update 37480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 46\n",
      "Added episode 50\n",
      "Replay buf 47915\n",
      "Soft update 37520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 46\n",
      "Added episode 50\n",
      "Replay buf 47965\n",
      "Soft update 37560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:13:31.610027 EEST | [final-sideways-pixels-final-31] Epoch 46 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.821782\n",
      "trainer/Policy Loss                                              0.00917858\n",
      "trainer/Raw Policy Loss                                          0.00917858\n",
      "trainer/State estimation loss                                    0.00428016\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.45808\n",
      "trainer/Q Predictions Std                                       11.4342\n",
      "trainer/Q Predictions Max                                        3.32994\n",
      "trainer/Q Predictions Min                                      -37.2671\n",
      "trainer/Q Targets Mean                                          -9.17259\n",
      "trainer/Q Targets Std                                           11.4294\n",
      "trainer/Q Targets Max                                            3.70419\n",
      "trainer/Q Targets Min                                          -36.7194\n",
      "trainer/Bellman Errors Mean                                      0.821782\n",
      "trainer/Bellman Errors Std                                       3.78379\n",
      "trainer/Bellman Errors Max                                      71.3511\n",
      "trainer/Bellman Errors Min                                       3.35517e-07\n",
      "trainer/Policy Action Mean                                      -0.118465\n",
      "trainer/Policy Action Std                                        0.675562\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  47965\n",
      "exploration/num paths total                                   1010\n",
      "exploration/path length Mean                                    35\n",
      "exploration/path length Std                                     18.0858\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.988018\n",
      "exploration/Rewards Std                                          0.108803\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -34.5806\n",
      "exploration/Returns Std                                         18.5677\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.20438\n",
      "exploration/Actions Std                                          0.585261\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           31\n",
      "exploration/Average Returns                                    -34.5806\n",
      "exploration/env_infos/final/is_success Mean                      0.419355\n",
      "exploration/env_infos/final/is_success Std                       0.493453\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0119816\n",
      "exploration/env_infos/is_success Std                             0.108803\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   23764\n",
      "evaluation/num paths total                                     508\n",
      "evaluation/path length Mean                                     36.4286\n",
      "evaluation/path length Std                                      18.3292\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.990196\n",
      "evaluation/Rewards Std                                           0.0985282\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -36.0714\n",
      "evaluation/Returns Std                                          18.8053\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.247278\n",
      "evaluation/Actions Std                                           0.588125\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            14\n",
      "evaluation/Average Returns                                     -36.0714\n",
      "evaluation/env_infos/final/is_success Mean                       0.357143\n",
      "evaluation/env_infos/final/is_success Std                        0.479157\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00980392\n",
      "evaluation/env_infos/is_success Std                              0.0985282\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.111244\n",
      "time/evaluation sampling (s)                                    17.2531\n",
      "time/exploration sampling (s)                                   37.0552\n",
      "time/logging (s)                                                 0.00725789\n",
      "time/saving (s)                                                  0.0714206\n",
      "time/training (s)                                              197.418\n",
      "time/epoch (s)                                                 251.917\n",
      "time/total (s)                                               12049.9\n",
      "Epoch                                                           46\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 47\n",
      "\n",
      " Cycle 0 47\n",
      "Added episode 50\n",
      "Replay buf 48015\n",
      "Soft update 37600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 47\n",
      "Added episode 50\n",
      "Replay buf 48065\n",
      "Soft update 37640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 47\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 43\n",
      "Replay buf 48118\n",
      "Soft update 37680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 47\n",
      "Added episode 50\n",
      "Replay buf 48168\n",
      "Soft update 37720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 47\n",
      "Added episode 50\n",
      "Replay buf 48218\n",
      "Soft update 37760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 47\n",
      "Added episode 50\n",
      "Replay buf 48268\n",
      "Soft update 37800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 47\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 48328\n",
      "Soft update 37840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 47\n",
      "Added episode 50\n",
      "Replay buf 48378\n",
      "Soft update 37880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 47\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 48439\n",
      "Soft update 37920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 47\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 44\n",
      "Replay buf 48494\n",
      "Soft update 37960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 47\n",
      "Added episode 50\n",
      "Replay buf 48544\n",
      "Soft update 38000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 47\n",
      "Added episode 50\n",
      "Replay buf 48594\n",
      "Soft update 38040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 47\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 48671\n",
      "Soft update 38080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 47\n",
      "Added episode 50\n",
      "Replay buf 48721\n",
      "Soft update 38120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 47\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 48782\n",
      "Soft update 38160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 47\n",
      "Added episode 50\n",
      "Replay buf 48832\n",
      "Soft update 38200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 47\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 48893\n",
      "Soft update 38240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 47\n",
      "Added episode 50\n",
      "Replay buf 48943\n",
      "Soft update 38280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 47\n",
      "Added episode 50\n",
      "Replay buf 48993\n",
      "Soft update 38320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 47\n",
      "Added episode 50\n",
      "Replay buf 49043\n",
      "Soft update 38360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:17:43.401181 EEST | [final-sideways-pixels-final-31] Epoch 47 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                  0.597022\n",
      "trainer/Policy Loss                                              0.00877395\n",
      "trainer/Raw Policy Loss                                          0.00877395\n",
      "trainer/State estimation loss                                    0.00411583\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.01469\n",
      "trainer/Q Predictions Std                                       11.6342\n",
      "trainer/Q Predictions Max                                        4.88088\n",
      "trainer/Q Predictions Min                                      -38.6852\n",
      "trainer/Q Targets Mean                                          -8.91637\n",
      "trainer/Q Targets Std                                           11.6336\n",
      "trainer/Q Targets Max                                            5.35795\n",
      "trainer/Q Targets Min                                          -37.9648\n",
      "trainer/Bellman Errors Mean                                      0.597022\n",
      "trainer/Bellman Errors Std                                       3.16767\n",
      "trainer/Bellman Errors Max                                      83.7926\n",
      "trainer/Bellman Errors Min                                       1.3516e-07\n",
      "trainer/Policy Action Mean                                      -0.162244\n",
      "trainer/Policy Action Std                                        0.656426\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  49043\n",
      "exploration/num paths total                                   1038\n",
      "exploration/path length Mean                                    38.5\n",
      "exploration/path length Std                                     17.2616\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.990724\n",
      "exploration/Rewards Std                                          0.0958665\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -38.1429\n",
      "exploration/Returns Std                                         17.6912\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.183567\n",
      "exploration/Actions Std                                          0.602524\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           28\n",
      "exploration/Average Returns                                    -38.1429\n",
      "exploration/env_infos/final/is_success Mean                      0.357143\n",
      "exploration/env_infos/final/is_success Std                       0.479157\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00927644\n",
      "exploration/env_infos/is_success Std                             0.0958665\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   24269\n",
      "evaluation/num paths total                                     521\n",
      "evaluation/path length Mean                                     38.8462\n",
      "evaluation/path length Std                                      15.2207\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.990099\n",
      "evaluation/Rewards Std                                           0.0990099\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -38.4615\n",
      "evaluation/Returns Std                                          15.6727\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.224033\n",
      "evaluation/Actions Std                                           0.592403\n",
      "evaluation/Actions Max                                           0.999988\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            13\n",
      "evaluation/Average Returns                                     -38.4615\n",
      "evaluation/env_infos/final/is_success Mean                       0.384615\n",
      "evaluation/env_infos/final/is_success Std                        0.486504\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00990099\n",
      "evaluation/env_infos/is_success Std                              0.0990099\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.111512\n",
      "time/evaluation sampling (s)                                    17.284\n",
      "time/exploration sampling (s)                                   36.635\n",
      "time/logging (s)                                                 0.0070069\n",
      "time/saving (s)                                                  0.0702556\n",
      "time/training (s)                                              197.677\n",
      "time/epoch (s)                                                 251.785\n",
      "time/total (s)                                               12301.7\n",
      "Epoch                                                           47\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 48\n",
      "\n",
      " Cycle 0 48\n",
      "Added episode 50\n",
      "Replay buf 49093\n",
      "Soft update 38400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 48\n",
      "Added episode 50\n",
      "Replay buf 49143\n",
      "Soft update 38440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 48\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 49202\n",
      "Soft update 38480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 48\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 50\n",
      "Replay buf 49268\n",
      "Soft update 38520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 48\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 23\n",
      "Added episode 50\n",
      "Replay buf 49341\n",
      "Soft update 38560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 48\n",
      "Added episode 50\n",
      "Replay buf 49391\n",
      "Soft update 38600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 48\n",
      "Added episode 50\n",
      "Replay buf 49441\n",
      "Soft update 38640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 48\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 49509\n",
      "Soft update 38680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 48\n",
      "Added episode 50\n",
      "Replay buf 49559\n",
      "Soft update 38720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 48\n",
      "Added episode 50\n",
      "Replay buf 49609\n",
      "Soft update 38760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 48\n",
      "Added episode 50\n",
      "Replay buf 49659\n",
      "Soft update 38800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 48\n",
      "Added episode 50\n",
      "Replay buf 49709\n",
      "Soft update 38840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 48\n",
      "Added episode 50\n",
      "Replay buf 49759\n",
      "Soft update 38880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 48\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 10\n",
      "Added episode 17\n",
      "Added episode 26\n",
      "Replay buf 49828\n",
      "Soft update 38920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 48\n",
      "Added episode 50\n",
      "Replay buf 49878\n",
      "Soft update 38960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 48\n",
      "Added episode 50\n",
      "Replay buf 49928\n",
      "Soft update 39000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 48\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 49991\n",
      "Soft update 39040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 48\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 50059\n",
      "Soft update 39080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 48\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 50130\n",
      "Soft update 39120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 48\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 11\n",
      "Added episode 26\n",
      "Added episode 20\n",
      "Replay buf 50199\n",
      "Soft update 39160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:21:55.668065 EEST | [final-sideways-pixels-final-31] Epoch 48 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.594593\n",
      "trainer/Policy Loss                                              0.00854593\n",
      "trainer/Raw Policy Loss                                          0.00854593\n",
      "trainer/State estimation loss                                    0.00389952\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.83417\n",
      "trainer/Q Predictions Std                                       11.574\n",
      "trainer/Q Predictions Max                                        5.45515\n",
      "trainer/Q Predictions Min                                      -39.3307\n",
      "trainer/Q Targets Mean                                          -8.78243\n",
      "trainer/Q Targets Std                                           11.683\n",
      "trainer/Q Targets Max                                            6.01955\n",
      "trainer/Q Targets Min                                          -38.6995\n",
      "trainer/Bellman Errors Mean                                      0.594593\n",
      "trainer/Bellman Errors Std                                       2.34133\n",
      "trainer/Bellman Errors Max                                      44.259\n",
      "trainer/Bellman Errors Min                                       2.32863e-07\n",
      "trainer/Policy Action Mean                                      -0.0806294\n",
      "trainer/Policy Action Std                                        0.687895\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  50199\n",
      "exploration/num paths total                                   1072\n",
      "exploration/path length Mean                                    34\n",
      "exploration/path length Std                                     17.3731\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.986159\n",
      "exploration/Rewards Std                                          0.11683\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -33.5294\n",
      "exploration/Returns Std                                         17.861\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.196718\n",
      "exploration/Actions Std                                          0.612465\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           34\n",
      "exploration/Average Returns                                    -33.5294\n",
      "exploration/env_infos/final/is_success Mean                      0.470588\n",
      "exploration/env_infos/final/is_success Std                       0.499134\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0138408\n",
      "exploration/env_infos/is_success Std                             0.11683\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   24769\n",
      "evaluation/num paths total                                     531\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.173425\n",
      "evaluation/Actions Std                                           0.593209\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.119651\n",
      "time/evaluation sampling (s)                                    16.0879\n",
      "time/exploration sampling (s)                                   38.3773\n",
      "time/logging (s)                                                 0.00707723\n",
      "time/saving (s)                                                  0.0712698\n",
      "time/training (s)                                              197.598\n",
      "time/epoch (s)                                                 252.262\n",
      "time/total (s)                                               12553.9\n",
      "Epoch                                                           48\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 49\n",
      "\n",
      " Cycle 0 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 36\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 50296\n",
      "Soft update 39200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 49\n",
      "Added episode 50\n",
      "Replay buf 50346\n",
      "Soft update 39240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 49\n",
      "Added episode 50\n",
      "Replay buf 50396\n",
      "Soft update 39280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 49\n",
      "Added episode 50\n",
      "Replay buf 50446\n",
      "Soft update 39320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 49\n",
      "Added episode 50\n",
      "Replay buf 50496\n",
      "Soft update 39360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 49\n",
      "Added episode 50\n",
      "Replay buf 50546\n",
      "Soft update 39400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 50621\n",
      "Soft update 39440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 49\n",
      "Added episode 50\n",
      "Replay buf 50671\n",
      "Soft update 39480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 50732\n",
      "Soft update 39520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 49\n",
      "Added episode 50\n",
      "Replay buf 50782\n",
      "Soft update 39560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 50845\n",
      "Soft update 39600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 50915\n",
      "Soft update 39640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 49\n",
      "Added episode 50\n",
      "Replay buf 50965\n",
      "Soft update 39680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 49\n",
      "Added episode 50\n",
      "Replay buf 51015\n",
      "Soft update 39720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 49\n",
      "Added episode 50\n",
      "Replay buf 51065\n",
      "Soft update 39760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 49\n",
      "Added episode 50\n",
      "Replay buf 51115\n",
      "Soft update 39800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 49\n",
      "Added episode 50\n",
      "Replay buf 51165\n",
      "Soft update 39840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 49\n",
      "Added episode 50\n",
      "Replay buf 51215\n",
      "Soft update 39880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 49\n",
      "Added episode 50\n",
      "Replay buf 51265\n",
      "Soft update 39920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 51324\n",
      "Soft update 39960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:26:08.463314 EEST | [final-sideways-pixels-final-31] Epoch 49 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.914129\n",
      "trainer/Policy Loss                                              0.0086512\n",
      "trainer/Raw Policy Loss                                          0.0086512\n",
      "trainer/State estimation loss                                    0.00345557\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -8.91616\n",
      "trainer/Q Predictions Std                                       11.8998\n",
      "trainer/Q Predictions Max                                        8.98647\n",
      "trainer/Q Predictions Min                                      -39.423\n",
      "trainer/Q Targets Mean                                          -9.00056\n",
      "trainer/Q Targets Std                                           12.0731\n",
      "trainer/Q Targets Max                                            8.47224\n",
      "trainer/Q Targets Min                                          -40.4591\n",
      "trainer/Bellman Errors Mean                                      0.914129\n",
      "trainer/Bellman Errors Std                                       5.91026\n",
      "trainer/Bellman Errors Max                                     146.152\n",
      "trainer/Bellman Errors Min                                       2.82677e-09\n",
      "trainer/Policy Action Mean                                      -0.0874278\n",
      "trainer/Policy Action Std                                        0.673407\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  51324\n",
      "exploration/num paths total                                   1101\n",
      "exploration/path length Mean                                    38.7931\n",
      "exploration/path length Std                                     17.2794\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.992\n",
      "exploration/Rewards Std                                          0.0890842\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -38.4828\n",
      "exploration/Returns Std                                         17.7271\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.172246\n",
      "exploration/Actions Std                                          0.60631\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           29\n",
      "exploration/Average Returns                                    -38.4828\n",
      "exploration/env_infos/final/is_success Mean                      0.310345\n",
      "exploration/env_infos/final/is_success Std                       0.462635\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.008\n",
      "exploration/env_infos/is_success Std                             0.0890842\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   25269\n",
      "evaluation/num paths total                                     541\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.16466\n",
      "evaluation/Actions Std                                           0.605798\n",
      "evaluation/Actions Max                                           0.999989\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.117027\n",
      "time/evaluation sampling (s)                                    17.987\n",
      "time/exploration sampling (s)                                   36.8635\n",
      "time/logging (s)                                                 0.00925218\n",
      "time/saving (s)                                                  0.0708225\n",
      "time/training (s)                                              197.744\n",
      "time/epoch (s)                                                 252.792\n",
      "time/total (s)                                               12806.7\n",
      "Epoch                                                           49\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n",
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 8\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 50\n",
      "\n",
      " Cycle 0 50\n",
      "Added episode 50\n",
      "Replay buf 51374\n",
      "Soft update 40000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 50\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 51438\n",
      "Soft update 40040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 50\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 51509\n",
      "Soft update 40080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 50\n",
      "Added episode 50\n",
      "Replay buf 51559\n",
      "Soft update 40120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 50\n",
      "Added episode 50\n",
      "Replay buf 51609\n",
      "Soft update 40160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 50\n",
      "Added episode 50\n",
      "Replay buf 51659\n",
      "Soft update 40200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 50\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 51742\n",
      "Soft update 40240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 50\n",
      "Added episode 50\n",
      "Replay buf 51792\n",
      "Soft update 40280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 50\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 51854\n",
      "Soft update 40320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 50\n",
      "Added episode 50\n",
      "Replay buf 51904\n",
      "Soft update 40360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 50\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 20\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 51992\n",
      "Soft update 40400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 50\n",
      "Added episode 50\n",
      "Replay buf 52042\n",
      "Soft update 40440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 50\n",
      "Added episode 50\n",
      "Replay buf 52092\n",
      "Soft update 40480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 50\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 50\n",
      "Replay buf 52158\n",
      "Soft update 40520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 50\n",
      "Added episode 50\n",
      "Replay buf 52208\n",
      "Soft update 40560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 50\n",
      "Added episode 50\n",
      "Replay buf 52258\n",
      "Soft update 40600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 50\n",
      "Added episode 50\n",
      "Replay buf 52308\n",
      "Soft update 40640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 50\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 19\n",
      "Added episode 50\n",
      "Replay buf 52377\n",
      "Soft update 40680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 50\n",
      "Added episode 50\n",
      "Replay buf 52427\n",
      "Soft update 40720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 50\n",
      "Added episode 50\n",
      "Replay buf 52477\n",
      "Soft update 40760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:30:21.333704 EEST | [final-sideways-pixels-final-31] Epoch 50 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.701035\n",
      "trainer/Policy Loss                                              0.00886906\n",
      "trainer/Raw Policy Loss                                          0.00886906\n",
      "trainer/State estimation loss                                    0.00425183\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.09576\n",
      "trainer/Q Predictions Std                                       12.14\n",
      "trainer/Q Predictions Max                                        4.34204\n",
      "trainer/Q Predictions Min                                      -40.158\n",
      "trainer/Q Targets Mean                                          -9.07536\n",
      "trainer/Q Targets Std                                           12.0571\n",
      "trainer/Q Targets Max                                            4.59673\n",
      "trainer/Q Targets Min                                          -38.7854\n",
      "trainer/Bellman Errors Mean                                      0.701035\n",
      "trainer/Bellman Errors Std                                       4.19703\n",
      "trainer/Bellman Errors Max                                     127.265\n",
      "trainer/Bellman Errors Min                                       9.00422e-07\n",
      "trainer/Policy Action Mean                                      -0.138268\n",
      "trainer/Policy Action Std                                        0.634493\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  52477\n",
      "exploration/num paths total                                   1131\n",
      "exploration/path length Mean                                    38.4333\n",
      "exploration/path length Std                                     16.4695\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.991327\n",
      "exploration/Rewards Std                                          0.0927243\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -38.1\n",
      "exploration/Returns Std                                         16.9378\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.186763\n",
      "exploration/Actions Std                                          0.613001\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           30\n",
      "exploration/Average Returns                                    -38.1\n",
      "exploration/env_infos/final/is_success Mean                      0.333333\n",
      "exploration/env_infos/final/is_success Std                       0.471405\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00867303\n",
      "exploration/env_infos/is_success Std                             0.0927243\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   25791\n",
      "evaluation/num paths total                                     557\n",
      "evaluation/path length Mean                                     32.625\n",
      "evaluation/path length Std                                      18.1138\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.984674\n",
      "evaluation/Rewards Std                                           0.122845\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -32.125\n",
      "evaluation/Returns Std                                          18.5939\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.209779\n",
      "evaluation/Actions Std                                           0.555023\n",
      "evaluation/Actions Max                                           0.999794\n",
      "evaluation/Actions Min                                          -0.999999\n",
      "evaluation/Num Paths                                            16\n",
      "evaluation/Average Returns                                     -32.125\n",
      "evaluation/env_infos/final/is_success Mean                       0.5\n",
      "evaluation/env_infos/final/is_success Std                        0.5\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0153257\n",
      "evaluation/env_infos/is_success Std                              0.122845\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.120481\n",
      "time/evaluation sampling (s)                                    16.721\n",
      "time/exploration sampling (s)                                   38.8148\n",
      "time/logging (s)                                                 0.00720194\n",
      "time/saving (s)                                                  0.0708689\n",
      "time/training (s)                                              197.127\n",
      "time/epoch (s)                                                 252.862\n",
      "time/total (s)                                               13059.6\n",
      "Epoch                                                           50\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 51\n",
      "\n",
      " Cycle 0 51\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 52537\n",
      "Soft update 40800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 51\n",
      "Added episode 50\n",
      "Replay buf 52587\n",
      "Soft update 40840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 51\n",
      "Added episode 50\n",
      "Replay buf 52637\n",
      "Soft update 40880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 51\n",
      "Added episode 50\n",
      "Replay buf 52687\n",
      "Soft update 40920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 51\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 52747\n",
      "Soft update 40960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 51\n",
      "Added episode 50\n",
      "Replay buf 52797\n",
      "Soft update 41000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 51\n",
      "Added episode 50\n",
      "Replay buf 52847\n",
      "Soft update 41040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 51\n",
      "Added episode 50\n",
      "Replay buf 52897\n",
      "Soft update 41080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 51\n",
      "Added episode 50\n",
      "Replay buf 52947\n",
      "Soft update 41120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 51\n",
      "Added episode 50\n",
      "Replay buf 52997\n",
      "Soft update 41160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 51\n",
      "Added episode 50\n",
      "Replay buf 53047\n",
      "Soft update 41200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 51\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 53119\n",
      "Soft update 41240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 51\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 9\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 53200\n",
      "Soft update 41280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 51\n",
      "Added episode 50\n",
      "Replay buf 53250\n",
      "Soft update 41320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 51\n",
      "Added episode 50\n",
      "Replay buf 53300\n",
      "Soft update 41360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 51\n",
      "Added episode 50\n",
      "Replay buf 53350\n",
      "Soft update 41400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 51\n",
      "Added episode 50\n",
      "Replay buf 53400\n",
      "Soft update 41440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 51\n",
      "Added episode 50\n",
      "Replay buf 53450\n",
      "Soft update 41480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 51\n",
      "Added episode 50\n",
      "Replay buf 53500\n",
      "Soft update 41520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 51\n",
      "Added episode 50\n",
      "Replay buf 53550\n",
      "Soft update 41560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:34:40.023403 EEST | [final-sideways-pixels-final-31] Epoch 51 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.494334\n",
      "trainer/Policy Loss                                            nan\n",
      "trainer/Raw Policy Loss                                        nan\n",
      "trainer/State estimation loss                                    0.00360063\n",
      "trainer/Preactivation Policy Loss                              nan\n",
      "trainer/Q Predictions Mean                                      -8.89344\n",
      "trainer/Q Predictions Std                                       11.99\n",
      "trainer/Q Predictions Max                                       12.0115\n",
      "trainer/Q Predictions Min                                      -39.8589\n",
      "trainer/Q Targets Mean                                          -8.93068\n",
      "trainer/Q Targets Std                                           12.0265\n",
      "trainer/Q Targets Max                                           12.2924\n",
      "trainer/Q Targets Min                                          -39.8103\n",
      "trainer/Bellman Errors Mean                                      0.494334\n",
      "trainer/Bellman Errors Std                                       1.77429\n",
      "trainer/Bellman Errors Max                                      37.6846\n",
      "trainer/Bellman Errors Min                                       1.38956e-07\n",
      "trainer/Policy Action Mean                                      -0.156296\n",
      "trainer/Policy Action Std                                        0.688341\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  53550\n",
      "exploration/num paths total                                   1158\n",
      "exploration/path length Mean                                    39.7407\n",
      "exploration/path length Std                                     17.3538\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.993476\n",
      "exploration/Rewards Std                                          0.0805059\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -39.4815\n",
      "exploration/Returns Std                                         17.7917\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.169574\n",
      "exploration/Actions Std                                          0.639462\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           27\n",
      "exploration/Average Returns                                    -39.4815\n",
      "exploration/env_infos/final/is_success Mean                      0.259259\n",
      "exploration/env_infos/final/is_success Std                       0.438228\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00652376\n",
      "exploration/env_infos/is_success Std                             0.0805059\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   26318\n",
      "evaluation/num paths total                                     569\n",
      "evaluation/path length Mean                                     43.9167\n",
      "evaluation/path length Std                                      13.6776\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.996205\n",
      "evaluation/Rewards Std                                           0.0614871\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -43.75\n",
      "evaluation/Returns Std                                          14.0483\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.261187\n",
      "evaluation/Actions Std                                           0.631081\n",
      "evaluation/Actions Max                                           0.999999\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            12\n",
      "evaluation/Average Returns                                     -43.75\n",
      "evaluation/env_infos/final/is_success Mean                       0.166667\n",
      "evaluation/env_infos/final/is_success Std                        0.372678\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00379507\n",
      "evaluation/env_infos/is_success Std                              0.0614871\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.118285\n",
      "time/evaluation sampling (s)                                    17.9896\n",
      "time/exploration sampling (s)                                   35.4135\n",
      "time/logging (s)                                                 0.00995611\n",
      "time/saving (s)                                                  0.0731342\n",
      "time/training (s)                                              205.082\n",
      "time/epoch (s)                                                 258.687\n",
      "time/total (s)                                               13318.3\n",
      "Epoch                                                           51\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 8\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 52\n",
      "\n",
      " Cycle 0 52\n",
      "Added episode 50\n",
      "Replay buf 53600\n",
      "Soft update 41600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 52\n",
      "Added episode 50\n",
      "Replay buf 53650\n",
      "Soft update 41640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 52\n",
      "Added episode 50\n",
      "Replay buf 53700\n",
      "Soft update 41680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 52\n",
      "Added episode 50\n",
      "Replay buf 53750\n",
      "Soft update 41720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 52\n",
      "Added episode 50\n",
      "Replay buf 53800\n",
      "Soft update 41760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 52\n",
      "Added episode 50\n",
      "Replay buf 53850\n",
      "Soft update 41800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 52\n",
      "Added episode 50\n",
      "Replay buf 53900\n",
      "Soft update 41840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 52\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 42\n",
      "Added episode 50\n",
      "Replay buf 53992\n",
      "Soft update 41880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 52\n",
      "Added episode 50\n",
      "Replay buf 54042\n",
      "Soft update 41920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 52\n",
      "Added episode 50\n",
      "Replay buf 54092\n",
      "Soft update 41960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 52\n",
      "Added episode 50\n",
      "Replay buf 54142\n",
      "Soft update 42000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 52\n",
      "Added episode 50\n",
      "Replay buf 54192\n",
      "Soft update 42040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 52\n",
      "Added episode 50\n",
      "Replay buf 54242\n",
      "Soft update 42080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 52\n",
      "Added episode 50\n",
      "Replay buf 54292\n",
      "Soft update 42120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 52\n",
      "Added episode 50\n",
      "Replay buf 54342\n",
      "Soft update 42160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 52\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 50\n",
      "Replay buf 54409\n",
      "Soft update 42200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 52\n",
      "Added episode 50\n",
      "Replay buf 54459\n",
      "Soft update 42240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 52\n",
      "Added episode 50\n",
      "Replay buf 54509\n",
      "Soft update 42280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 52\n",
      "Added episode 50\n",
      "Replay buf 54559\n",
      "Soft update 42320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 52\n",
      "Added episode 50\n",
      "Replay buf 54609\n",
      "Soft update 42360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:38:55.844630 EEST | [final-sideways-pixels-final-31] Epoch 52 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.816709\n",
      "trainer/Policy Loss                                              0.00901942\n",
      "trainer/Raw Policy Loss                                          0.00901942\n",
      "trainer/State estimation loss                                    0.00377319\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.39241\n",
      "trainer/Q Predictions Std                                       12.5326\n",
      "trainer/Q Predictions Max                                        4.77292\n",
      "trainer/Q Predictions Min                                      -40.555\n",
      "trainer/Q Targets Mean                                          -9.55592\n",
      "trainer/Q Targets Std                                           12.6774\n",
      "trainer/Q Targets Max                                            5.7109\n",
      "trainer/Q Targets Min                                          -40.0742\n",
      "trainer/Bellman Errors Mean                                      0.816709\n",
      "trainer/Bellman Errors Std                                       5.75224\n",
      "trainer/Bellman Errors Max                                     168.696\n",
      "trainer/Bellman Errors Min                                       2.59761e-08\n",
      "trainer/Policy Action Mean                                      -0.18665\n",
      "trainer/Policy Action Std                                        0.678889\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  54609\n",
      "exploration/num paths total                                   1180\n",
      "exploration/path length Mean                                    48.1364\n",
      "exploration/path length Std                                      6.99542\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     17\n",
      "exploration/Rewards Mean                                        -0.998111\n",
      "exploration/Rewards Std                                          0.0434167\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -48.0455\n",
      "exploration/Returns Std                                          7.23927\n",
      "exploration/Returns Max                                        -16\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.180465\n",
      "exploration/Actions Std                                          0.61738\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           22\n",
      "exploration/Average Returns                                    -48.0455\n",
      "exploration/env_infos/final/is_success Mean                      0.0909091\n",
      "exploration/env_infos/final/is_success Std                       0.28748\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00188857\n",
      "exploration/env_infos/is_success Std                             0.0434167\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   26857\n",
      "evaluation/num paths total                                     592\n",
      "evaluation/path length Mean                                     23.4348\n",
      "evaluation/path length Std                                      16.3277\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.966605\n",
      "evaluation/Rewards Std                                           0.179666\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -22.6522\n",
      "evaluation/Returns Std                                          16.6827\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.273462\n",
      "evaluation/Actions Std                                           0.670913\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            23\n",
      "evaluation/Average Returns                                     -22.6522\n",
      "evaluation/env_infos/final/is_success Mean                       0.782609\n",
      "evaluation/env_infos/final/is_success Std                        0.412471\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0333952\n",
      "evaluation/env_infos/is_success Std                              0.179666\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.11391\n",
      "time/evaluation sampling (s)                                    18.2852\n",
      "time/exploration sampling (s)                                   35.4485\n",
      "time/logging (s)                                                 0.00720134\n",
      "time/saving (s)                                                  0.0748001\n",
      "time/training (s)                                              201.882\n",
      "time/epoch (s)                                                 255.812\n",
      "time/total (s)                                               13574.1\n",
      "Epoch                                                           52\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 53\n",
      "\n",
      " Cycle 0 53\n",
      "Added episode 50\n",
      "Replay buf 54659\n",
      "Soft update 42400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 53\n",
      "Added episode 50\n",
      "Replay buf 54709\n",
      "Soft update 42440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 53\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 50\n",
      "Replay buf 54776\n",
      "Soft update 42480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 53\n",
      "Added episode 50\n",
      "Replay buf 54826\n",
      "Soft update 42520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 53\n",
      "Added episode 50\n",
      "Replay buf 54876\n",
      "Soft update 42560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 53\n",
      "Added episode 50\n",
      "Replay buf 54926\n",
      "Soft update 42600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 53\n",
      "Added episode 50\n",
      "Replay buf 54976\n",
      "Soft update 42640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 53\n",
      "Added episode 50\n",
      "Replay buf 55026\n",
      "Soft update 42680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 53\n",
      "Added episode 50\n",
      "Replay buf 55076\n",
      "Soft update 42720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 53\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 55136\n",
      "Soft update 42760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 53\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 55210\n",
      "Soft update 42800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 53\n",
      "Added episode 50\n",
      "Replay buf 55260\n",
      "Soft update 42840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 53\n",
      "Added episode 50\n",
      "Replay buf 55310\n",
      "Soft update 42880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 53\n",
      "Added episode 50\n",
      "Replay buf 55360\n",
      "Soft update 42920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 53\n",
      "Added episode 50\n",
      "Replay buf 55410\n",
      "Soft update 42960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 53\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 28\n",
      "Added episode 50\n",
      "Replay buf 55488\n",
      "Soft update 43000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 53\n",
      "Added episode 50\n",
      "Replay buf 55538\n",
      "Soft update 43040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 53\n",
      "Added episode 50\n",
      "Replay buf 55588\n",
      "Soft update 43080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 53\n",
      "Added episode 50\n",
      "Replay buf 55638\n",
      "Soft update 43120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 53\n",
      "Added episode 50\n",
      "Replay buf 55688\n",
      "Soft update 43160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:43:14.788912 EEST | [final-sideways-pixels-final-31] Epoch 53 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.796412\n",
      "trainer/Policy Loss                                              0.00945753\n",
      "trainer/Raw Policy Loss                                          0.00945753\n",
      "trainer/State estimation loss                                    0.00383922\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.76816\n",
      "trainer/Q Predictions Std                                       12.7328\n",
      "trainer/Q Predictions Max                                        7.20975\n",
      "trainer/Q Predictions Min                                      -42.1113\n",
      "trainer/Q Targets Mean                                          -9.6221\n",
      "trainer/Q Targets Std                                           12.6986\n",
      "trainer/Q Targets Max                                            7.11502\n",
      "trainer/Q Targets Min                                          -41.1469\n",
      "trainer/Bellman Errors Mean                                      0.796412\n",
      "trainer/Bellman Errors Std                                       3.31743\n",
      "trainer/Bellman Errors Max                                      63.8963\n",
      "trainer/Bellman Errors Min                                       5.00735e-07\n",
      "trainer/Policy Action Mean                                      -0.146804\n",
      "trainer/Policy Action Std                                        0.672542\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  55688\n",
      "exploration/num paths total                                   1205\n",
      "exploration/path length Mean                                    43.16\n",
      "exploration/path length Std                                     13.9905\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.995366\n",
      "exploration/Rewards Std                                          0.067915\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -42.96\n",
      "exploration/Returns Std                                         14.3819\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.182333\n",
      "exploration/Actions Std                                          0.606021\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           25\n",
      "exploration/Average Returns                                    -42.96\n",
      "exploration/env_infos/final/is_success Mean                      0.2\n",
      "exploration/env_infos/final/is_success Std                       0.4\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00463392\n",
      "exploration/env_infos/is_success Std                             0.067915\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   27359\n",
      "evaluation/num paths total                                     606\n",
      "evaluation/path length Mean                                     35.8571\n",
      "evaluation/path length Std                                      18.9807\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.99004\n",
      "evaluation/Rewards Std                                           0.0993023\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -35.5\n",
      "evaluation/Returns Std                                          19.4597\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.175817\n",
      "evaluation/Actions Std                                           0.664479\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            14\n",
      "evaluation/Average Returns                                     -35.5\n",
      "evaluation/env_infos/final/is_success Mean                       0.357143\n",
      "evaluation/env_infos/final/is_success Std                        0.479157\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00996016\n",
      "evaluation/env_infos/is_success Std                              0.0993023\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.11567\n",
      "time/evaluation sampling (s)                                    16.8315\n",
      "time/exploration sampling (s)                                   37.6893\n",
      "time/logging (s)                                                 0.00693603\n",
      "time/saving (s)                                                  0.0692368\n",
      "time/training (s)                                              204.226\n",
      "time/epoch (s)                                                 258.939\n",
      "time/total (s)                                               13833.1\n",
      "Epoch                                                           53\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 54\n",
      "\n",
      " Cycle 0 54\n",
      "Added episode 50\n",
      "Replay buf 55738\n",
      "Soft update 43200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 54\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 25\n",
      "Added episode 50\n",
      "Replay buf 55813\n",
      "Soft update 43240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 54\n",
      "Added episode 50\n",
      "Replay buf 55863\n",
      "Soft update 43280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 54\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 55925\n",
      "Soft update 43320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 54\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 55990\n",
      "Soft update 43360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 54\n",
      "Added episode 50\n",
      "Replay buf 56040\n",
      "Soft update 43400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 54\n",
      "Added episode 50\n",
      "Replay buf 56090\n",
      "Soft update 43440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 54\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 56152\n",
      "Soft update 43480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 54\n",
      "Added episode 50\n",
      "Replay buf 56202\n",
      "Soft update 43520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 54\n",
      "Added episode 50\n",
      "Replay buf 56252\n",
      "Soft update 43560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 54\n",
      "Added episode 50\n",
      "Replay buf 56302\n",
      "Soft update 43600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 54\n",
      "Added episode 50\n",
      "Replay buf 56352\n",
      "Soft update 43640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 54\n",
      "Added episode 50\n",
      "Replay buf 56402\n",
      "Soft update 43680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 54\n",
      "Added episode 50\n",
      "Replay buf 56452\n",
      "Soft update 43720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 54\n",
      "Added episode 50\n",
      "Replay buf 56502\n",
      "Soft update 43760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 54\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 56562\n",
      "Soft update 43800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 54\n",
      "Added episode 50\n",
      "Replay buf 56612\n",
      "Soft update 43840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 54\n",
      "Added episode 50\n",
      "Replay buf 56662\n",
      "Soft update 43880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 54\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 56721\n",
      "Soft update 43920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 54\n",
      "Added episode 50\n",
      "Replay buf 56771\n",
      "Soft update 43960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:47:32.975562 EEST | [final-sideways-pixels-final-31] Epoch 54 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.650799\n",
      "trainer/Policy Loss                                              0.00934638\n",
      "trainer/Raw Policy Loss                                          0.00934638\n",
      "trainer/State estimation loss                                    0.00367838\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.63766\n",
      "trainer/Q Predictions Std                                       12.7022\n",
      "trainer/Q Predictions Max                                        9.66524\n",
      "trainer/Q Predictions Min                                      -41.8933\n",
      "trainer/Q Targets Mean                                          -9.53639\n",
      "trainer/Q Targets Std                                           12.6369\n",
      "trainer/Q Targets Max                                            9.6322\n",
      "trainer/Q Targets Min                                          -41.4768\n",
      "trainer/Bellman Errors Mean                                      0.650799\n",
      "trainer/Bellman Errors Std                                       2.50909\n",
      "trainer/Bellman Errors Max                                      52.3067\n",
      "trainer/Bellman Errors Min                                       3.00963e-07\n",
      "trainer/Policy Action Mean                                      -0.154999\n",
      "trainer/Policy Action Std                                        0.678241\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  56771\n",
      "exploration/num paths total                                   1231\n",
      "exploration/path length Mean                                    41.6538\n",
      "exploration/path length Std                                     15.452\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.99446\n",
      "exploration/Rewards Std                                          0.0742258\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -41.4231\n",
      "exploration/Returns Std                                         15.8677\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.194221\n",
      "exploration/Actions Std                                          0.623411\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           26\n",
      "exploration/Average Returns                                    -41.4231\n",
      "exploration/env_infos/final/is_success Mean                      0.230769\n",
      "exploration/env_infos/final/is_success Std                       0.421325\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00554017\n",
      "exploration/env_infos/is_success Std                             0.0742258\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   27889\n",
      "evaluation/num paths total                                     618\n",
      "evaluation/path length Mean                                     44.1667\n",
      "evaluation/path length Std                                      13.1011\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      12\n",
      "evaluation/Rewards Mean                                         -0.996226\n",
      "evaluation/Rewards Std                                           0.0613135\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -44\n",
      "evaluation/Returns Std                                          13.4722\n",
      "evaluation/Returns Max                                         -11\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.198701\n",
      "evaluation/Actions Std                                           0.611031\n",
      "evaluation/Actions Max                                           0.999986\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            12\n",
      "evaluation/Average Returns                                     -44\n",
      "evaluation/env_infos/final/is_success Mean                       0.166667\n",
      "evaluation/env_infos/final/is_success Std                        0.372678\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00377358\n",
      "evaluation/env_infos/is_success Std                              0.0613135\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.116101\n",
      "time/evaluation sampling (s)                                    18.5131\n",
      "time/exploration sampling (s)                                   36.0861\n",
      "time/logging (s)                                                 0.00703643\n",
      "time/saving (s)                                                  0.0728013\n",
      "time/training (s)                                              203.386\n",
      "time/epoch (s)                                                 258.181\n",
      "time/total (s)                                               14091.2\n",
      "Epoch                                                           54\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 55\n",
      "\n",
      " Cycle 0 55\n",
      "Added episode 50\n",
      "Replay buf 56821\n",
      "Soft update 44000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 55\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 56884\n",
      "Soft update 44040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 55\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 56945\n",
      "Soft update 44080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 55\n",
      "Added episode 50\n",
      "Replay buf 56995\n",
      "Soft update 44120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 55\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 57069\n",
      "Soft update 44160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 55\n",
      "Added episode 50\n",
      "Replay buf 57119\n",
      "Soft update 44200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 55\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 20\n",
      "Added episode 50\n",
      "Replay buf 57189\n",
      "Soft update 44240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 55\n",
      "Added episode 50\n",
      "Replay buf 57239\n",
      "Soft update 44280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 55\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 57315\n",
      "Soft update 44320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 55\n",
      "Added episode 50\n",
      "Replay buf 57365\n",
      "Soft update 44360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 55\n",
      "Added episode 50\n",
      "Replay buf 57415\n",
      "Soft update 44400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 55\n",
      "Added episode 50\n",
      "Replay buf 57465\n",
      "Soft update 44440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 55\n",
      "Added episode 50\n",
      "Replay buf 57515\n",
      "Soft update 44480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 55\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 22\n",
      "Added episode 50\n",
      "Replay buf 57587\n",
      "Soft update 44520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 55\n",
      "Added episode 50\n",
      "Replay buf 57637\n",
      "Soft update 44560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 55\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 57700\n",
      "Soft update 44600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 55\n",
      "Added episode 50\n",
      "Replay buf 57750\n",
      "Soft update 44640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 55\n",
      "Added episode 50\n",
      "Replay buf 57800\n",
      "Soft update 44680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 55\n",
      "Added episode 50\n",
      "Replay buf 57850\n",
      "Soft update 44720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 55\n",
      "Added episode 50\n",
      "Replay buf 57900\n",
      "Soft update 44760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:51:51.379784 EEST | [final-sideways-pixels-final-31] Epoch 55 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.10703\n",
      "trainer/Policy Loss                                              0.00938018\n",
      "trainer/Raw Policy Loss                                          0.00938018\n",
      "trainer/State estimation loss                                    0.00363586\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.56159\n",
      "trainer/Q Predictions Std                                       13.3284\n",
      "trainer/Q Predictions Max                                       13.6472\n",
      "trainer/Q Predictions Min                                      -43.1929\n",
      "trainer/Q Targets Mean                                          -9.52858\n",
      "trainer/Q Targets Std                                           13.1044\n",
      "trainer/Q Targets Max                                           13.1602\n",
      "trainer/Q Targets Min                                          -43.5698\n",
      "trainer/Bellman Errors Mean                                      1.10703\n",
      "trainer/Bellman Errors Std                                       8.40996\n",
      "trainer/Bellman Errors Max                                     186.525\n",
      "trainer/Bellman Errors Min                                       5.39414e-07\n",
      "trainer/Policy Action Mean                                      -0.208017\n",
      "trainer/Policy Action Std                                        0.664954\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  57900\n",
      "exploration/num paths total                                   1260\n",
      "exploration/path length Mean                                    38.931\n",
      "exploration/path length Std                                     16.6276\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     11\n",
      "exploration/Rewards Mean                                        -0.992028\n",
      "exploration/Rewards Std                                          0.0889275\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -38.6207\n",
      "exploration/Returns Std                                         17.0868\n",
      "exploration/Returns Max                                        -10\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.192077\n",
      "exploration/Actions Std                                          0.615532\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           29\n",
      "exploration/Average Returns                                    -38.6207\n",
      "exploration/env_infos/final/is_success Mean                      0.310345\n",
      "exploration/env_infos/final/is_success Std                       0.462635\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00797166\n",
      "exploration/env_infos/is_success Std                             0.0889275\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   28389\n",
      "evaluation/num paths total                                     628\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.240245\n",
      "evaluation/Actions Std                                           0.647566\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.119688\n",
      "time/evaluation sampling (s)                                    16.2538\n",
      "time/exploration sampling (s)                                   38.5902\n",
      "time/logging (s)                                                 0.00929816\n",
      "time/saving (s)                                                  0.0725752\n",
      "time/training (s)                                              203.355\n",
      "time/epoch (s)                                                 258.401\n",
      "time/total (s)                                               14349.7\n",
      "Epoch                                                           55\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 56\n",
      "\n",
      " Cycle 0 56\n",
      "Added episode 50\n",
      "Replay buf 57950\n",
      "Soft update 44800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 56\n",
      "Added episode 50\n",
      "Replay buf 58000\n",
      "Soft update 44840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 56\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 25\n",
      "Added episode 50\n",
      "Replay buf 58075\n",
      "Soft update 44880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 56\n",
      "Added episode 50\n",
      "Replay buf 58125\n",
      "Soft update 44920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 56\n",
      "Added episode 50\n",
      "Replay buf 58175\n",
      "Soft update 44960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 56\n",
      "Added episode 50\n",
      "Replay buf 58225\n",
      "Soft update 45000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 56\n",
      "Added episode 50\n",
      "Replay buf 58275\n",
      "Soft update 45040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 56\n",
      "Added episode 50\n",
      "Replay buf 58325\n",
      "Soft update 45080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 56\n",
      "Added episode 50\n",
      "Replay buf 58375\n",
      "Soft update 45120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 56\n",
      "Added episode 50\n",
      "Replay buf 58425\n",
      "Soft update 45160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 56\n",
      "Added episode 50\n",
      "Replay buf 58475\n",
      "Soft update 45200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 56\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 30\n",
      "Added episode 50\n",
      "Replay buf 58555\n",
      "Soft update 45240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 56\n",
      "Added episode 50\n",
      "Replay buf 58605\n",
      "Soft update 45280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 56\n",
      "Added episode 50\n",
      "Replay buf 58655\n",
      "Soft update 45320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 56\n",
      "Added episode 50\n",
      "Replay buf 58705\n",
      "Soft update 45360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 56\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 58768\n",
      "Soft update 45400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 56\n",
      "Added episode 50\n",
      "Replay buf 58818\n",
      "Soft update 45440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 56\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 15\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 58905\n",
      "Soft update 45480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 56\n",
      "Added episode 50\n",
      "Replay buf 58955\n",
      "Soft update 45520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 56\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 59032\n",
      "Soft update 45560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 12:56:05.044578 EEST | [final-sideways-pixels-final-31] Epoch 56 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.10013\n",
      "trainer/Policy Loss                                              0.00907542\n",
      "trainer/Raw Policy Loss                                          0.00907542\n",
      "trainer/State estimation loss                                    0.00352719\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.38096\n",
      "trainer/Q Predictions Std                                       12.949\n",
      "trainer/Q Predictions Max                                       13.1607\n",
      "trainer/Q Predictions Min                                      -44.4238\n",
      "trainer/Q Targets Mean                                          -9.35215\n",
      "trainer/Q Targets Std                                           12.9637\n",
      "trainer/Q Targets Max                                           14.0851\n",
      "trainer/Q Targets Min                                          -44.3366\n",
      "trainer/Bellman Errors Mean                                      1.10013\n",
      "trainer/Bellman Errors Std                                       7.8236\n",
      "trainer/Bellman Errors Max                                     199.282\n",
      "trainer/Bellman Errors Min                                       2.52234e-07\n",
      "trainer/Policy Action Mean                                      -0.142528\n",
      "trainer/Policy Action Std                                        0.674769\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  59032\n",
      "exploration/num paths total                                   1288\n",
      "exploration/path length Mean                                    40.4286\n",
      "exploration/path length Std                                     15.5459\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.992933\n",
      "exploration/Rewards Std                                          0.0837687\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -40.1429\n",
      "exploration/Returns Std                                         15.986\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.172891\n",
      "exploration/Actions Std                                          0.615041\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           28\n",
      "exploration/Average Returns                                    -40.1429\n",
      "exploration/env_infos/final/is_success Mean                      0.285714\n",
      "exploration/env_infos/final/is_success Std                       0.451754\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00706714\n",
      "exploration/env_infos/is_success Std                             0.0837687\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   28889\n",
      "evaluation/num paths total                                     638\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.230369\n",
      "evaluation/Actions Std                                           0.643979\n",
      "evaluation/Actions Max                                           0.999945\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.118966\n",
      "time/evaluation sampling (s)                                    16.5814\n",
      "time/exploration sampling (s)                                   37.5745\n",
      "time/logging (s)                                                 0.00699428\n",
      "time/saving (s)                                                  0.0715568\n",
      "time/training (s)                                              199.302\n",
      "time/epoch (s)                                                 253.656\n",
      "time/total (s)                                               14603.3\n",
      "Epoch                                                           56\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 57\n",
      "\n",
      " Cycle 0 57\n",
      "Added episode 50\n",
      "Replay buf 59082\n",
      "Soft update 45600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 57\n",
      "Added episode 50\n",
      "Replay buf 59132\n",
      "Soft update 45640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 57\n",
      "Added episode 50\n",
      "Replay buf 59182\n",
      "Soft update 45680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 57\n",
      "Added episode 50\n",
      "Replay buf 59232\n",
      "Soft update 45720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 57\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 24\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 59318\n",
      "Soft update 45760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 57\n",
      "Added episode 50\n",
      "Replay buf 59368\n",
      "Soft update 45800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 57\n",
      "Added episode 50\n",
      "Replay buf 59418\n",
      "Soft update 45840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 57\n",
      "Added episode 50\n",
      "Replay buf 59468\n",
      "Soft update 45880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 57\n",
      "Added episode 50\n",
      "Replay buf 59518\n",
      "Soft update 45920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 57\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 19\n",
      "Added episode 11\n",
      "Added episode 12\n",
      "Added episode 10\n",
      "Replay buf 59570\n",
      "Soft update 45960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 57\n",
      "Added episode 50\n",
      "Replay buf 59620\n",
      "Soft update 46000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 57\n",
      "Added episode 50\n",
      "Replay buf 59670\n",
      "Soft update 46040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 57\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 59732\n",
      "Soft update 46080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 57\n",
      "Added episode 50\n",
      "Replay buf 59782\n",
      "Soft update 46120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 57\n",
      "Added episode 50\n",
      "Replay buf 59832\n",
      "Soft update 46160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 57\n",
      "Added episode 50\n",
      "Replay buf 59882\n",
      "Soft update 46200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 57\n",
      "Added episode 50\n",
      "Replay buf 59932\n",
      "Soft update 46240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 57\n",
      "Added episode 50\n",
      "Replay buf 59982\n",
      "Soft update 46280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 57\n",
      "Added episode 50\n",
      "Replay buf 60032\n",
      "Soft update 46320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 57\n",
      "Added episode 50\n",
      "Replay buf 60082\n",
      "Soft update 46360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:00:14.282632 EEST | [final-sideways-pixels-final-31] Epoch 57 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.44738\n",
      "trainer/Policy Loss                                              0.00956819\n",
      "trainer/Raw Policy Loss                                          0.00956819\n",
      "trainer/State estimation loss                                    0.00399586\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.76402\n",
      "trainer/Q Predictions Std                                       13.257\n",
      "trainer/Q Predictions Max                                        7.37481\n",
      "trainer/Q Predictions Min                                      -43.9972\n",
      "trainer/Q Targets Mean                                          -9.72546\n",
      "trainer/Q Targets Std                                           13.3742\n",
      "trainer/Q Targets Max                                            7.54558\n",
      "trainer/Q Targets Min                                          -44.1455\n",
      "trainer/Bellman Errors Mean                                      1.44738\n",
      "trainer/Bellman Errors Std                                      15.2499\n",
      "trainer/Bellman Errors Max                                     364.502\n",
      "trainer/Bellman Errors Min                                       3.37025e-08\n",
      "trainer/Policy Action Mean                                      -0.163681\n",
      "trainer/Policy Action Std                                        0.658739\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  60082\n",
      "exploration/num paths total                                   1314\n",
      "exploration/path length Mean                                    40.3846\n",
      "exploration/path length Std                                     16.0362\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.993333\n",
      "exploration/Rewards Std                                          0.081377\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -40.1154\n",
      "exploration/Returns Std                                         16.4745\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.181502\n",
      "exploration/Actions Std                                          0.609176\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           26\n",
      "exploration/Average Returns                                    -40.1154\n",
      "exploration/env_infos/final/is_success Mean                      0.269231\n",
      "exploration/env_infos/final/is_success Std                       0.44356\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00666667\n",
      "exploration/env_infos/is_success Std                             0.081377\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   29412\n",
      "evaluation/num paths total                                     649\n",
      "evaluation/path length Mean                                     47.5455\n",
      "evaluation/path length Std                                       7.76195\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      23\n",
      "evaluation/Rewards Mean                                         -0.998088\n",
      "evaluation/Rewards Std                                           0.0436851\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -47.4545\n",
      "evaluation/Returns Std                                           8.04944\n",
      "evaluation/Returns Max                                         -22\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.206296\n",
      "evaluation/Actions Std                                           0.597073\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            11\n",
      "evaluation/Average Returns                                     -47.4545\n",
      "evaluation/env_infos/final/is_success Mean                       0.0909091\n",
      "evaluation/env_infos/final/is_success Std                        0.28748\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00191205\n",
      "evaluation/env_infos/is_success Std                              0.0436851\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.107575\n",
      "time/evaluation sampling (s)                                    17.1099\n",
      "time/exploration sampling (s)                                   34.9932\n",
      "time/logging (s)                                                 0.00698409\n",
      "time/saving (s)                                                  0.07097\n",
      "time/training (s)                                              196.944\n",
      "time/epoch (s)                                                 249.232\n",
      "time/total (s)                                               14852.6\n",
      "Epoch                                                           57\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 58\n",
      "\n",
      " Cycle 0 58\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 33\n",
      "Added episode 50\n",
      "Replay buf 60165\n",
      "Soft update 46400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 58\n",
      "Added episode 50\n",
      "Replay buf 60215\n",
      "Soft update 46440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 58\n",
      "Added episode 50\n",
      "Replay buf 60265\n",
      "Soft update 46480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 58\n",
      "Added episode 50\n",
      "Replay buf 60315\n",
      "Soft update 46520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 58\n",
      "Added episode 50\n",
      "Replay buf 60365\n",
      "Soft update 46560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 58\n",
      "Added episode 50\n",
      "Replay buf 60415\n",
      "Soft update 46600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 58\n",
      "Added episode 50\n",
      "Replay buf 60465\n",
      "Soft update 46640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 58\n",
      "Added episode 50\n",
      "Replay buf 60515\n",
      "Soft update 46680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 58\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 60586\n",
      "Soft update 46720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 58\n",
      "Added episode 50\n",
      "Replay buf 60636\n",
      "Soft update 46760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 58\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 50\n",
      "Replay buf 60703\n",
      "Soft update 46800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 58\n",
      "Added episode 50\n",
      "Replay buf 60753\n",
      "Soft update 46840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 58\n",
      "Added episode 50\n",
      "Replay buf 60803\n",
      "Soft update 46880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 58\n",
      "Added episode 50\n",
      "Replay buf 60853\n",
      "Soft update 46920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 58\n",
      "Added episode 50\n",
      "Replay buf 60903\n",
      "Soft update 46960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 58\n",
      "Added episode 50\n",
      "Replay buf 60953\n",
      "Soft update 47000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 58\n",
      "Added episode 50\n",
      "Replay buf 61003\n",
      "Soft update 47040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 58\n",
      "Added episode 50\n",
      "Replay buf 61053\n",
      "Soft update 47080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 58\n",
      "Added episode 50\n",
      "Replay buf 61103\n",
      "Soft update 47120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 58\n",
      "Added episode 50\n",
      "Replay buf 61153\n",
      "Soft update 47160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:04:28.165924 EEST | [final-sideways-pixels-final-31] Epoch 58 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.992991\n",
      "trainer/Policy Loss                                            nan\n",
      "trainer/Raw Policy Loss                                        nan\n",
      "trainer/State estimation loss                                    0.00395861\n",
      "trainer/Preactivation Policy Loss                              nan\n",
      "trainer/Q Predictions Mean                                      -9.41415\n",
      "trainer/Q Predictions Std                                       12.9972\n",
      "trainer/Q Predictions Max                                       13.4322\n",
      "trainer/Q Predictions Min                                      -44.4465\n",
      "trainer/Q Targets Mean                                          -9.33157\n",
      "trainer/Q Targets Std                                           13.0553\n",
      "trainer/Q Targets Max                                           13.2927\n",
      "trainer/Q Targets Min                                          -44.7305\n",
      "trainer/Bellman Errors Mean                                      0.992991\n",
      "trainer/Bellman Errors Std                                       5.94578\n",
      "trainer/Bellman Errors Max                                     153.836\n",
      "trainer/Bellman Errors Min                                       1.35647e-08\n",
      "trainer/Policy Action Mean                                      -0.134021\n",
      "trainer/Policy Action Std                                        0.675431\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  61153\n",
      "exploration/num paths total                                   1338\n",
      "exploration/path length Mean                                    44.625\n",
      "exploration/path length Std                                     12.5924\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.996265\n",
      "exploration/Rewards Std                                          0.060999\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -44.4583\n",
      "exploration/Returns Std                                         12.9485\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.199063\n",
      "exploration/Actions Std                                          0.610378\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           24\n",
      "exploration/Average Returns                                    -44.4583\n",
      "exploration/env_infos/final/is_success Mean                      0.166667\n",
      "exploration/env_infos/final/is_success Std                       0.372678\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00373483\n",
      "exploration/env_infos/is_success Std                             0.060999\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   29948\n",
      "evaluation/num paths total                                     665\n",
      "evaluation/path length Mean                                     33.5\n",
      "evaluation/path length Std                                      18.7483\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.98694\n",
      "evaluation/Rewards Std                                           0.11353\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -33.0625\n",
      "evaluation/Returns Std                                          19.2434\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.185217\n",
      "evaluation/Actions Std                                           0.632276\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            16\n",
      "evaluation/Average Returns                                     -33.0625\n",
      "evaluation/env_infos/final/is_success Mean                       0.4375\n",
      "evaluation/env_infos/final/is_success Std                        0.496078\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0130597\n",
      "evaluation/env_infos/is_success Std                              0.11353\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.112446\n",
      "time/evaluation sampling (s)                                    17.4058\n",
      "time/exploration sampling (s)                                   35.5768\n",
      "time/logging (s)                                                 0.00710344\n",
      "time/saving (s)                                                  0.0709211\n",
      "time/training (s)                                              200.705\n",
      "time/epoch (s)                                                 253.878\n",
      "time/total (s)                                               15106.4\n",
      "Epoch                                                           58\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 59\n",
      "\n",
      " Cycle 0 59\n",
      "Added episode 50\n",
      "Replay buf 61203\n",
      "Soft update 47200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 59\n",
      "Added episode 50\n",
      "Replay buf 61253\n",
      "Soft update 47240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 59\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 24\n",
      "Added episode 50\n",
      "Replay buf 61327\n",
      "Soft update 47280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 59\n",
      "Added episode 50\n",
      "Replay buf 61377\n",
      "Soft update 47320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 59\n",
      "Added episode 50\n",
      "Replay buf 61427\n",
      "Soft update 47360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 59\n",
      "Added episode 50\n",
      "Replay buf 61477\n",
      "Soft update 47400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 59\n",
      "Added episode 50\n",
      "Replay buf 61527\n",
      "Soft update 47440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 59\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 61603\n",
      "Soft update 47480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 59\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 13\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 61689\n",
      "Soft update 47520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 59\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 61750\n",
      "Soft update 47560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 59\n",
      "Added episode 50\n",
      "Replay buf 61800\n",
      "Soft update 47600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 59\n",
      "Added episode 50\n",
      "Replay buf 61850\n",
      "Soft update 47640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 59\n",
      "Added episode 50\n",
      "Replay buf 61900\n",
      "Soft update 47680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 59\n",
      "Added episode 50\n",
      "Replay buf 61950\n",
      "Soft update 47720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 59\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 42\n",
      "Added episode 10\n",
      "Replay buf 62002\n",
      "Soft update 47760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 59\n",
      "Added episode 50\n",
      "Replay buf 62052\n",
      "Soft update 47800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 59\n",
      "Added episode 50\n",
      "Replay buf 62102\n",
      "Soft update 47840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 59\n",
      "Added episode 50\n",
      "Replay buf 62152\n",
      "Soft update 47880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 59\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 62214\n",
      "Soft update 47920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 59\n",
      "Added episode 50\n",
      "Replay buf 62264\n",
      "Soft update 47960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:08:44.360622 EEST | [final-sideways-pixels-final-31] Epoch 59 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.19524\n",
      "trainer/Policy Loss                                              0.0095126\n",
      "trainer/Raw Policy Loss                                          0.0095126\n",
      "trainer/State estimation loss                                    0.00396552\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.78362\n",
      "trainer/Q Predictions Std                                       13.2783\n",
      "trainer/Q Predictions Max                                        8.06847\n",
      "trainer/Q Predictions Min                                      -46.1117\n",
      "trainer/Q Targets Mean                                          -9.81395\n",
      "trainer/Q Targets Std                                           13.4281\n",
      "trainer/Q Targets Max                                            7.29941\n",
      "trainer/Q Targets Min                                          -46.6915\n",
      "trainer/Bellman Errors Mean                                      1.19524\n",
      "trainer/Bellman Errors Std                                      10.1217\n",
      "trainer/Bellman Errors Max                                     290.101\n",
      "trainer/Bellman Errors Min                                       1.14619e-09\n",
      "trainer/Policy Action Mean                                      -0.158736\n",
      "trainer/Policy Action Std                                        0.657761\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  62264\n",
      "exploration/num paths total                                   1367\n",
      "exploration/path length Mean                                    38.3103\n",
      "exploration/path length Std                                     17.0357\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.990999\n",
      "exploration/Rewards Std                                          0.0944451\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -37.9655\n",
      "exploration/Returns Std                                         17.4859\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.172019\n",
      "exploration/Actions Std                                          0.598802\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           29\n",
      "exploration/Average Returns                                    -37.9655\n",
      "exploration/env_infos/final/is_success Mean                      0.344828\n",
      "exploration/env_infos/final/is_success Std                       0.475312\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0090009\n",
      "exploration/env_infos/is_success Std                             0.0944451\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   30448\n",
      "evaluation/num paths total                                     675\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.207723\n",
      "evaluation/Actions Std                                           0.64181\n",
      "evaluation/Actions Max                                           0.999962\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.115053\n",
      "time/evaluation sampling (s)                                    17.1119\n",
      "time/exploration sampling (s)                                   36.9331\n",
      "time/logging (s)                                                 0.0069747\n",
      "time/saving (s)                                                  0.0703508\n",
      "time/training (s)                                              201.952\n",
      "time/epoch (s)                                                 256.189\n",
      "time/total (s)                                               15362.6\n",
      "Epoch                                                           59\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 11\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 60\n",
      "\n",
      " Cycle 0 60\n",
      "Added episode 50\n",
      "Replay buf 62314\n",
      "Soft update 48000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 60\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 62375\n",
      "Soft update 48040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 60\n",
      "Added episode 50\n",
      "Replay buf 62425\n",
      "Soft update 48080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 60\n",
      "Added episode 50\n",
      "Replay buf 62475\n",
      "Soft update 48120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 60\n",
      "Added episode 50\n",
      "Replay buf 62525\n",
      "Soft update 48160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 60\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 62590\n",
      "Soft update 48200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 60\n",
      "Added episode 50\n",
      "Replay buf 62640\n",
      "Soft update 48240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 60\n",
      "Added episode 50\n",
      "Replay buf 62690\n",
      "Soft update 48280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 60\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 62761\n",
      "Soft update 48320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 60\n",
      "Added episode 50\n",
      "Replay buf 62811\n",
      "Soft update 48360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 60\n",
      "Added episode 50\n",
      "Replay buf 62861\n",
      "Soft update 48400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 60\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 62921\n",
      "Soft update 48440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 60\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 62981\n",
      "Soft update 48480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 60\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 10\n",
      "Added episode 15\n",
      "Added episode 11\n",
      "Replay buf 63033\n",
      "Soft update 48520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 60\n",
      "Added episode 50\n",
      "Replay buf 63083\n",
      "Soft update 48560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 60\n",
      "Added episode 50\n",
      "Replay buf 63133\n",
      "Soft update 48600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 60\n",
      "Added episode 50\n",
      "Replay buf 63183\n",
      "Soft update 48640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 60\n",
      "Added episode 50\n",
      "Replay buf 63233\n",
      "Soft update 48680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 60\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 63293\n",
      "Soft update 48720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 60\n",
      "Added episode 50\n",
      "Replay buf 63343\n",
      "Soft update 48760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:13:18.010629 EEST | [final-sideways-pixels-final-31] Epoch 60 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                  1.10217\n",
      "trainer/Policy Loss                                              0.00944685\n",
      "trainer/Raw Policy Loss                                          0.00944685\n",
      "trainer/State estimation loss                                    0.00380986\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.68717\n",
      "trainer/Q Predictions Std                                       13.5241\n",
      "trainer/Q Predictions Max                                        7.40303\n",
      "trainer/Q Predictions Min                                      -46.6379\n",
      "trainer/Q Targets Mean                                          -9.69283\n",
      "trainer/Q Targets Std                                           13.589\n",
      "trainer/Q Targets Max                                            7.34925\n",
      "trainer/Q Targets Min                                          -46.3193\n",
      "trainer/Bellman Errors Mean                                      1.10217\n",
      "trainer/Bellman Errors Std                                       6.40697\n",
      "trainer/Bellman Errors Max                                     127.627\n",
      "trainer/Bellman Errors Min                                       1.4727e-08\n",
      "trainer/Policy Action Mean                                      -0.168651\n",
      "trainer/Policy Action Std                                        0.681874\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  63343\n",
      "exploration/num paths total                                   1397\n",
      "exploration/path length Mean                                    35.9667\n",
      "exploration/path length Std                                     18.4977\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.989805\n",
      "exploration/Rewards Std                                          0.100452\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -35.6\n",
      "exploration/Returns Std                                         18.9782\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.193186\n",
      "exploration/Actions Std                                          0.620037\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           30\n",
      "exploration/Average Returns                                    -35.6\n",
      "exploration/env_infos/final/is_success Mean                      0.366667\n",
      "exploration/env_infos/final/is_success Std                       0.481894\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0101946\n",
      "exploration/env_infos/is_success Std                             0.100452\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   30996\n",
      "evaluation/num paths total                                     689\n",
      "evaluation/path length Mean                                     39.1429\n",
      "evaluation/path length Std                                      17.1708\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      11\n",
      "evaluation/Rewards Mean                                         -0.992701\n",
      "evaluation/Rewards Std                                           0.0851234\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -38.8571\n",
      "evaluation/Returns Std                                          17.6225\n",
      "evaluation/Returns Max                                         -10\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.235151\n",
      "evaluation/Actions Std                                           0.666226\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            14\n",
      "evaluation/Average Returns                                     -38.8571\n",
      "evaluation/env_infos/final/is_success Mean                       0.285714\n",
      "evaluation/env_infos/final/is_success Std                        0.451754\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00729927\n",
      "evaluation/env_infos/is_success Std                              0.0851234\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.120661\n",
      "time/evaluation sampling (s)                                    18.0031\n",
      "time/exploration sampling (s)                                   37.4056\n",
      "time/logging (s)                                                 0.00716927\n",
      "time/saving (s)                                                  0.0727059\n",
      "time/training (s)                                              218.035\n",
      "time/epoch (s)                                                 273.645\n",
      "time/total (s)                                               15636.3\n",
      "Epoch                                                           60\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 13\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 61\n",
      "\n",
      " Cycle 0 61\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 19\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 63424\n",
      "Soft update 48800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 61\n",
      "Added episode 50\n",
      "Replay buf 63474\n",
      "Soft update 48840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 61\n",
      "Added episode 50\n",
      "Replay buf 63524\n",
      "Soft update 48880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 61\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 50\n",
      "Replay buf 63590\n",
      "Soft update 48920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 61\n",
      "Added episode 50\n",
      "Replay buf 63640\n",
      "Soft update 48960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 61\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 27\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 63728\n",
      "Soft update 49000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 61\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 63789\n",
      "Soft update 49040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 61\n",
      "Added episode 50\n",
      "Replay buf 63839\n",
      "Soft update 49080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 61\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 63904\n",
      "Soft update 49120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 61\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 26\n",
      "Added episode 50\n",
      "Replay buf 63989\n",
      "Soft update 49160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 61\n",
      "Added episode 50\n",
      "Replay buf 64039\n",
      "Soft update 49200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 61\n",
      "Added episode 50\n",
      "Replay buf 64089\n",
      "Soft update 49240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 61\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 47\n",
      "Replay buf 64149\n",
      "Soft update 49280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 61\n",
      "Added episode 50\n",
      "Replay buf 64199\n",
      "Soft update 49320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 61\n",
      "Added episode 50\n",
      "Replay buf 64249\n",
      "Soft update 49360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 61\n",
      "Added episode 50\n",
      "Replay buf 64299\n",
      "Soft update 49400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 61\n",
      "Added episode 50\n",
      "Replay buf 64349\n",
      "Soft update 49440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 61\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 64408\n",
      "Soft update 49480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 61\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 64473\n",
      "Soft update 49520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 61\n",
      "Added episode 50\n",
      "Replay buf 64523\n",
      "Soft update 49560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:17:52.670278 EEST | [final-sideways-pixels-final-31] Epoch 61 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.14973\n",
      "trainer/Policy Loss                                              0.00959755\n",
      "trainer/Raw Policy Loss                                          0.00959755\n",
      "trainer/State estimation loss                                    0.00343386\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                      -9.84924\n",
      "trainer/Q Predictions Std                                       13.5916\n",
      "trainer/Q Predictions Max                                        6.52835\n",
      "trainer/Q Predictions Min                                      -46.0199\n",
      "trainer/Q Targets Mean                                          -9.73146\n",
      "trainer/Q Targets Std                                           13.6929\n",
      "trainer/Q Targets Max                                            6.57225\n",
      "trainer/Q Targets Min                                          -46.2022\n",
      "trainer/Bellman Errors Mean                                      1.14973\n",
      "trainer/Bellman Errors Std                                       6.12894\n",
      "trainer/Bellman Errors Max                                     107.638\n",
      "trainer/Bellman Errors Min                                       1.28726e-08\n",
      "trainer/Policy Action Mean                                      -0.157452\n",
      "trainer/Policy Action Std                                        0.631128\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  64523\n",
      "exploration/num paths total                                   1429\n",
      "exploration/path length Mean                                    36.875\n",
      "exploration/path length Std                                     17.1259\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.988983\n",
      "exploration/Rewards Std                                          0.104382\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -36.4688\n",
      "exploration/Returns Std                                         17.5819\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.177735\n",
      "exploration/Actions Std                                          0.611035\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           32\n",
      "exploration/Average Returns                                    -36.4688\n",
      "exploration/env_infos/final/is_success Mean                      0.40625\n",
      "exploration/env_infos/final/is_success Std                       0.491132\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0110169\n",
      "exploration/env_infos/is_success Std                             0.104382\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   31501\n",
      "evaluation/num paths total                                     715\n",
      "evaluation/path length Mean                                     19.4231\n",
      "evaluation/path length Std                                      13.5083\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      11\n",
      "evaluation/Rewards Mean                                         -0.956436\n",
      "evaluation/Rewards Std                                           0.204124\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -18.5769\n",
      "evaluation/Returns Std                                          13.8569\n",
      "evaluation/Returns Max                                         -10\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.163097\n",
      "evaluation/Actions Std                                           0.649517\n",
      "evaluation/Actions Max                                           0.999998\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            26\n",
      "evaluation/Average Returns                                     -18.5769\n",
      "evaluation/env_infos/final/is_success Mean                       0.846154\n",
      "evaluation/env_infos/final/is_success Std                        0.360801\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0435644\n",
      "evaluation/env_infos/is_success Std                              0.204124\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.137614\n",
      "time/evaluation sampling (s)                                    16.4099\n",
      "time/exploration sampling (s)                                   40.3095\n",
      "time/logging (s)                                                 0.00980479\n",
      "time/saving (s)                                                  0.0734255\n",
      "time/training (s)                                              217.716\n",
      "time/epoch (s)                                                 274.657\n",
      "time/total (s)                                               15910.9\n",
      "Epoch                                                           61\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 62\n",
      "\n",
      " Cycle 0 62\n",
      "Added episode 50\n",
      "Replay buf 64573\n",
      "Soft update 49600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 64633\n",
      "Soft update 49640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 62\n",
      "Added episode 50\n",
      "Replay buf 64683\n",
      "Soft update 49680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 64743\n",
      "Soft update 49720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 62\n",
      "Added episode 50\n",
      "Replay buf 64793\n",
      "Soft update 49760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 64861\n",
      "Soft update 49800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 64923\n",
      "Soft update 49840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 64992\n",
      "Soft update 49880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 62\n",
      "Added episode 50\n",
      "Replay buf 65042\n",
      "Soft update 49920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 62\n",
      "Added episode 50\n",
      "Replay buf 65092\n",
      "Soft update 49960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 65157\n",
      "Soft update 50000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 12\n",
      "Added episode 12\n",
      "Added episode 9\n",
      "Added episode 11\n",
      "Replay buf 65216\n",
      "Soft update 50040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 62\n",
      "Added episode 50\n",
      "Replay buf 65266\n",
      "Soft update 50080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 62\n",
      "Added episode 50\n",
      "Replay buf 65316\n",
      "Soft update 50120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 65379\n",
      "Soft update 50160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 65444\n",
      "Soft update 50200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 62\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 65505\n",
      "Soft update 50240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 62\n",
      "Added episode 50\n",
      "Replay buf 65555\n",
      "Soft update 50280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 62\n",
      "Added episode 50\n",
      "Replay buf 65605\n",
      "Soft update 50320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 62\n",
      "Added episode 50\n",
      "Replay buf 65655\n",
      "Soft update 50360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:22:26.068028 EEST | [final-sideways-pixels-final-31] Epoch 62 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.08792\n",
      "trainer/Policy Loss                                              0.00998998\n",
      "trainer/Raw Policy Loss                                          0.00998998\n",
      "trainer/State estimation loss                                    0.00414638\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.0531\n",
      "trainer/Q Predictions Std                                       13.9277\n",
      "trainer/Q Predictions Max                                       11.7611\n",
      "trainer/Q Predictions Min                                      -45.657\n",
      "trainer/Q Targets Mean                                          -9.94371\n",
      "trainer/Q Targets Std                                           14.0146\n",
      "trainer/Q Targets Max                                           11.8554\n",
      "trainer/Q Targets Min                                          -46.264\n",
      "trainer/Bellman Errors Mean                                      1.08792\n",
      "trainer/Bellman Errors Std                                       7.07252\n",
      "trainer/Bellman Errors Max                                     167.297\n",
      "trainer/Bellman Errors Min                                       1.16809e-07\n",
      "trainer/Policy Action Mean                                      -0.166956\n",
      "trainer/Policy Action Std                                        0.596669\n",
      "trainer/Policy Action Max                                        0.999985\n",
      "trainer/Policy Action Min                                       -0.999896\n",
      "exploration/num steps total                                  65655\n",
      "exploration/num paths total                                   1463\n",
      "exploration/path length Mean                                    33.2941\n",
      "exploration/path length Std                                     18.8766\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.986749\n",
      "exploration/Rewards Std                                          0.114347\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -32.8529\n",
      "exploration/Returns Std                                         19.3712\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.168394\n",
      "exploration/Actions Std                                          0.622637\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           34\n",
      "exploration/Average Returns                                    -32.8529\n",
      "exploration/env_infos/final/is_success Mean                      0.441176\n",
      "exploration/env_infos/final/is_success Std                       0.496528\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0132509\n",
      "exploration/env_infos/is_success Std                             0.114347\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   32022\n",
      "evaluation/num paths total                                     730\n",
      "evaluation/path length Mean                                     34.7333\n",
      "evaluation/path length Std                                      17.0116\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      11\n",
      "evaluation/Rewards Mean                                         -0.986564\n",
      "evaluation/Rewards Std                                           0.115131\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -34.2667\n",
      "evaluation/Returns Std                                          17.4908\n",
      "evaluation/Returns Max                                         -10\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.199543\n",
      "evaluation/Actions Std                                           0.513998\n",
      "evaluation/Actions Max                                           0.99823\n",
      "evaluation/Actions Min                                          -0.999236\n",
      "evaluation/Num Paths                                            15\n",
      "evaluation/Average Returns                                     -34.2667\n",
      "evaluation/env_infos/final/is_success Mean                       0.466667\n",
      "evaluation/env_infos/final/is_success Std                        0.498888\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0134357\n",
      "evaluation/env_infos/is_success Std                              0.115131\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.123155\n",
      "time/evaluation sampling (s)                                    18.7594\n",
      "time/exploration sampling (s)                                   38.2792\n",
      "time/logging (s)                                                 0.00719231\n",
      "time/saving (s)                                                  0.0736717\n",
      "time/training (s)                                              216.146\n",
      "time/epoch (s)                                                 273.388\n",
      "time/total (s)                                               16184.3\n",
      "Epoch                                                           62\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 63\n",
      "\n",
      " Cycle 0 63\n",
      "Added episode 50\n",
      "Replay buf 65705\n",
      "Soft update 50400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 63\n",
      "Added episode 50\n",
      "Replay buf 65755\n",
      "Soft update 50440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 28\n",
      "Added episode 20\n",
      "Added episode 33\n",
      "Replay buf 65836\n",
      "Soft update 50480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 65910\n",
      "Soft update 50520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 65983\n",
      "Soft update 50560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 66043\n",
      "Soft update 50600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 28\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 66131\n",
      "Soft update 50640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 66191\n",
      "Soft update 50680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 63\n",
      "Added episode 50\n",
      "Replay buf 66241\n",
      "Soft update 50720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 63\n",
      "Added episode 50\n",
      "Replay buf 66291\n",
      "Soft update 50760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 29\n",
      "Added episode 50\n",
      "Replay buf 66370\n",
      "Soft update 50800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 63\n",
      "Added episode 50\n",
      "Replay buf 66420\n",
      "Soft update 50840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 14\n",
      "Added episode 10\n",
      "Added episode 36\n",
      "Replay buf 66490\n",
      "Soft update 50880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 66565\n",
      "Soft update 50920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 63\n",
      "Added episode 50\n",
      "Replay buf 66615\n",
      "Soft update 50960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 66674\n",
      "Soft update 51000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 66734\n",
      "Soft update 51040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 66797\n",
      "Soft update 51080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 63\n",
      "Added episode 50\n",
      "Replay buf 66847\n",
      "Soft update 51120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 63\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 22\n",
      "Added episode 50\n",
      "Replay buf 66919\n",
      "Soft update 51160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:26:59.762736 EEST | [final-sideways-pixels-final-31] Epoch 63 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.13493\n",
      "trainer/Policy Loss                                              0.00981168\n",
      "trainer/Raw Policy Loss                                          0.00981168\n",
      "trainer/State estimation loss                                    0.0041332\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.0571\n",
      "trainer/Q Predictions Std                                       14.1047\n",
      "trainer/Q Predictions Max                                       16.9144\n",
      "trainer/Q Predictions Min                                      -47.6145\n",
      "trainer/Q Targets Mean                                         -10.1214\n",
      "trainer/Q Targets Std                                           14.1142\n",
      "trainer/Q Targets Max                                           16.7292\n",
      "trainer/Q Targets Min                                          -47.4922\n",
      "trainer/Bellman Errors Mean                                      1.13493\n",
      "trainer/Bellman Errors Std                                       6.27647\n",
      "trainer/Bellman Errors Max                                     138.955\n",
      "trainer/Bellman Errors Min                                       1.11413e-09\n",
      "trainer/Policy Action Mean                                      -0.198419\n",
      "trainer/Policy Action Std                                        0.650373\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -0.999998\n",
      "exploration/num steps total                                  66919\n",
      "exploration/num paths total                                   1503\n",
      "exploration/path length Mean                                    31.6\n",
      "exploration/path length Std                                     17.7944\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.982595\n",
      "exploration/Rewards Std                                          0.130775\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -31.05\n",
      "exploration/Returns Std                                         18.2605\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.176234\n",
      "exploration/Actions Std                                          0.627291\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           40\n",
      "exploration/Average Returns                                    -31.05\n",
      "exploration/env_infos/final/is_success Mean                      0.55\n",
      "exploration/env_infos/final/is_success Std                       0.497494\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0174051\n",
      "exploration/env_infos/is_success Std                             0.130775\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   32537\n",
      "evaluation/num paths total                                     741\n",
      "evaluation/path length Mean                                     46.8182\n",
      "evaluation/path length Std                                       6.91268\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      29\n",
      "evaluation/Rewards Mean                                         -0.996116\n",
      "evaluation/Rewards Std                                           0.0621966\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -46.6364\n",
      "evaluation/Returns Std                                           7.28975\n",
      "evaluation/Returns Max                                         -28\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.153987\n",
      "evaluation/Actions Std                                           0.633469\n",
      "evaluation/Actions Max                                           0.999943\n",
      "evaluation/Actions Min                                          -0.999998\n",
      "evaluation/Num Paths                                            11\n",
      "evaluation/Average Returns                                     -46.6364\n",
      "evaluation/env_infos/final/is_success Mean                       0.181818\n",
      "evaluation/env_infos/final/is_success Std                        0.385695\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0038835\n",
      "evaluation/env_infos/is_success Std                              0.0621966\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.138248\n",
      "time/evaluation sampling (s)                                    18.3768\n",
      "time/exploration sampling (s)                                   42.5739\n",
      "time/logging (s)                                                 0.00744687\n",
      "time/saving (s)                                                  0.0707746\n",
      "time/training (s)                                              212.522\n",
      "time/epoch (s)                                                 273.689\n",
      "time/total (s)                                               16458\n",
      "Epoch                                                           63\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 10\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 64\n",
      "\n",
      " Cycle 0 64\n",
      "Added episode 50\n",
      "Replay buf 66969\n",
      "Soft update 51200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 64\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 67043\n",
      "Soft update 51240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 64\n",
      "Added episode 50\n",
      "Replay buf 67093\n",
      "Soft update 51280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 64\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 67170\n",
      "Soft update 51320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 64\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 67254\n",
      "Soft update 51360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 64\n",
      "Added episode 50\n",
      "Replay buf 67304\n",
      "Soft update 51400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 64\n",
      "Added episode 50\n",
      "Replay buf 67354\n",
      "Soft update 51440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 64\n",
      "Added episode 50\n",
      "Replay buf 67404\n",
      "Soft update 51480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 64\n",
      "Added episode 50\n",
      "Replay buf 67454\n",
      "Soft update 51520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 64\n",
      "Added episode 50\n",
      "Replay buf 67504\n",
      "Soft update 51560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 64\n",
      "Added episode 50\n",
      "Replay buf 67554\n",
      "Soft update 51600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 64\n",
      "Added episode 50\n",
      "Replay buf 67604\n",
      "Soft update 51640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 64\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 67667\n",
      "Soft update 51680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 64\n",
      "Added episode 50\n",
      "Replay buf 67717\n",
      "Soft update 51720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 64\n",
      "Added episode 50\n",
      "Replay buf 67767\n",
      "Soft update 51760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 64\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 67844\n",
      "Soft update 51800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 64\n",
      "Added episode 50\n",
      "Replay buf 67894\n",
      "Soft update 51840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 64\n",
      "Added episode 50\n",
      "Replay buf 67944\n",
      "Soft update 51880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 64\n",
      "Added episode 50\n",
      "Replay buf 67994\n",
      "Soft update 51920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 64\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 20\n",
      "Added episode 33\n",
      "Replay buf 68047\n",
      "Soft update 51960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:31:20.660061 EEST | [final-sideways-pixels-final-31] Epoch 64 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.07364\n",
      "trainer/Policy Loss                                              0.0100199\n",
      "trainer/Raw Policy Loss                                          0.0100199\n",
      "trainer/State estimation loss                                    0.00453837\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.3219\n",
      "trainer/Q Predictions Std                                       14.0804\n",
      "trainer/Q Predictions Max                                       14.6246\n",
      "trainer/Q Predictions Min                                      -47.9291\n",
      "trainer/Q Targets Mean                                         -10.2173\n",
      "trainer/Q Targets Std                                           14.0287\n",
      "trainer/Q Targets Max                                           14.728\n",
      "trainer/Q Targets Min                                          -48.7159\n",
      "trainer/Bellman Errors Mean                                      1.07364\n",
      "trainer/Bellman Errors Std                                       4.57864\n",
      "trainer/Bellman Errors Max                                      86.5619\n",
      "trainer/Bellman Errors Min                                       2.71383e-07\n",
      "trainer/Policy Action Mean                                      -0.112406\n",
      "trainer/Policy Action Std                                        0.664595\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -0.999976\n",
      "exploration/num steps total                                  68047\n",
      "exploration/num paths total                                   1534\n",
      "exploration/path length Mean                                    36.3871\n",
      "exploration/path length Std                                     17.5695\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.989362\n",
      "exploration/Rewards Std                                          0.102592\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -36\n",
      "exploration/Returns Std                                         18.0447\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.172333\n",
      "exploration/Actions Std                                          0.584789\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           31\n",
      "exploration/Average Returns                                    -36\n",
      "exploration/env_infos/final/is_success Mean                      0.387097\n",
      "exploration/env_infos/final/is_success Std                       0.487086\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0106383\n",
      "exploration/env_infos/is_success Std                             0.102592\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   33080\n",
      "evaluation/num paths total                                     759\n",
      "evaluation/path length Mean                                     30.1667\n",
      "evaluation/path length Std                                      18.5659\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.981584\n",
      "evaluation/Rewards Std                                           0.134451\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -29.6111\n",
      "evaluation/Returns Std                                          19.0413\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.154578\n",
      "evaluation/Actions Std                                           0.592741\n",
      "evaluation/Actions Max                                           0.999871\n",
      "evaluation/Actions Min                                          -0.999938\n",
      "evaluation/Num Paths                                            18\n",
      "evaluation/Average Returns                                     -29.6111\n",
      "evaluation/env_infos/final/is_success Mean                       0.555556\n",
      "evaluation/env_infos/final/is_success Std                        0.496904\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0184162\n",
      "evaluation/env_infos/is_success Std                              0.134451\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.116872\n",
      "time/evaluation sampling (s)                                    17.085\n",
      "time/exploration sampling (s)                                   36.7384\n",
      "time/logging (s)                                                 0.00733208\n",
      "time/saving (s)                                                  0.0722212\n",
      "time/training (s)                                              206.872\n",
      "time/epoch (s)                                                 260.891\n",
      "time/total (s)                                               16718.9\n",
      "Epoch                                                           64\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 9\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 65\n",
      "\n",
      " Cycle 0 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 68110\n",
      "Soft update 52000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 68172\n",
      "Soft update 52040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 68232\n",
      "Soft update 52080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 68292\n",
      "Soft update 52120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 68365\n",
      "Soft update 52160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 68450\n",
      "Soft update 52200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 68529\n",
      "Soft update 52240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 12\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 68623\n",
      "Soft update 52280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 65\n",
      "Added episode 50\n",
      "Replay buf 68673\n",
      "Soft update 52320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 16\n",
      "Added episode 13\n",
      "Added episode 10\n",
      "Replay buf 68728\n",
      "Soft update 52360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 65\n",
      "Added episode 50\n",
      "Replay buf 68778\n",
      "Soft update 52400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 16\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 68866\n",
      "Soft update 52440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 65\n",
      "Added episode 50\n",
      "Replay buf 68916\n",
      "Soft update 52480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 65\n",
      "Added episode 50\n",
      "Replay buf 68966\n",
      "Soft update 52520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 65\n",
      "Added episode 50\n",
      "Replay buf 69016\n",
      "Soft update 52560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 65\n",
      "Added episode 50\n",
      "Replay buf 69066\n",
      "Soft update 52600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 69126\n",
      "Soft update 52640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 69185\n",
      "Soft update 52680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 65\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 69247\n",
      "Soft update 52720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 65\n",
      "Added episode 50\n",
      "Replay buf 69297\n",
      "Soft update 52760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:35:50.509971 EEST | [final-sideways-pixels-final-31] Epoch 65 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.4313\n",
      "trainer/Policy Loss                                              0.0104167\n",
      "trainer/Raw Policy Loss                                          0.0104167\n",
      "trainer/State estimation loss                                    0.00385131\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.6803\n",
      "trainer/Q Predictions Std                                       14.2782\n",
      "trainer/Q Predictions Max                                       15.4662\n",
      "trainer/Q Predictions Min                                      -49.6372\n",
      "trainer/Q Targets Mean                                         -10.689\n",
      "trainer/Q Targets Std                                           14.1575\n",
      "trainer/Q Targets Max                                           15.0167\n",
      "trainer/Q Targets Min                                          -49.1149\n",
      "trainer/Bellman Errors Mean                                      1.4313\n",
      "trainer/Bellman Errors Std                                      11.5991\n",
      "trainer/Bellman Errors Max                                     352.465\n",
      "trainer/Bellman Errors Min                                       4.35524e-07\n",
      "trainer/Policy Action Mean                                      -0.245805\n",
      "trainer/Policy Action Std                                        0.673387\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  69297\n",
      "exploration/num paths total                                   1577\n",
      "exploration/path length Mean                                    29.0698\n",
      "exploration/path length Std                                     18.7262\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.9808\n",
      "exploration/Rewards Std                                          0.137227\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -28.5116\n",
      "exploration/Returns Std                                         19.2201\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.220796\n",
      "exploration/Actions Std                                          0.635413\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           43\n",
      "exploration/Average Returns                                    -28.5116\n",
      "exploration/env_infos/final/is_success Mean                      0.55814\n",
      "exploration/env_infos/final/is_success Std                       0.496608\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0192\n",
      "exploration/env_infos/is_success Std                             0.137227\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   33626\n",
      "evaluation/num paths total                                     774\n",
      "evaluation/path length Mean                                     36.4\n",
      "evaluation/path length Std                                      17.6136\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.989011\n",
      "evaluation/Rewards Std                                           0.104251\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -36\n",
      "evaluation/Returns Std                                          18.0776\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.270958\n",
      "evaluation/Actions Std                                           0.652546\n",
      "evaluation/Actions Max                                           0.999998\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            15\n",
      "evaluation/Average Returns                                     -36\n",
      "evaluation/env_infos/final/is_success Mean                       0.4\n",
      "evaluation/env_infos/final/is_success Std                        0.489898\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.010989\n",
      "evaluation/env_infos/is_success Std                              0.104251\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.130102\n",
      "time/evaluation sampling (s)                                    18.2356\n",
      "time/exploration sampling (s)                                   41.7758\n",
      "time/logging (s)                                                 0.00751077\n",
      "time/saving (s)                                                  0.0703984\n",
      "time/training (s)                                              209.625\n",
      "time/epoch (s)                                                 269.844\n",
      "time/total (s)                                               16988.8\n",
      "Epoch                                                           65\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 21\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 66\n",
      "\n",
      " Cycle 0 66\n",
      "Added episode 50\n",
      "Replay buf 69347\n",
      "Soft update 52800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 66\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 22\n",
      "Added episode 50\n",
      "Replay buf 69419\n",
      "Soft update 52840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 66\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 69479\n",
      "Soft update 52880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 66\n",
      "Added episode 50\n",
      "Replay buf 69529\n",
      "Soft update 52920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 66\n",
      "Added episode 50\n",
      "Replay buf 69579\n",
      "Soft update 52960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 66\n",
      "Added episode 50\n",
      "Replay buf 69629\n",
      "Soft update 53000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 66\n",
      "Added episode 50\n",
      "Replay buf 69679\n",
      "Soft update 53040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 66\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 69741\n",
      "Soft update 53080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 66\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 69802\n",
      "Soft update 53120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 66\n",
      "Added episode 50\n",
      "Replay buf 69852\n",
      "Soft update 53160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 66\n",
      "Added episode 50\n",
      "Replay buf 69902\n",
      "Soft update 53200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 66\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 69961\n",
      "Soft update 53240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 66\n",
      "Added episode 50\n",
      "Replay buf 70011\n",
      "Soft update 53280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 66\n",
      "Added episode 50\n",
      "Replay buf 70061\n",
      "Soft update 53320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 66\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 70146\n",
      "Soft update 53360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 66\n",
      "Added episode 50\n",
      "Replay buf 70196\n",
      "Soft update 53400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 66\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 70269\n",
      "Soft update 53440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 66\n",
      "Added episode 50\n",
      "Replay buf 70319\n",
      "Soft update 53480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 66\n",
      "Added episode 50\n",
      "Replay buf 70369\n",
      "Soft update 53520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 66\n",
      "Added episode 50\n",
      "Replay buf 70419\n",
      "Soft update 53560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:40:16.306917 EEST | [final-sideways-pixels-final-31] Epoch 66 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  0.95698\n",
      "trainer/Policy Loss                                              0.0103826\n",
      "trainer/Raw Policy Loss                                          0.0103826\n",
      "trainer/State estimation loss                                    0.00381873\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.6007\n",
      "trainer/Q Predictions Std                                       14.2947\n",
      "trainer/Q Predictions Max                                       11.1409\n",
      "trainer/Q Predictions Min                                      -49.2108\n",
      "trainer/Q Targets Mean                                         -10.5916\n",
      "trainer/Q Targets Std                                           14.308\n",
      "trainer/Q Targets Max                                           11.4024\n",
      "trainer/Q Targets Min                                          -50.67\n",
      "trainer/Bellman Errors Mean                                      0.95698\n",
      "trainer/Bellman Errors Std                                       3.43267\n",
      "trainer/Bellman Errors Max                                      37.873\n",
      "trainer/Bellman Errors Min                                       5.91941e-07\n",
      "trainer/Policy Action Mean                                      -0.08544\n",
      "trainer/Policy Action Std                                        0.654085\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  70419\n",
      "exploration/num paths total                                   1607\n",
      "exploration/path length Mean                                    37.4\n",
      "exploration/path length Std                                     17.9287\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.991087\n",
      "exploration/Rewards Std                                          0.0939852\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -37.0667\n",
      "exploration/Returns Std                                         18.3973\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.157555\n",
      "exploration/Actions Std                                          0.602055\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           30\n",
      "exploration/Average Returns                                    -37.0667\n",
      "exploration/env_infos/final/is_success Mean                      0.333333\n",
      "exploration/env_infos/final/is_success Std                       0.471405\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.00891266\n",
      "exploration/env_infos/is_success Std                             0.0939852\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   34152\n",
      "evaluation/num paths total                                     788\n",
      "evaluation/path length Mean                                     37.5714\n",
      "evaluation/path length Std                                      16.3083\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.988593\n",
      "evaluation/Rewards Std                                           0.106192\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -37.1429\n",
      "evaluation/Returns Std                                          16.7454\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.141823\n",
      "evaluation/Actions Std                                           0.59881\n",
      "evaluation/Actions Max                                           0.999992\n",
      "evaluation/Actions Min                                          -0.999998\n",
      "evaluation/Num Paths                                            14\n",
      "evaluation/Average Returns                                     -37.1429\n",
      "evaluation/env_infos/final/is_success Mean                       0.428571\n",
      "evaluation/env_infos/final/is_success Std                        0.494872\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0114068\n",
      "evaluation/env_infos/is_success Std                              0.106192\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.120733\n",
      "time/evaluation sampling (s)                                    18.973\n",
      "time/exploration sampling (s)                                   37.4708\n",
      "time/logging (s)                                                 0.00710173\n",
      "time/saving (s)                                                  0.0700328\n",
      "time/training (s)                                              209.149\n",
      "time/epoch (s)                                                 265.791\n",
      "time/total (s)                                               17254.6\n",
      "Epoch                                                           66\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 12\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 67\n",
      "\n",
      " Cycle 0 67\n",
      "Added episode 50\n",
      "Replay buf 70469\n",
      "Soft update 53600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 67\n",
      "Added episode 50\n",
      "Replay buf 70519\n",
      "Soft update 53640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 67\n",
      "Added episode 50\n",
      "Replay buf 70569\n",
      "Soft update 53680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 67\n",
      "Added episode 50\n",
      "Replay buf 70619\n",
      "Soft update 53720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 67\n",
      "Added episode 50\n",
      "Replay buf 70669\n",
      "Soft update 53760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 67\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 25\n",
      "Added episode 15\n",
      "Replay buf 70730\n",
      "Soft update 53800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 67\n",
      "Added episode 50\n",
      "Replay buf 70780\n",
      "Soft update 53840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 67\n",
      "Added episode 50\n",
      "Replay buf 70830\n",
      "Soft update 53880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 67\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 19\n",
      "Added episode 50\n",
      "Replay buf 70899\n",
      "Soft update 53920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 67\n",
      "Added episode 50\n",
      "Replay buf 70949\n",
      "Soft update 53960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 67\n",
      "Added episode 50\n",
      "Replay buf 70999\n",
      "Soft update 54000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 67\n",
      "Added episode 50\n",
      "Replay buf 71049\n",
      "Soft update 54040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 67\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 15\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 71145\n",
      "Soft update 54080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 67\n",
      "Added episode 50\n",
      "Replay buf 71195\n",
      "Soft update 54120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 67\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 21\n",
      "Added episode 31\n",
      "Replay buf 71261\n",
      "Soft update 54160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 67\n",
      "Added episode 50\n",
      "Replay buf 71311\n",
      "Soft update 54200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 67\n",
      "Added episode 50\n",
      "Replay buf 71361\n",
      "Soft update 54240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 67\n",
      "Added episode 50\n",
      "Replay buf 71411\n",
      "Soft update 54280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 67\n",
      "Added episode 50\n",
      "Replay buf 71461\n",
      "Soft update 54320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 67\n",
      "Added episode 50\n",
      "Replay buf 71511\n",
      "Soft update 54360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:44:35.638780 EEST | [final-sideways-pixels-final-31] Epoch 67 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.01932\n",
      "trainer/Policy Loss                                            nan\n",
      "trainer/Raw Policy Loss                                        nan\n",
      "trainer/State estimation loss                                    0.00412988\n",
      "trainer/Preactivation Policy Loss                              nan\n",
      "trainer/Q Predictions Mean                                     -10.5486\n",
      "trainer/Q Predictions Std                                       14.5134\n",
      "trainer/Q Predictions Max                                       13.518\n",
      "trainer/Q Predictions Min                                      -49.1997\n",
      "trainer/Q Targets Mean                                         -10.5919\n",
      "trainer/Q Targets Std                                           14.4909\n",
      "trainer/Q Targets Max                                           13.8264\n",
      "trainer/Q Targets Min                                          -50.8647\n",
      "trainer/Bellman Errors Mean                                      1.01932\n",
      "trainer/Bellman Errors Std                                       4.43931\n",
      "trainer/Bellman Errors Max                                      75.4981\n",
      "trainer/Bellman Errors Min                                       1.57204e-07\n",
      "trainer/Policy Action Mean                                      -0.160392\n",
      "trainer/Policy Action Std                                        0.647772\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  71511\n",
      "exploration/num paths total                                   1636\n",
      "exploration/path length Mean                                    37.6552\n",
      "exploration/path length Std                                     16.2189\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.989927\n",
      "exploration/Rewards Std                                          0.0998588\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -37.2759\n",
      "exploration/Returns Std                                         16.6917\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.189099\n",
      "exploration/Actions Std                                          0.587431\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           29\n",
      "exploration/Average Returns                                    -37.2759\n",
      "exploration/env_infos/final/is_success Mean                      0.37931\n",
      "exploration/env_infos/final/is_success Std                       0.485215\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0100733\n",
      "exploration/env_infos/is_success Std                             0.0998588\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   34669\n",
      "evaluation/num paths total                                     813\n",
      "evaluation/path length Mean                                     20.68\n",
      "evaluation/path length Std                                      16.5208\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.963249\n",
      "evaluation/Rewards Std                                           0.188149\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -19.92\n",
      "evaluation/Returns Std                                          16.9468\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.214788\n",
      "evaluation/Actions Std                                           0.649469\n",
      "evaluation/Actions Max                                           0.999999\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            25\n",
      "evaluation/Average Returns                                     -19.92\n",
      "evaluation/env_infos/final/is_success Mean                       0.76\n",
      "evaluation/env_infos/final/is_success Std                        0.427083\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0367505\n",
      "evaluation/env_infos/is_success Std                              0.188149\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.114705\n",
      "time/evaluation sampling (s)                                    16.2328\n",
      "time/exploration sampling (s)                                   36.4799\n",
      "time/logging (s)                                                 0.00718463\n",
      "time/saving (s)                                                  0.0691762\n",
      "time/training (s)                                              206.423\n",
      "time/epoch (s)                                                 259.326\n",
      "time/total (s)                                               17513.9\n",
      "Epoch                                                           67\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 68\n",
      "\n",
      " Cycle 0 68\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 33\n",
      "Added episode 50\n",
      "Replay buf 71594\n",
      "Soft update 54400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 68\n",
      "Added episode 50\n",
      "Replay buf 71644\n",
      "Soft update 54440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 68\n",
      "Added episode 50\n",
      "Replay buf 71694\n",
      "Soft update 54480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 68\n",
      "Added episode 50\n",
      "Replay buf 71744\n",
      "Soft update 54520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 68\n",
      "Added episode 50\n",
      "Replay buf 71794\n",
      "Soft update 54560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 68\n",
      "Added episode 50\n",
      "Replay buf 71844\n",
      "Soft update 54600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 68\n",
      "Added episode 50\n",
      "Replay buf 71894\n",
      "Soft update 54640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 68\n",
      "Added episode 50\n",
      "Replay buf 71944\n",
      "Soft update 54680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 68\n",
      "Added episode 50\n",
      "Replay buf 71994\n",
      "Soft update 54720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 68\n",
      "Added episode 50\n",
      "Replay buf 72044\n",
      "Soft update 54760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 68\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 15\n",
      "Added episode 12\n",
      "Added episode 16\n",
      "Replay buf 72098\n",
      "Soft update 54800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 68\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 72174\n",
      "Soft update 54840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 68\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 72237\n",
      "Soft update 54880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 68\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 72308\n",
      "Soft update 54920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 68\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 72381\n",
      "Soft update 54960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 68\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 72442\n",
      "Soft update 55000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 68\n",
      "Added episode 50\n",
      "Replay buf 72492\n",
      "Soft update 55040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 68\n",
      "Added episode 50\n",
      "Replay buf 72542\n",
      "Soft update 55080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 68\n",
      "Added episode 50\n",
      "Replay buf 72592\n",
      "Soft update 55120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 68\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 39\n",
      "Added episode 10\n",
      "Added episode 41\n",
      "Replay buf 72682\n",
      "Soft update 55160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:49:04.180043 EEST | [final-sideways-pixels-final-31] Epoch 68 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.38878\n",
      "trainer/Policy Loss                                              0.0100988\n",
      "trainer/Raw Policy Loss                                          0.0100988\n",
      "trainer/State estimation loss                                    0.00430783\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.3647\n",
      "trainer/Q Predictions Std                                       14.177\n",
      "trainer/Q Predictions Max                                       10.5739\n",
      "trainer/Q Predictions Min                                      -48.9673\n",
      "trainer/Q Targets Mean                                         -10.3998\n",
      "trainer/Q Targets Std                                           14.3627\n",
      "trainer/Q Targets Max                                           10.5026\n",
      "trainer/Q Targets Min                                          -50.3001\n",
      "trainer/Bellman Errors Mean                                      1.38878\n",
      "trainer/Bellman Errors Std                                       8.26897\n",
      "trainer/Bellman Errors Max                                     200.34\n",
      "trainer/Bellman Errors Min                                       6.10098e-08\n",
      "trainer/Policy Action Mean                                      -0.196881\n",
      "trainer/Policy Action Std                                        0.63407\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  72682\n",
      "exploration/num paths total                                   1670\n",
      "exploration/path length Mean                                    34.4412\n",
      "exploration/path length Std                                     17.9217\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.986336\n",
      "exploration/Rewards Std                                          0.11609\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -33.9706\n",
      "exploration/Returns Std                                         18.3824\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.176931\n",
      "exploration/Actions Std                                          0.62332\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           34\n",
      "exploration/Average Returns                                    -33.9706\n",
      "exploration/env_infos/final/is_success Mean                      0.470588\n",
      "exploration/env_infos/final/is_success Std                       0.499134\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0136635\n",
      "exploration/env_infos/is_success Std                             0.11609\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   35183\n",
      "evaluation/num paths total                                     828\n",
      "evaluation/path length Mean                                     34.2667\n",
      "evaluation/path length Std                                      19.2716\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.988327\n",
      "evaluation/Rewards Std                                           0.10741\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -33.8667\n",
      "evaluation/Returns Std                                          19.7615\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.236714\n",
      "evaluation/Actions Std                                           0.596686\n",
      "evaluation/Actions Max                                           0.999985\n",
      "evaluation/Actions Min                                          -0.999987\n",
      "evaluation/Num Paths                                            15\n",
      "evaluation/Average Returns                                     -33.8667\n",
      "evaluation/env_infos/final/is_success Mean                       0.4\n",
      "evaluation/env_infos/final/is_success Std                        0.489898\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0116732\n",
      "evaluation/env_infos/is_success Std                              0.10741\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.124065\n",
      "time/evaluation sampling (s)                                    17.1598\n",
      "time/exploration sampling (s)                                   40.0951\n",
      "time/logging (s)                                                 0.00753829\n",
      "time/saving (s)                                                  0.069788\n",
      "time/training (s)                                              211.08\n",
      "time/epoch (s)                                                 268.536\n",
      "time/total (s)                                               17782.4\n",
      "Epoch                                                           68\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 69\n",
      "\n",
      " Cycle 0 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 72742\n",
      "Soft update 55200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 12\n",
      "Added episode 9\n",
      "Added episode 11\n",
      "Replay buf 72796\n",
      "Soft update 55240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 69\n",
      "Added episode 50\n",
      "Replay buf 72846\n",
      "Soft update 55280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 69\n",
      "Added episode 50\n",
      "Replay buf 72896\n",
      "Soft update 55320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 69\n",
      "Added episode 50\n",
      "Replay buf 72946\n",
      "Soft update 55360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 23\n",
      "Added episode 50\n",
      "Replay buf 73028\n",
      "Soft update 55400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 29\n",
      "Added episode 50\n",
      "Replay buf 73117\n",
      "Soft update 55440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 69\n",
      "Added episode 50\n",
      "Replay buf 73167\n",
      "Soft update 55480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 69\n",
      "Added episode 50\n",
      "Replay buf 73217\n",
      "Soft update 55520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 69\n",
      "Added episode 50\n",
      "Replay buf 73267\n",
      "Soft update 55560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 69\n",
      "Added episode 50\n",
      "Replay buf 73317\n",
      "Soft update 55600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 73378\n",
      "Soft update 55640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 73461\n",
      "Soft update 55680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 69\n",
      "Added episode 50\n",
      "Replay buf 73511\n",
      "Soft update 55720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 29\n",
      "Added episode 9\n",
      "Replay buf 73561\n",
      "Soft update 55760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 73635\n",
      "Soft update 55800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 12\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 73718\n",
      "Soft update 55840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 69\n",
      "Added episode 50\n",
      "Replay buf 73768\n",
      "Soft update 55880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 21\n",
      "Added episode 50\n",
      "Replay buf 73839\n",
      "Soft update 55920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 69\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 73900\n",
      "Soft update 55960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:53:30.336724 EEST | [final-sideways-pixels-final-31] Epoch 69 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  2.0205\n",
      "trainer/Policy Loss                                              0.0105482\n",
      "trainer/Raw Policy Loss                                          0.0105482\n",
      "trainer/State estimation loss                                    0.00377448\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.8987\n",
      "trainer/Q Predictions Std                                       14.7612\n",
      "trainer/Q Predictions Max                                       12.1038\n",
      "trainer/Q Predictions Min                                      -50.722\n",
      "trainer/Q Targets Mean                                         -10.9958\n",
      "trainer/Q Targets Std                                           14.8927\n",
      "trainer/Q Targets Max                                           12.4967\n",
      "trainer/Q Targets Min                                          -51.3569\n",
      "trainer/Bellman Errors Mean                                      2.0205\n",
      "trainer/Bellman Errors Std                                      21.8671\n",
      "trainer/Bellman Errors Max                                     678.497\n",
      "trainer/Bellman Errors Min                                       4.46927e-07\n",
      "trainer/Policy Action Mean                                      -0.160988\n",
      "trainer/Policy Action Std                                        0.67699\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  73900\n",
      "exploration/num paths total                                   1712\n",
      "exploration/path length Mean                                    29\n",
      "exploration/path length Std                                     18.7006\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.980296\n",
      "exploration/Rewards Std                                          0.138983\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -28.4286\n",
      "exploration/Returns Std                                         19.1823\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.197572\n",
      "exploration/Actions Std                                          0.630392\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           42\n",
      "exploration/Average Returns                                    -28.4286\n",
      "exploration/env_infos/final/is_success Mean                      0.571429\n",
      "exploration/env_infos/final/is_success Std                       0.494872\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0197044\n",
      "exploration/env_infos/is_success Std                             0.138983\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   35688\n",
      "evaluation/num paths total                                     856\n",
      "evaluation/path length Mean                                     18.0357\n",
      "evaluation/path length Std                                      13.5633\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.952475\n",
      "evaluation/Rewards Std                                           0.212758\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -17.1786\n",
      "evaluation/Returns Std                                          13.9003\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.270842\n",
      "evaluation/Actions Std                                           0.651258\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            28\n",
      "evaluation/Average Returns                                     -17.1786\n",
      "evaluation/env_infos/final/is_success Mean                       0.857143\n",
      "evaluation/env_infos/final/is_success Std                        0.349927\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0475248\n",
      "evaluation/env_infos/is_success Std                              0.212758\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.127024\n",
      "time/evaluation sampling (s)                                    16.9832\n",
      "time/exploration sampling (s)                                   40.7876\n",
      "time/logging (s)                                                 0.00753399\n",
      "time/saving (s)                                                  0.0697761\n",
      "time/training (s)                                              208.176\n",
      "time/epoch (s)                                                 266.151\n",
      "time/total (s)                                               18048.6\n",
      "Epoch                                                           69\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 9\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 70\n",
      "\n",
      " Cycle 0 70\n",
      "Added episode 50\n",
      "Replay buf 73950\n",
      "Soft update 56000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 74012\n",
      "Soft update 56040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 21\n",
      "Added episode 50\n",
      "Replay buf 74083\n",
      "Soft update 56080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 50\n",
      "Replay buf 74149\n",
      "Soft update 56120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 70\n",
      "Added episode 50\n",
      "Replay buf 74199\n",
      "Soft update 56160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 70\n",
      "Added episode 50\n",
      "Replay buf 74249\n",
      "Soft update 56200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 70\n",
      "Added episode 50\n",
      "Replay buf 74299\n",
      "Soft update 56240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 74362\n",
      "Soft update 56280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 74423\n",
      "Soft update 56320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 74494\n",
      "Soft update 56360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 74572\n",
      "Soft update 56400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 24\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 74657\n",
      "Soft update 56440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 14\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 74742\n",
      "Soft update 56480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 70\n",
      "Added episode 50\n",
      "Replay buf 74792\n",
      "Soft update 56520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 70\n",
      "Added episode 50\n",
      "Replay buf 74842\n",
      "Soft update 56560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 70\n",
      "Added episode 50\n",
      "Replay buf 74892\n",
      "Soft update 56600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 70\n",
      "Added episode 50\n",
      "Replay buf 74942\n",
      "Soft update 56640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 75014\n",
      "Soft update 56680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 70\n",
      "Added episode 50\n",
      "Replay buf 75064\n",
      "Soft update 56720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 70\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 14\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Replay buf 75122\n",
      "Soft update 56760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 13:57:55.539501 EEST | [final-sideways-pixels-final-31] Epoch 70 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.05654\n",
      "trainer/Policy Loss                                              0.010213\n",
      "trainer/Raw Policy Loss                                          0.010213\n",
      "trainer/State estimation loss                                    0.00371408\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.4747\n",
      "trainer/Q Predictions Std                                       14.4284\n",
      "trainer/Q Predictions Max                                       15.5325\n",
      "trainer/Q Predictions Min                                      -49.8216\n",
      "trainer/Q Targets Mean                                         -10.4905\n",
      "trainer/Q Targets Std                                           14.5119\n",
      "trainer/Q Targets Max                                           16.2597\n",
      "trainer/Q Targets Min                                          -49.9841\n",
      "trainer/Bellman Errors Mean                                      1.05654\n",
      "trainer/Bellman Errors Std                                       6.63755\n",
      "trainer/Bellman Errors Max                                     186.442\n",
      "trainer/Bellman Errors Min                                       1.76078e-09\n",
      "trainer/Policy Action Mean                                      -0.193165\n",
      "trainer/Policy Action Std                                        0.660696\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  75122\n",
      "exploration/num paths total                                   1752\n",
      "exploration/path length Mean                                    30.55\n",
      "exploration/path length Std                                     18.6895\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                     10\n",
      "exploration/Rewards Mean                                        -0.981997\n",
      "exploration/Rewards Std                                          0.132963\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -30\n",
      "exploration/Returns Std                                         19.1585\n",
      "exploration/Returns Max                                         -9\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.205609\n",
      "exploration/Actions Std                                          0.630321\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           40\n",
      "exploration/Average Returns                                    -30\n",
      "exploration/env_infos/final/is_success Mean                      0.55\n",
      "exploration/env_infos/final/is_success Std                       0.497494\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0180033\n",
      "exploration/env_infos/is_success Std                             0.132963\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   36221\n",
      "evaluation/num paths total                                     893\n",
      "evaluation/path length Mean                                     14.4054\n",
      "evaluation/path length Std                                      10.8838\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       8\n",
      "evaluation/Rewards Mean                                         -0.93621\n",
      "evaluation/Rewards Std                                           0.244378\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -13.4865\n",
      "evaluation/Returns Std                                          11.1492\n",
      "evaluation/Returns Max                                          -7\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.266871\n",
      "evaluation/Actions Std                                           0.682734\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            37\n",
      "evaluation/Average Returns                                     -13.4865\n",
      "evaluation/env_infos/final/is_success Mean                       0.918919\n",
      "evaluation/env_infos/final/is_success Std                        0.27296\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0637899\n",
      "evaluation/env_infos/is_success Std                              0.244378\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.124901\n",
      "time/evaluation sampling (s)                                    17.189\n",
      "time/exploration sampling (s)                                   40.8801\n",
      "time/logging (s)                                                 0.00773327\n",
      "time/saving (s)                                                  0.0700144\n",
      "time/training (s)                                              206.926\n",
      "time/epoch (s)                                                 265.197\n",
      "time/total (s)                                               18313.8\n",
      "Epoch                                                           70\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 71\n",
      "\n",
      " Cycle 0 71\n",
      "Added episode 50\n",
      "Replay buf 75172\n",
      "Soft update 56800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 20\n",
      "Added episode 11\n",
      "Added episode 12\n",
      "Replay buf 75225\n",
      "Soft update 56840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 19\n",
      "Added episode 27\n",
      "Added episode 11\n",
      "Replay buf 75282\n",
      "Soft update 56880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 75362\n",
      "Soft update 56920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 29\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 75453\n",
      "Soft update 56960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 75514\n",
      "Soft update 57000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 75583\n",
      "Soft update 57040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 75642\n",
      "Soft update 57080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 71\n",
      "Added episode 50\n",
      "Replay buf 75692\n",
      "Soft update 57120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 16\n",
      "Added episode 13\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 75790\n",
      "Soft update 57160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 75852\n",
      "Soft update 57200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 75913\n",
      "Soft update 57240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 75990\n",
      "Soft update 57280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 76075\n",
      "Soft update 57320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 71\n",
      "Added episode 50\n",
      "Replay buf 76125\n",
      "Soft update 57360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 10\n",
      "Added episode 26\n",
      "Added episode 50\n",
      "Replay buf 76223\n",
      "Soft update 57400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 13\n",
      "Added episode 21\n",
      "Added episode 50\n",
      "Replay buf 76322\n",
      "Soft update 57440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 13\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 23\n",
      "Replay buf 76392\n",
      "Soft update 57480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 24\n",
      "Added episode 50\n",
      "Replay buf 76466\n",
      "Soft update 57520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 71\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 22\n",
      "Added episode 50\n",
      "Replay buf 76538\n",
      "Soft update 57560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:02:29.046292 EEST | [final-sideways-pixels-final-31] Epoch 71 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.25647\n",
      "trainer/Policy Loss                                              0.0104183\n",
      "trainer/Raw Policy Loss                                          0.0104183\n",
      "trainer/State estimation loss                                    0.00406965\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.7599\n",
      "trainer/Q Predictions Std                                       14.3177\n",
      "trainer/Q Predictions Max                                       13.4524\n",
      "trainer/Q Predictions Min                                      -52.1678\n",
      "trainer/Q Targets Mean                                         -10.6389\n",
      "trainer/Q Targets Std                                           14.3711\n",
      "trainer/Q Targets Max                                           13.6326\n",
      "trainer/Q Targets Min                                          -52.1558\n",
      "trainer/Bellman Errors Mean                                      1.25647\n",
      "trainer/Bellman Errors Std                                       6.27255\n",
      "trainer/Bellman Errors Max                                     131.196\n",
      "trainer/Bellman Errors Min                                       5.30868e-07\n",
      "trainer/Policy Action Mean                                      -0.162671\n",
      "trainer/Policy Action Std                                        0.683134\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  76538\n",
      "exploration/num paths total                                   1809\n",
      "exploration/path length Mean                                    24.8421\n",
      "exploration/path length Std                                     17.0436\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.971751\n",
      "exploration/Rewards Std                                          0.165682\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -24.1404\n",
      "exploration/Returns Std                                         17.4843\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.199362\n",
      "exploration/Actions Std                                          0.654443\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           57\n",
      "exploration/Average Returns                                    -24.1404\n",
      "exploration/env_infos/final/is_success Mean                      0.701754\n",
      "exploration/env_infos/final/is_success Std                       0.457488\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0282486\n",
      "exploration/env_infos/is_success Std                             0.165682\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   36729\n",
      "evaluation/num paths total                                     904\n",
      "evaluation/path length Mean                                     46.1818\n",
      "evaluation/path length Std                                       9.15342\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      19\n",
      "evaluation/Rewards Mean                                         -0.996063\n",
      "evaluation/Rewards Std                                           0.0626219\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -46\n",
      "evaluation/Returns Std                                           9.49641\n",
      "evaluation/Returns Max                                         -18\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.191844\n",
      "evaluation/Actions Std                                           0.613436\n",
      "evaluation/Actions Max                                           0.999959\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            11\n",
      "evaluation/Average Returns                                     -46\n",
      "evaluation/env_infos/final/is_success Mean                       0.181818\n",
      "evaluation/env_infos/final/is_success Std                        0.385695\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.00393701\n",
      "evaluation/env_infos/is_success Std                              0.0626219\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.140333\n",
      "time/evaluation sampling (s)                                    17.0277\n",
      "time/exploration sampling (s)                                   47.0941\n",
      "time/logging (s)                                                 0.00787805\n",
      "time/saving (s)                                                  0.0838841\n",
      "time/training (s)                                              209.147\n",
      "time/epoch (s)                                                 273.501\n",
      "time/total (s)                                               18587.3\n",
      "Epoch                                                           71\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 21\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 72\n",
      "\n",
      " Cycle 0 72\n",
      "Added episode 50\n",
      "Replay buf 76588\n",
      "Soft update 57600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 18\n",
      "Added episode 12\n",
      "Added episode 12\n",
      "Replay buf 76640\n",
      "Soft update 57640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 72\n",
      "Added episode 50\n",
      "Replay buf 76690\n",
      "Soft update 57680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 72\n",
      "Added episode 50\n",
      "Replay buf 76740\n",
      "Soft update 57720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 76813\n",
      "Soft update 57760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 16\n",
      "Added episode 9\n",
      "Replay buf 76868\n",
      "Soft update 57800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 72\n",
      "Added episode 50\n",
      "Replay buf 76918\n",
      "Soft update 57840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 72\n",
      "Added episode 50\n",
      "Replay buf 76968\n",
      "Soft update 57880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 34\n",
      "Replay buf 77022\n",
      "Soft update 57920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 72\n",
      "Added episode 50\n",
      "Replay buf 77072\n",
      "Soft update 57960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 14\n",
      "Added episode 28\n",
      "Replay buf 77126\n",
      "Soft update 58000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 21\n",
      "Added episode 50\n",
      "Replay buf 77207\n",
      "Soft update 58040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 72\n",
      "Added episode 50\n",
      "Replay buf 77257\n",
      "Soft update 58080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 72\n",
      "Added episode 50\n",
      "Replay buf 77307\n",
      "Soft update 58120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 72\n",
      "Added episode 50\n",
      "Replay buf 77357\n",
      "Soft update 58160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 72\n",
      "Added episode 50\n",
      "Replay buf 77407\n",
      "Soft update 58200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 17\n",
      "Added episode 50\n",
      "Replay buf 77492\n",
      "Soft update 58240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 9\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 77574\n",
      "Soft update 58280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 77643\n",
      "Soft update 58320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 72\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 77716\n",
      "Soft update 58360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:07:05.123416 EEST | [final-sideways-pixels-final-31] Epoch 72 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                  1.24933\n",
      "trainer/Policy Loss                                              0.0100748\n",
      "trainer/Raw Policy Loss                                          0.0100748\n",
      "trainer/State estimation loss                                    0.00421557\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.3572\n",
      "trainer/Q Predictions Std                                       14.3561\n",
      "trainer/Q Predictions Max                                       24.7457\n",
      "trainer/Q Predictions Min                                      -52.0487\n",
      "trainer/Q Targets Mean                                         -10.297\n",
      "trainer/Q Targets Std                                           14.3791\n",
      "trainer/Q Targets Max                                           25.6982\n",
      "trainer/Q Targets Min                                          -51.6212\n",
      "trainer/Bellman Errors Mean                                      1.24933\n",
      "trainer/Bellman Errors Std                                       6.87856\n",
      "trainer/Bellman Errors Max                                     176.393\n",
      "trainer/Bellman Errors Min                                       5.8677e-08\n",
      "trainer/Policy Action Mean                                      -0.170972\n",
      "trainer/Policy Action Std                                        0.673979\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  77716\n",
      "exploration/num paths total                                   1853\n",
      "exploration/path length Mean                                    26.7727\n",
      "exploration/path length Std                                     18.157\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.976231\n",
      "exploration/Rewards Std                                          0.152329\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -26.1364\n",
      "exploration/Returns Std                                         18.6226\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.179294\n",
      "exploration/Actions Std                                          0.647327\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           44\n",
      "exploration/Average Returns                                    -26.1364\n",
      "exploration/env_infos/final/is_success Mean                      0.636364\n",
      "exploration/env_infos/final/is_success Std                       0.481046\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0237691\n",
      "exploration/env_infos/is_success Std                             0.152329\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   37262\n",
      "evaluation/num paths total                                     918\n",
      "evaluation/path length Mean                                     38.0714\n",
      "evaluation/path length Std                                      12.5041\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      20\n",
      "evaluation/Rewards Mean                                         -0.986867\n",
      "evaluation/Rewards Std                                           0.113845\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -37.5714\n",
      "evaluation/Returns Std                                          12.9819\n",
      "evaluation/Returns Max                                         -19\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.25235\n",
      "evaluation/Actions Std                                           0.602225\n",
      "evaluation/Actions Max                                           0.999997\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            14\n",
      "evaluation/Average Returns                                     -37.5714\n",
      "evaluation/env_infos/final/is_success Mean                       0.5\n",
      "evaluation/env_infos/final/is_success Std                        0.5\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0131332\n",
      "evaluation/env_infos/is_success Std                              0.113845\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.12452\n",
      "time/evaluation sampling (s)                                    19.5012\n",
      "time/exploration sampling (s)                                   39.5518\n",
      "time/logging (s)                                                 0.00736644\n",
      "time/saving (s)                                                  0.0707603\n",
      "time/training (s)                                              216.815\n",
      "time/epoch (s)                                                 276.071\n",
      "time/total (s)                                               18863.4\n",
      "Epoch                                                           72\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 16\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 73\n",
      "\n",
      " Cycle 0 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 77792\n",
      "Soft update 58400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 77873\n",
      "Soft update 58440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 73\n",
      "Added episode 50\n",
      "Replay buf 77923\n",
      "Soft update 58480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 77984\n",
      "Soft update 58520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 73\n",
      "Added episode 50\n",
      "Replay buf 78034\n",
      "Soft update 58560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 78120\n",
      "Soft update 58600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 73\n",
      "Added episode 50\n",
      "Replay buf 78170\n",
      "Soft update 58640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 78231\n",
      "Soft update 58680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 78292\n",
      "Soft update 58720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 73\n",
      "Added episode 50\n",
      "Replay buf 78342\n",
      "Soft update 58760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 19\n",
      "Added episode 50\n",
      "Replay buf 78411\n",
      "Soft update 58800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 78484\n",
      "Soft update 58840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Added episode 26\n",
      "Added episode 9\n",
      "Replay buf 78538\n",
      "Soft update 58880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 20\n",
      "Added episode 13\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 78630\n",
      "Soft update 58920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 78689\n",
      "Soft update 58960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 78749\n",
      "Soft update 59000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 78829\n",
      "Soft update 59040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 11\n",
      "Added episode 9\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 12\n",
      "Replay buf 78890\n",
      "Soft update 59080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 78970\n",
      "Soft update 59120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 73\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 79047\n",
      "Soft update 59160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:11:40.454957 EEST | [final-sideways-pixels-final-31] Epoch 73 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.43828\n",
      "trainer/Policy Loss                                              0.0102769\n",
      "trainer/Raw Policy Loss                                          0.0102769\n",
      "trainer/State estimation loss                                    0.00358168\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.6161\n",
      "trainer/Q Predictions Std                                       14.825\n",
      "trainer/Q Predictions Max                                       17.3629\n",
      "trainer/Q Predictions Min                                      -53.1602\n",
      "trainer/Q Targets Mean                                         -10.7469\n",
      "trainer/Q Targets Std                                           14.7467\n",
      "trainer/Q Targets Max                                           18.0538\n",
      "trainer/Q Targets Min                                          -53.3237\n",
      "trainer/Bellman Errors Mean                                      1.43828\n",
      "trainer/Bellman Errors Std                                       6.88462\n",
      "trainer/Bellman Errors Max                                     123.639\n",
      "trainer/Bellman Errors Min                                       4.58476e-07\n",
      "trainer/Policy Action Mean                                      -0.177798\n",
      "trainer/Policy Action Std                                        0.650127\n",
      "trainer/Policy Action Max                                        0.999999\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  79047\n",
      "exploration/num paths total                                   1906\n",
      "exploration/path length Mean                                    25.1132\n",
      "exploration/path length Std                                     18.0948\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.973704\n",
      "exploration/Rewards Std                                          0.160014\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -24.4528\n",
      "exploration/Returns Std                                         18.562\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.217411\n",
      "exploration/Actions Std                                          0.658222\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           53\n",
      "exploration/Average Returns                                    -24.4528\n",
      "exploration/env_infos/final/is_success Mean                      0.660377\n",
      "exploration/env_infos/final/is_success Std                       0.473581\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.026296\n",
      "exploration/env_infos/is_success Std                             0.160014\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   37811\n",
      "evaluation/num paths total                                     938\n",
      "evaluation/path length Mean                                     27.45\n",
      "evaluation/path length Std                                      16.5846\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.974499\n",
      "evaluation/Rewards Std                                           0.157641\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -26.75\n",
      "evaluation/Returns Std                                          16.9937\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.208976\n",
      "evaluation/Actions Std                                           0.614871\n",
      "evaluation/Actions Max                                           0.999999\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            20\n",
      "evaluation/Average Returns                                     -26.75\n",
      "evaluation/env_infos/final/is_success Mean                       0.7\n",
      "evaluation/env_infos/final/is_success Std                        0.458258\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0255009\n",
      "evaluation/env_infos/is_success Std                              0.157641\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.134333\n",
      "time/evaluation sampling (s)                                    19.2629\n",
      "time/exploration sampling (s)                                   43.6301\n",
      "time/logging (s)                                                 0.00783049\n",
      "time/saving (s)                                                  0.0699431\n",
      "time/training (s)                                              212.221\n",
      "time/epoch (s)                                                 275.326\n",
      "time/total (s)                                               19138.7\n",
      "Epoch                                                           73\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 9\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 74\n",
      "\n",
      " Cycle 0 74\n",
      "Added episode 50\n",
      "Replay buf 79097\n",
      "Soft update 59200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 74\n",
      "Added episode 50\n",
      "Replay buf 79147\n",
      "Soft update 59240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 74\n",
      "Added episode 50\n",
      "Replay buf 79197\n",
      "Soft update 59280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 74\n",
      "Added episode 50\n",
      "Replay buf 79247\n",
      "Soft update 59320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 74\n",
      "Added episode 50\n",
      "Replay buf 79297\n",
      "Soft update 59360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 74\n",
      "Added episode 50\n",
      "Replay buf 79347\n",
      "Soft update 59400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 21\n",
      "Added episode 30\n",
      "Replay buf 79411\n",
      "Soft update 59440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 79481\n",
      "Soft update 59480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 74\n",
      "Added episode 50\n",
      "Replay buf 79531\n",
      "Soft update 59520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 79608\n",
      "Soft update 59560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 50\n",
      "Replay buf 79675\n",
      "Soft update 59600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 79740\n",
      "Soft update 59640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 23\n",
      "Added episode 12\n",
      "Added episode 21\n",
      "Replay buf 79805\n",
      "Soft update 59680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 26\n",
      "Added episode 50\n",
      "Replay buf 79881\n",
      "Soft update 59720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 74\n",
      "Added episode 50\n",
      "Replay buf 79931\n",
      "Soft update 59760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 24\n",
      "Added episode 50\n",
      "Replay buf 80005\n",
      "Soft update 59800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 74\n",
      "Added episode 50\n",
      "Replay buf 80055\n",
      "Soft update 59840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 80115\n",
      "Soft update 59880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 74\n",
      "Added episode 50\n",
      "Replay buf 80165\n",
      "Soft update 59920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 74\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 80233\n",
      "Soft update 59960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:16:14.667395 EEST | [final-sideways-pixels-final-31] Epoch 74 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.93639\n",
      "trainer/Policy Loss                                              0.0105444\n",
      "trainer/Raw Policy Loss                                          0.0105444\n",
      "trainer/State estimation loss                                    0.00411997\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.8248\n",
      "trainer/Q Predictions Std                                       14.8782\n",
      "trainer/Q Predictions Max                                       20.4538\n",
      "trainer/Q Predictions Min                                      -51.814\n",
      "trainer/Q Targets Mean                                         -10.9086\n",
      "trainer/Q Targets Std                                           14.959\n",
      "trainer/Q Targets Max                                           21.1725\n",
      "trainer/Q Targets Min                                          -51.5654\n",
      "trainer/Bellman Errors Mean                                      1.93639\n",
      "trainer/Bellman Errors Std                                      15.6031\n",
      "trainer/Bellman Errors Max                                     383.917\n",
      "trainer/Bellman Errors Min                                       2.27601e-07\n",
      "trainer/Policy Action Mean                                      -0.183007\n",
      "trainer/Policy Action Std                                        0.625891\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  80233\n",
      "exploration/num paths total                                   1942\n",
      "exploration/path length Mean                                    32.9444\n",
      "exploration/path length Std                                     17.6901\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.984823\n",
      "exploration/Rewards Std                                          0.122257\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -32.4444\n",
      "exploration/Returns Std                                         18.1727\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.196677\n",
      "exploration/Actions Std                                          0.632347\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           36\n",
      "exploration/Average Returns                                    -32.4444\n",
      "exploration/env_infos/final/is_success Mean                      0.5\n",
      "exploration/env_infos/final/is_success Std                       0.5\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0151771\n",
      "exploration/env_infos/is_success Std                             0.122257\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   38320\n",
      "evaluation/num paths total                                     971\n",
      "evaluation/path length Mean                                     15.4242\n",
      "evaluation/path length Std                                      12.9171\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.943025\n",
      "evaluation/Rewards Std                                           0.231794\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -14.5455\n",
      "evaluation/Returns Std                                          13.2416\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.247388\n",
      "evaluation/Actions Std                                           0.708861\n",
      "evaluation/Actions Max                                           0.999999\n",
      "evaluation/Actions Min                                          -0.999999\n",
      "evaluation/Num Paths                                            33\n",
      "evaluation/Average Returns                                     -14.5455\n",
      "evaluation/env_infos/final/is_success Mean                       0.878788\n",
      "evaluation/env_infos/final/is_success Std                        0.326374\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0569745\n",
      "evaluation/env_infos/is_success Std                              0.231794\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.124367\n",
      "time/evaluation sampling (s)                                    15.9286\n",
      "time/exploration sampling (s)                                   39.4104\n",
      "time/logging (s)                                                 0.00752098\n",
      "time/saving (s)                                                  0.0710276\n",
      "time/training (s)                                              218.664\n",
      "time/epoch (s)                                                 274.206\n",
      "time/total (s)                                               19412.9\n",
      "Epoch                                                           74\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 9\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 75\n",
      "\n",
      " Cycle 0 75\n",
      "Added episode 50\n",
      "Replay buf 80283\n",
      "Soft update 60000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 75\n",
      "Added episode 50\n",
      "Replay buf 80333\n",
      "Soft update 60040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 75\n",
      "Added episode 50\n",
      "Replay buf 80383\n",
      "Soft update 60080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 80456\n",
      "Soft update 60120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 80520\n",
      "Soft update 60160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 26\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 80607\n",
      "Soft update 60200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 75\n",
      "Added episode 50\n",
      "Replay buf 80657\n",
      "Soft update 60240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 75\n",
      "Added episode 50\n",
      "Replay buf 80707\n",
      "Soft update 60280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 15\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 80796\n",
      "Soft update 60320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 34\n",
      "Added episode 18\n",
      "Replay buf 80848\n",
      "Soft update 60360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 75\n",
      "Added episode 50\n",
      "Replay buf 80898\n",
      "Soft update 60400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 80962\n",
      "Soft update 60440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 75\n",
      "Added episode 50\n",
      "Replay buf 81012\n",
      "Soft update 60480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 81072\n",
      "Soft update 60520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 81133\n",
      "Soft update 60560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 10\n",
      "Added episode 16\n",
      "Added episode 11\n",
      "Added episode 13\n",
      "Replay buf 81195\n",
      "Soft update 60600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 75\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 81254\n",
      "Soft update 60640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 75\n",
      "Added episode 50\n",
      "Replay buf 81304\n",
      "Soft update 60680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 75\n",
      "Added episode 50\n",
      "Replay buf 81354\n",
      "Soft update 60720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 75\n",
      "Added episode 50\n",
      "Replay buf 81404\n",
      "Soft update 60760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:20:46.521115 EEST | [final-sideways-pixels-final-31] Epoch 75 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.19597\n",
      "trainer/Policy Loss                                              0.010566\n",
      "trainer/Raw Policy Loss                                          0.010566\n",
      "trainer/State estimation loss                                    0.00382446\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.7902\n",
      "trainer/Q Predictions Std                                       15.6062\n",
      "trainer/Q Predictions Max                                       30.6027\n",
      "trainer/Q Predictions Min                                      -53.3063\n",
      "trainer/Q Targets Mean                                         -10.833\n",
      "trainer/Q Targets Std                                           15.7646\n",
      "trainer/Q Targets Max                                           30.8744\n",
      "trainer/Q Targets Min                                          -53.6231\n",
      "trainer/Bellman Errors Mean                                      1.19597\n",
      "trainer/Bellman Errors Std                                       6.22905\n",
      "trainer/Bellman Errors Max                                     115.29\n",
      "trainer/Bellman Errors Min                                       9.14732e-07\n",
      "trainer/Policy Action Mean                                      -0.166626\n",
      "trainer/Policy Action Std                                        0.651964\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  81404\n",
      "exploration/num paths total                                   1979\n",
      "exploration/path length Mean                                    31.6486\n",
      "exploration/path length Std                                     18.3807\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.983775\n",
      "exploration/Rewards Std                                          0.126342\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -31.1351\n",
      "exploration/Returns Std                                         18.8668\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.192053\n",
      "exploration/Actions Std                                          0.623706\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           37\n",
      "exploration/Average Returns                                    -31.1351\n",
      "exploration/env_infos/final/is_success Mean                      0.513513\n",
      "exploration/env_infos/final/is_success Std                       0.499817\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0162254\n",
      "exploration/env_infos/is_success Std                             0.126342\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   38820\n",
      "evaluation/num paths total                                     994\n",
      "evaluation/path length Mean                                     21.7391\n",
      "evaluation/path length Std                                      17.2531\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.966\n",
      "evaluation/Rewards Std                                           0.181229\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -21\n",
      "evaluation/Returns Std                                          17.6807\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.21958\n",
      "evaluation/Actions Std                                           0.657114\n",
      "evaluation/Actions Max                                           0.999994\n",
      "evaluation/Actions Min                                          -0.999999\n",
      "evaluation/Num Paths                                            23\n",
      "evaluation/Average Returns                                     -21\n",
      "evaluation/env_infos/final/is_success Mean                       0.73913\n",
      "evaluation/env_infos/final/is_success Std                        0.439109\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.034\n",
      "evaluation/env_infos/is_success Std                              0.181229\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.12146\n",
      "time/evaluation sampling (s)                                    17.4455\n",
      "time/exploration sampling (s)                                   38.9428\n",
      "time/logging (s)                                                 0.00782182\n",
      "time/saving (s)                                                  0.0712926\n",
      "time/training (s)                                              215.259\n",
      "time/epoch (s)                                                 271.848\n",
      "time/total (s)                                               19684.8\n",
      "Epoch                                                           75\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 19\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 76\n",
      "\n",
      " Cycle 0 76\n",
      "Added episode 50\n",
      "Replay buf 81454\n",
      "Soft update 60800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 76\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 81514\n",
      "Soft update 60840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 76\n",
      "Added episode 50\n",
      "Replay buf 81564\n",
      "Soft update 60880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 76\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 81635\n",
      "Soft update 60920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 76\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 9\n",
      "Added episode 12\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Added episode 9\n",
      "Replay buf 81693\n",
      "Soft update 60960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 76\n",
      "Added episode 50\n",
      "Replay buf 81743\n",
      "Soft update 61000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 76\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 24\n",
      "Added episode 50\n",
      "Replay buf 81817\n",
      "Soft update 61040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 76\n",
      "Added episode 50\n",
      "Replay buf 81867\n",
      "Soft update 61080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 76\n",
      "Added episode 50\n",
      "Replay buf 81917\n",
      "Soft update 61120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 76\n",
      "Added episode 50\n",
      "Replay buf 81967\n",
      "Soft update 61160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 76\n",
      "Added episode 50\n",
      "Replay buf 82017\n",
      "Soft update 61200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 76\n",
      "Added episode 50\n",
      "Replay buf 82067\n",
      "Soft update 61240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 76\n",
      "Added episode 50\n",
      "Replay buf 82117\n",
      "Soft update 61280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 76\n",
      "Added episode 50\n",
      "Replay buf 82167\n",
      "Soft update 61320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 76\n",
      "Added episode 50\n",
      "Replay buf 82217\n",
      "Soft update 61360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 76\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 82277\n",
      "Soft update 61400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 76\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 82348\n",
      "Soft update 61440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 76\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 82411\n",
      "Soft update 61480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 76\n",
      "Added episode 50\n",
      "Replay buf 82461\n",
      "Soft update 61520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 76\n",
      "Added episode 50\n",
      "Replay buf 82511\n",
      "Soft update 61560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:25:14.306021 EEST | [final-sideways-pixels-final-31] Epoch 76 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  2.39795\n",
      "trainer/Policy Loss                                              0.0107058\n",
      "trainer/Raw Policy Loss                                          0.0107058\n",
      "trainer/State estimation loss                                    0.00389934\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.9108\n",
      "trainer/Q Predictions Std                                       15.7673\n",
      "trainer/Q Predictions Max                                       23.7163\n",
      "trainer/Q Predictions Min                                      -64.3421\n",
      "trainer/Q Targets Mean                                         -10.8996\n",
      "trainer/Q Targets Std                                           15.7245\n",
      "trainer/Q Targets Max                                           22.8751\n",
      "trainer/Q Targets Min                                          -63.5349\n",
      "trainer/Bellman Errors Mean                                      2.39795\n",
      "trainer/Bellman Errors Std                                      35.5283\n",
      "trainer/Bellman Errors Max                                    1191.19\n",
      "trainer/Bellman Errors Min                                       2.57409e-07\n",
      "trainer/Policy Action Mean                                      -0.208351\n",
      "trainer/Policy Action Std                                        0.674322\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  82511\n",
      "exploration/num paths total                                   2012\n",
      "exploration/path length Mean                                    33.5455\n",
      "exploration/path length Std                                     19.3251\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.987353\n",
      "exploration/Rewards Std                                          0.111745\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -33.1212\n",
      "exploration/Returns Std                                         19.8154\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.188616\n",
      "exploration/Actions Std                                          0.628691\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           33\n",
      "exploration/Average Returns                                    -33.1212\n",
      "exploration/env_infos/final/is_success Mean                      0.424242\n",
      "exploration/env_infos/final/is_success Std                       0.494227\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0126468\n",
      "exploration/env_infos/is_success Std                             0.111745\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   39351\n",
      "evaluation/num paths total                                    1034\n",
      "evaluation/path length Mean                                     13.275\n",
      "evaluation/path length Std                                       9.03877\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.926554\n",
      "evaluation/Rewards Std                                           0.260868\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -12.3\n",
      "evaluation/Returns Std                                           9.14112\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.232413\n",
      "evaluation/Actions Std                                           0.720316\n",
      "evaluation/Actions Max                                           0.999999\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            40\n",
      "evaluation/Average Returns                                     -12.3\n",
      "evaluation/env_infos/final/is_success Mean                       0.975\n",
      "evaluation/env_infos/final/is_success Std                        0.156125\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0734463\n",
      "evaluation/env_infos/is_success Std                              0.260868\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.115496\n",
      "time/evaluation sampling (s)                                    17.4691\n",
      "time/exploration sampling (s)                                   37.4871\n",
      "time/logging (s)                                                 0.00748542\n",
      "time/saving (s)                                                  0.0698597\n",
      "time/training (s)                                              212.63\n",
      "time/epoch (s)                                                 267.779\n",
      "time/total (s)                                               19952.6\n",
      "Epoch                                                           76\n",
      "-----------------------------------------------------------  ---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation sampling\n",
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 10\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 77\n",
      "\n",
      " Cycle 0 77\n",
      "Added episode 50\n",
      "Replay buf 82561\n",
      "Soft update 61600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 16\n",
      "Added episode 12\n",
      "Added episode 9\n",
      "Added episode 13\n",
      "Replay buf 82621\n",
      "Soft update 61640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 82680\n",
      "Soft update 61680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 82743\n",
      "Soft update 61720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 82803\n",
      "Soft update 61760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 77\n",
      "Added episode 50\n",
      "Replay buf 82853\n",
      "Soft update 61800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 13\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 82939\n",
      "Soft update 61840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 82999\n",
      "Soft update 61880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 77\n",
      "Added episode 50\n",
      "Replay buf 83049\n",
      "Soft update 61920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 83110\n",
      "Soft update 61960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 77\n",
      "Added episode 50\n",
      "Replay buf 83160\n",
      "Soft update 62000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 77\n",
      "Added episode 50\n",
      "Replay buf 83210\n",
      "Soft update 62040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 77\n",
      "Added episode 50\n",
      "Replay buf 83260\n",
      "Soft update 62080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 77\n",
      "Added episode 50\n",
      "Replay buf 83310\n",
      "Soft update 62120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 77\n",
      "Added episode 50\n",
      "Replay buf 83360\n",
      "Soft update 62160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 83433\n",
      "Soft update 62200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 83495\n",
      "Soft update 62240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 83565\n",
      "Soft update 62280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 77\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 19\n",
      "Added episode 50\n",
      "Replay buf 83634\n",
      "Soft update 62320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 77\n",
      "Added episode 50\n",
      "Replay buf 83684\n",
      "Soft update 62360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:29:44.421726 EEST | [final-sideways-pixels-final-31] Epoch 77 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  2.07935\n",
      "trainer/Policy Loss                                              0.0111029\n",
      "trainer/Raw Policy Loss                                          0.0111029\n",
      "trainer/State estimation loss                                    0.00382878\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -11.4209\n",
      "trainer/Q Predictions Std                                       15.734\n",
      "trainer/Q Predictions Max                                       25.6632\n",
      "trainer/Q Predictions Min                                      -54.4487\n",
      "trainer/Q Targets Mean                                         -11.4669\n",
      "trainer/Q Targets Std                                           15.7956\n",
      "trainer/Q Targets Max                                           25.5653\n",
      "trainer/Q Targets Min                                          -53.9423\n",
      "trainer/Bellman Errors Mean                                      2.07935\n",
      "trainer/Bellman Errors Std                                      17.02\n",
      "trainer/Bellman Errors Max                                     485.455\n",
      "trainer/Bellman Errors Min                                       9.31323e-10\n",
      "trainer/Policy Action Mean                                      -0.201648\n",
      "trainer/Policy Action Std                                        0.687075\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  83684\n",
      "exploration/num paths total                                   2050\n",
      "exploration/path length Mean                                    30.8684\n",
      "exploration/path length Std                                     19.2233\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.983802\n",
      "exploration/Rewards Std                                          0.126236\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -30.3684\n",
      "exploration/Returns Std                                         19.721\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.195736\n",
      "exploration/Actions Std                                          0.649466\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           38\n",
      "exploration/Average Returns                                    -30.3684\n",
      "exploration/env_infos/final/is_success Mean                      0.5\n",
      "exploration/env_infos/final/is_success Std                       0.5\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0161978\n",
      "exploration/env_infos/is_success Std                             0.126236\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   39893\n",
      "evaluation/num paths total                                    1062\n",
      "evaluation/path length Mean                                     19.3571\n",
      "evaluation/path length Std                                      14.7217\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.957565\n",
      "evaluation/Rewards Std                                           0.20158\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -18.5357\n",
      "evaluation/Returns Std                                          15.0937\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.227445\n",
      "evaluation/Actions Std                                           0.67996\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            28\n",
      "evaluation/Average Returns                                     -18.5357\n",
      "evaluation/env_infos/final/is_success Mean                       0.821429\n",
      "evaluation/env_infos/final/is_success Std                        0.382993\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0424354\n",
      "evaluation/env_infos/is_success Std                              0.20158\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.121073\n",
      "time/evaluation sampling (s)                                    17.0982\n",
      "time/exploration sampling (s)                                   38.5808\n",
      "time/logging (s)                                                 0.00756913\n",
      "time/saving (s)                                                  0.0698926\n",
      "time/training (s)                                              214.09\n",
      "time/epoch (s)                                                 269.967\n",
      "time/total (s)                                               20222.7\n",
      "Epoch                                                           77\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 12\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 78\n",
      "\n",
      " Cycle 0 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 83758\n",
      "Soft update 62400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 78\n",
      "Added episode 50\n",
      "Replay buf 83808\n",
      "Soft update 62440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 83869\n",
      "Soft update 62480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 78\n",
      "Added episode 50\n",
      "Replay buf 83919\n",
      "Soft update 62520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Added episode 12\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 84011\n",
      "Soft update 62560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 84073\n",
      "Soft update 62600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 24\n",
      "Added episode 17\n",
      "Added episode 10\n",
      "Replay buf 84124\n",
      "Soft update 62640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 25\n",
      "Added episode 50\n",
      "Replay buf 84199\n",
      "Soft update 62680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 84262\n",
      "Soft update 62720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 78\n",
      "Added episode 50\n",
      "Replay buf 84312\n",
      "Soft update 62760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 78\n",
      "Added episode 50\n",
      "Replay buf 84362\n",
      "Soft update 62800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 35\n",
      "Added episode 11\n",
      "Replay buf 84418\n",
      "Soft update 62840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 12\n",
      "Added episode 9\n",
      "Added episode 9\n",
      "Added episode 17\n",
      "Replay buf 84476\n",
      "Soft update 62880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 78\n",
      "Added episode 50\n",
      "Replay buf 84526\n",
      "Soft update 62920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 78\n",
      "Added episode 50\n",
      "Replay buf 84576\n",
      "Soft update 62960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 84636\n",
      "Soft update 63000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 78\n",
      "Added episode 50\n",
      "Replay buf 84686\n",
      "Soft update 63040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 12\n",
      "Added episode 14\n",
      "Added episode 38\n",
      "Replay buf 84760\n",
      "Soft update 63080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 14\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 84844\n",
      "Soft update 63120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 78\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 84915\n",
      "Soft update 63160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:34:15.252876 EEST | [final-sideways-pixels-final-31] Epoch 78 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.47955\n",
      "trainer/Policy Loss                                              0.0114429\n",
      "trainer/Raw Policy Loss                                          0.0114429\n",
      "trainer/State estimation loss                                    0.00375985\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -11.6763\n",
      "trainer/Q Predictions Std                                       15.3949\n",
      "trainer/Q Predictions Max                                       19.9274\n",
      "trainer/Q Predictions Min                                      -54.8293\n",
      "trainer/Q Targets Mean                                         -11.5011\n",
      "trainer/Q Targets Std                                           15.252\n",
      "trainer/Q Targets Max                                           19.9187\n",
      "trainer/Q Targets Min                                          -54.1166\n",
      "trainer/Bellman Errors Mean                                      1.47955\n",
      "trainer/Bellman Errors Std                                       8.12177\n",
      "trainer/Bellman Errors Max                                     140.758\n",
      "trainer/Bellman Errors Min                                       2.04342e-07\n",
      "trainer/Policy Action Mean                                      -0.184422\n",
      "trainer/Policy Action Std                                        0.655686\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  84915\n",
      "exploration/num paths total                                   2097\n",
      "exploration/path length Mean                                    26.1915\n",
      "exploration/path length Std                                     18.035\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.974817\n",
      "exploration/Rewards Std                                          0.15668\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -25.5319\n",
      "exploration/Returns Std                                         18.485\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.218373\n",
      "exploration/Actions Std                                          0.645217\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           47\n",
      "exploration/Average Returns                                    -25.5319\n",
      "exploration/env_infos/final/is_success Mean                      0.659574\n",
      "exploration/env_infos/final/is_success Std                       0.473852\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0251828\n",
      "exploration/env_infos/is_success Std                             0.15668\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   40403\n",
      "evaluation/num paths total                                    1094\n",
      "evaluation/path length Mean                                     15.9375\n",
      "evaluation/path length Std                                      13.0478\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.945098\n",
      "evaluation/Rewards Std                                           0.227789\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -15.0625\n",
      "evaluation/Returns Std                                          13.3743\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.221262\n",
      "evaluation/Actions Std                                           0.679936\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            32\n",
      "evaluation/Average Returns                                     -15.0625\n",
      "evaluation/env_infos/final/is_success Mean                       0.875\n",
      "evaluation/env_infos/final/is_success Std                        0.330719\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.054902\n",
      "evaluation/env_infos/is_success Std                              0.227789\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.125599\n",
      "time/evaluation sampling (s)                                    16.0653\n",
      "time/exploration sampling (s)                                   40.022\n",
      "time/logging (s)                                                 0.00759613\n",
      "time/saving (s)                                                  0.0696305\n",
      "time/training (s)                                              214.535\n",
      "time/epoch (s)                                                 270.825\n",
      "time/total (s)                                               20493.5\n",
      "Epoch                                                           78\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 8\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 79\n",
      "\n",
      " Cycle 0 79\n",
      "Added episode 50\n",
      "Replay buf 84965\n",
      "Soft update 63200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 79\n",
      "Added episode 50\n",
      "Replay buf 85015\n",
      "Soft update 63240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 85090\n",
      "Soft update 63280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 43\n",
      "Replay buf 85144\n",
      "Soft update 63320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 10\n",
      "Added episode 20\n",
      "Added episode 11\n",
      "Replay buf 85194\n",
      "Soft update 63360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 79\n",
      "Added episode 50\n",
      "Replay buf 85244\n",
      "Soft update 63400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 79\n",
      "Added episode 50\n",
      "Replay buf 85294\n",
      "Soft update 63440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 79\n",
      "Added episode 50\n",
      "Replay buf 85344\n",
      "Soft update 63480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 28\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 85437\n",
      "Soft update 63520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 79\n",
      "Added episode 50\n",
      "Replay buf 85487\n",
      "Soft update 63560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 85552\n",
      "Soft update 63600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 28\n",
      "Added episode 50\n",
      "Replay buf 85630\n",
      "Soft update 63640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 85690\n",
      "Soft update 63680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 17\n",
      "Added episode 50\n",
      "Replay buf 85768\n",
      "Soft update 63720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 85829\n",
      "Soft update 63760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 85899\n",
      "Soft update 63800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 50\n",
      "Replay buf 85966\n",
      "Soft update 63840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 79\n",
      "Added episode 50\n",
      "Replay buf 86016\n",
      "Soft update 63880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 86081\n",
      "Soft update 63920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 79\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 10\n",
      "Added episode 36\n",
      "Replay buf 86140\n",
      "Soft update 63960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:38:46.028228 EEST | [final-sideways-pixels-final-31] Epoch 79 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  --------------\n",
      "trainer/QF Loss                                                  1.31984\n",
      "trainer/Policy Loss                                              0.0104371\n",
      "trainer/Raw Policy Loss                                          0.0104371\n",
      "trainer/State estimation loss                                    0.00365753\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.6606\n",
      "trainer/Q Predictions Std                                       15.5869\n",
      "trainer/Q Predictions Max                                       26.4983\n",
      "trainer/Q Predictions Min                                      -54.4936\n",
      "trainer/Q Targets Mean                                         -10.7875\n",
      "trainer/Q Targets Std                                           15.7099\n",
      "trainer/Q Targets Max                                           26.8909\n",
      "trainer/Q Targets Min                                          -54.5702\n",
      "trainer/Bellman Errors Mean                                      1.31984\n",
      "trainer/Bellman Errors Std                                       5.75842\n",
      "trainer/Bellman Errors Max                                      95.8815\n",
      "trainer/Bellman Errors Min                                       5.7917e-07\n",
      "trainer/Policy Action Mean                                      -0.164349\n",
      "trainer/Policy Action Std                                        0.65801\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  86140\n",
      "exploration/num paths total                                   2137\n",
      "exploration/path length Mean                                    30.625\n",
      "exploration/path length Std                                     17.9565\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.981225\n",
      "exploration/Rewards Std                                          0.135731\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -30.05\n",
      "exploration/Returns Std                                         18.416\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.197119\n",
      "exploration/Actions Std                                          0.628604\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           40\n",
      "exploration/Average Returns                                    -30.05\n",
      "exploration/env_infos/final/is_success Mean                      0.575\n",
      "exploration/env_infos/final/is_success Std                       0.494343\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0187755\n",
      "exploration/env_infos/is_success Std                             0.135731\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   40906\n",
      "evaluation/num paths total                                    1131\n",
      "evaluation/path length Mean                                     13.5946\n",
      "evaluation/path length Std                                      10.8788\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.932406\n",
      "evaluation/Rewards Std                                           0.251049\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -12.6757\n",
      "evaluation/Returns Std                                          11.1502\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.240911\n",
      "evaluation/Actions Std                                           0.709912\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            37\n",
      "evaluation/Average Returns                                     -12.6757\n",
      "evaluation/env_infos/final/is_success Mean                       0.918919\n",
      "evaluation/env_infos/final/is_success Std                        0.27296\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0675944\n",
      "evaluation/env_infos/is_success Std                              0.251049\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.128024\n",
      "time/evaluation sampling (s)                                    15.913\n",
      "time/exploration sampling (s)                                   41.6022\n",
      "time/logging (s)                                                 0.00752995\n",
      "time/saving (s)                                                  0.0703771\n",
      "time/training (s)                                              213.048\n",
      "time/epoch (s)                                                 270.77\n",
      "time/total (s)                                               20764.3\n",
      "Epoch                                                           79\n",
      "-----------------------------------------------------------  --------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 80\n",
      "\n",
      " Cycle 0 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 86205\n",
      "Soft update 64000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 86276\n",
      "Soft update 64040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 80\n",
      "Added episode 50\n",
      "Replay buf 86326\n",
      "Soft update 64080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 80\n",
      "Added episode 50\n",
      "Replay buf 86376\n",
      "Soft update 64120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 29\n",
      "Added episode 12\n",
      "Added episode 9\n",
      "Replay buf 86426\n",
      "Soft update 64160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 11\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 86512\n",
      "Soft update 64200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 9\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 18\n",
      "Replay buf 86571\n",
      "Soft update 64240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 80\n",
      "Added episode 50\n",
      "Replay buf 86621\n",
      "Soft update 64280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 86708\n",
      "Soft update 64320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 80\n",
      "Added episode 50\n",
      "Replay buf 86758\n",
      "Soft update 64360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 80\n",
      "Added episode 50\n",
      "Replay buf 86808\n",
      "Soft update 64400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 80\n",
      "Added episode 50\n",
      "Replay buf 86858\n",
      "Soft update 64440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 86918\n",
      "Soft update 64480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 87002\n",
      "Soft update 64520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 80\n",
      "Added episode 50\n",
      "Replay buf 87052\n",
      "Soft update 64560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 87113\n",
      "Soft update 64600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 87193\n",
      "Soft update 64640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 80\n",
      "Added episode 50\n",
      "Replay buf 87243\n",
      "Soft update 64680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 80\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 87323\n",
      "Soft update 64720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 80\n",
      "Added episode 50\n",
      "Replay buf 87373\n",
      "Soft update 64760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:43:15.728431 EEST | [final-sideways-pixels-final-31] Epoch 80 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  2.22857\n",
      "trainer/Policy Loss                                              0.0107564\n",
      "trainer/Raw Policy Loss                                          0.0107564\n",
      "trainer/State estimation loss                                    0.00354284\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -11.0716\n",
      "trainer/Q Predictions Std                                       15.7119\n",
      "trainer/Q Predictions Max                                       27.443\n",
      "trainer/Q Predictions Min                                      -54.2253\n",
      "trainer/Q Targets Mean                                         -11.1141\n",
      "trainer/Q Targets Std                                           15.7934\n",
      "trainer/Q Targets Max                                           27.5199\n",
      "trainer/Q Targets Min                                          -54.7409\n",
      "trainer/Bellman Errors Mean                                      2.22857\n",
      "trainer/Bellman Errors Std                                      19.085\n",
      "trainer/Bellman Errors Max                                     487.597\n",
      "trainer/Bellman Errors Min                                       3.35713e-08\n",
      "trainer/Policy Action Mean                                      -0.213565\n",
      "trainer/Policy Action Std                                        0.678164\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  87373\n",
      "exploration/num paths total                                   2183\n",
      "exploration/path length Mean                                    26.8043\n",
      "exploration/path length Std                                     18.8375\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.977291\n",
      "exploration/Rewards Std                                          0.148974\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -26.1957\n",
      "exploration/Returns Std                                         19.3195\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.218298\n",
      "exploration/Actions Std                                          0.652861\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           46\n",
      "exploration/Average Returns                                    -26.1957\n",
      "exploration/env_infos/final/is_success Mean                      0.608696\n",
      "exploration/env_infos/final/is_success Std                       0.488042\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0227088\n",
      "exploration/env_infos/is_success Std                             0.148974\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   41413\n",
      "evaluation/num paths total                                    1152\n",
      "evaluation/path length Mean                                     24.1429\n",
      "evaluation/path length Std                                      18.2972\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.972387\n",
      "evaluation/Rewards Std                                           0.163862\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -23.4762\n",
      "evaluation/Returns Std                                          18.7683\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.274312\n",
      "evaluation/Actions Std                                           0.659588\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            21\n",
      "evaluation/Average Returns                                     -23.4762\n",
      "evaluation/env_infos/final/is_success Mean                       0.666667\n",
      "evaluation/env_infos/final/is_success Std                        0.471405\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0276134\n",
      "evaluation/env_infos/is_success Std                              0.163862\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.125921\n",
      "time/evaluation sampling (s)                                    16.0228\n",
      "time/exploration sampling (s)                                   39.9678\n",
      "time/logging (s)                                                 0.00749789\n",
      "time/saving (s)                                                  0.0696185\n",
      "time/training (s)                                              213.501\n",
      "time/epoch (s)                                                 269.695\n",
      "time/total (s)                                               21034\n",
      "Epoch                                                           80\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Evaluation done\n",
      "Epoch 81\n",
      "\n",
      " Cycle 0 81\n",
      "Added episode 50\n",
      "Replay buf 87423\n",
      "Soft update 64800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 81\n",
      "Added episode 50\n",
      "Replay buf 87473\n",
      "Soft update 64840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 20\n",
      "Added episode 9\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Replay buf 87524\n",
      "Soft update 64880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 29\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 87617\n",
      "Soft update 64920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 87691\n",
      "Soft update 64960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 47\n",
      "Added episode 16\n",
      "Replay buf 87754\n",
      "Soft update 65000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 81\n",
      "Added episode 50\n",
      "Replay buf 87804\n",
      "Soft update 65040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 12\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 10\n",
      "Replay buf 87862\n",
      "Soft update 65080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 87934\n",
      "Soft update 65120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 10\n",
      "Added episode 12\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 88033\n",
      "Soft update 65160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 15\n",
      "Added episode 10\n",
      "Added episode 27\n",
      "Replay buf 88096\n",
      "Soft update 65200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 81\n",
      "Added episode 50\n",
      "Replay buf 88146\n",
      "Soft update 65240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 88214\n",
      "Soft update 65280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 81\n",
      "Added episode 50\n",
      "Replay buf 88264\n",
      "Soft update 65320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 88339\n",
      "Soft update 65360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 81\n",
      "Added episode 50\n",
      "Replay buf 88389\n",
      "Soft update 65400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 88449\n",
      "Soft update 65440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 81\n",
      "Added episode 50\n",
      "Replay buf 88499\n",
      "Soft update 65480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 88559\n",
      "Soft update 65520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 81\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 10\n",
      "Added episode 8\n",
      "Added episode 50\n",
      "Replay buf 88638\n",
      "Soft update 65560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:47:46.862840 EEST | [final-sideways-pixels-final-31] Epoch 81 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.11853\n",
      "trainer/Policy Loss                                              0.0114117\n",
      "trainer/Raw Policy Loss                                          0.0114117\n",
      "trainer/State estimation loss                                    0.00362436\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -11.6216\n",
      "trainer/Q Predictions Std                                       15.8654\n",
      "trainer/Q Predictions Max                                       22.9811\n",
      "trainer/Q Predictions Min                                      -55.824\n",
      "trainer/Q Targets Mean                                         -11.6473\n",
      "trainer/Q Targets Std                                           15.9834\n",
      "trainer/Q Targets Max                                           22.6966\n",
      "trainer/Q Targets Min                                          -55.319\n",
      "trainer/Bellman Errors Mean                                      1.11853\n",
      "trainer/Bellman Errors Std                                       4.19972\n",
      "trainer/Bellman Errors Max                                      61.9844\n",
      "trainer/Bellman Errors Min                                       9.09495e-09\n",
      "trainer/Policy Action Mean                                      -0.167877\n",
      "trainer/Policy Action Std                                        0.670649\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  88638\n",
      "exploration/num paths total                                   2232\n",
      "exploration/path length Mean                                    25.8163\n",
      "exploration/path length Std                                     17.8962\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      8\n",
      "exploration/Rewards Mean                                        -0.973913\n",
      "exploration/Rewards Std                                          0.159394\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -25.1429\n",
      "exploration/Returns Std                                         18.3381\n",
      "exploration/Returns Max                                         -7\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.206979\n",
      "exploration/Actions Std                                          0.665288\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           49\n",
      "exploration/Average Returns                                    -25.1429\n",
      "exploration/env_infos/final/is_success Mean                      0.673469\n",
      "exploration/env_infos/final/is_success Std                       0.468944\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.026087\n",
      "exploration/env_infos/is_success Std                             0.159394\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   41913\n",
      "evaluation/num paths total                                    1162\n",
      "evaluation/path length Mean                                     50\n",
      "evaluation/path length Std                                       0\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      50\n",
      "evaluation/Rewards Mean                                         -1\n",
      "evaluation/Rewards Std                                           0\n",
      "evaluation/Rewards Max                                          -1\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -50\n",
      "evaluation/Returns Std                                           0\n",
      "evaluation/Returns Max                                         -50\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.176652\n",
      "evaluation/Actions Std                                           0.66505\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            10\n",
      "evaluation/Average Returns                                     -50\n",
      "evaluation/env_infos/final/is_success Mean                       0\n",
      "evaluation/env_infos/final/is_success Std                        0\n",
      "evaluation/env_infos/final/is_success Max                        0\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0\n",
      "evaluation/env_infos/is_success Std                              0\n",
      "evaluation/env_infos/is_success Max                              0\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.126628\n",
      "time/evaluation sampling (s)                                    15.5645\n",
      "time/exploration sampling (s)                                   42.1977\n",
      "time/logging (s)                                                 0.00755508\n",
      "time/saving (s)                                                  0.0688835\n",
      "time/training (s)                                              213.163\n",
      "time/epoch (s)                                                 271.129\n",
      "time/total (s)                                               21305.1\n",
      "Epoch                                                           81\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Image capture 12\n",
      "Image capture 13\n",
      "Image capture 14\n",
      "Image capture 15\n",
      "Image capture 16\n",
      "Image capture 17\n",
      "Image capture 18\n",
      "Image capture 19\n",
      "Image capture 20\n",
      "Image capture 21\n",
      "Image capture 22\n",
      "Image capture 23\n",
      "Image capture 24\n",
      "Image capture 25\n",
      "Image capture 26\n",
      "Image capture 27\n",
      "Image capture 28\n",
      "Image capture 29\n",
      "Image capture 30\n",
      "Image capture 31\n",
      "Image capture 32\n",
      "Image capture 33\n",
      "Image capture 34\n",
      "Image capture 35\n",
      "Image capture 36\n",
      "Image capture 37\n",
      "Image capture 38\n",
      "Image capture 39\n",
      "Image capture 40\n",
      "Image capture 41\n",
      "Image capture 42\n",
      "Image capture 43\n",
      "Image capture 44\n",
      "Image capture 45\n",
      "Image capture 46\n",
      "Image capture 47\n",
      "Image capture 48\n",
      "Image capture 49\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 82\n",
      "\n",
      " Cycle 0 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 88709\n",
      "Soft update 65600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 20\n",
      "Added episode 50\n",
      "Replay buf 88779\n",
      "Soft update 65640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 82\n",
      "Added episode 50\n",
      "Replay buf 88829\n",
      "Soft update 65680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 82\n",
      "Added episode 50\n",
      "Replay buf 88879\n",
      "Soft update 65720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 88940\n",
      "Soft update 65760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 26\n",
      "Added episode 22\n",
      "Added episode 15\n",
      "Replay buf 89003\n",
      "Soft update 65800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 28\n",
      "Replay buf 89073\n",
      "Soft update 65840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 13\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Replay buf 89123\n",
      "Soft update 65880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 82\n",
      "Added episode 50\n",
      "Replay buf 89173\n",
      "Soft update 65920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 82\n",
      "Added episode 50\n",
      "Replay buf 89223\n",
      "Soft update 65960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 11\n",
      "Added episode 16\n",
      "Added episode 10\n",
      "Replay buf 89276\n",
      "Soft update 66000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 89339\n",
      "Soft update 66040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 82\n",
      "Added episode 50\n",
      "Replay buf 89389\n",
      "Soft update 66080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 89461\n",
      "Soft update 66120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 89529\n",
      "Soft update 66160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 89598\n",
      "Soft update 66200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 82\n",
      "Added episode 50\n",
      "Replay buf 89648\n",
      "Soft update 66240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 89719\n",
      "Soft update 66280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 82\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 27\n",
      "Added episode 50\n",
      "Replay buf 89796\n",
      "Soft update 66320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 82\n",
      "Added episode 50\n",
      "Replay buf 89846\n",
      "Soft update 66360\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:52:18.543611 EEST | [final-sideways-pixels-final-31] Epoch 82 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.55251\n",
      "trainer/Policy Loss                                              0.0108443\n",
      "trainer/Raw Policy Loss                                          0.0108443\n",
      "trainer/State estimation loss                                    0.00338576\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -11.0891\n",
      "trainer/Q Predictions Std                                       16.3855\n",
      "trainer/Q Predictions Max                                       36.7164\n",
      "trainer/Q Predictions Min                                      -55.7534\n",
      "trainer/Q Targets Mean                                         -11.1379\n",
      "trainer/Q Targets Std                                           16.4245\n",
      "trainer/Q Targets Max                                           33.9128\n",
      "trainer/Q Targets Min                                          -56.3961\n",
      "trainer/Bellman Errors Mean                                      1.55251\n",
      "trainer/Bellman Errors Std                                       7.75456\n",
      "trainer/Bellman Errors Max                                     140.757\n",
      "trainer/Bellman Errors Min                                       1.63919e-06\n",
      "trainer/Policy Action Mean                                      -0.239637\n",
      "trainer/Policy Action Std                                        0.681427\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  89846\n",
      "exploration/num paths total                                   2278\n",
      "exploration/path length Mean                                    26.2609\n",
      "exploration/path length Std                                     17.9012\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.975166\n",
      "exploration/Rewards Std                                          0.15562\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -25.6087\n",
      "exploration/Returns Std                                         18.3629\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.218317\n",
      "exploration/Actions Std                                          0.655757\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           46\n",
      "exploration/Average Returns                                    -25.6087\n",
      "exploration/env_infos/final/is_success Mean                      0.652174\n",
      "exploration/env_infos/final/is_success Std                       0.47628\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0248344\n",
      "exploration/env_infos/is_success Std                             0.15562\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   42419\n",
      "evaluation/num paths total                                    1186\n",
      "evaluation/path length Mean                                     21.0833\n",
      "evaluation/path length Std                                      17.1365\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.964427\n",
      "evaluation/Rewards Std                                           0.185223\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -20.3333\n",
      "evaluation/Returns Std                                          17.5586\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.276439\n",
      "evaluation/Actions Std                                           0.651552\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            24\n",
      "evaluation/Average Returns                                     -20.3333\n",
      "evaluation/env_infos/final/is_success Mean                       0.75\n",
      "evaluation/env_infos/final/is_success Std                        0.433013\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0355731\n",
      "evaluation/env_infos/is_success Std                              0.185223\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.123124\n",
      "time/evaluation sampling (s)                                    17.7486\n",
      "time/exploration sampling (s)                                   39.9064\n",
      "time/logging (s)                                                 0.00748877\n",
      "time/saving (s)                                                  0.070842\n",
      "time/training (s)                                              213.819\n",
      "time/epoch (s)                                                 271.675\n",
      "time/total (s)                                               21576.8\n",
      "Epoch                                                           82\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 10\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 83\n",
      "\n",
      " Cycle 0 83\n",
      "Added episode 50\n",
      "Replay buf 89896\n",
      "Soft update 66400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 15\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Replay buf 89946\n",
      "Soft update 66440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 83\n",
      "Added episode 50\n",
      "Replay buf 89996\n",
      "Soft update 66480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 21\n",
      "Added episode 10\n",
      "Added episode 24\n",
      "Replay buf 90051\n",
      "Soft update 66520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 83\n",
      "Added episode 50\n",
      "Replay buf 90101\n",
      "Soft update 66560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 19\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 90185\n",
      "Soft update 66600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 83\n",
      "Added episode 50\n",
      "Replay buf 90235\n",
      "Soft update 66640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 83\n",
      "Added episode 50\n",
      "Replay buf 90285\n",
      "Soft update 66680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 83\n",
      "Added episode 50\n",
      "Replay buf 90335\n",
      "Soft update 66720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 9\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 90432\n",
      "Soft update 66760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 10\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 90517\n",
      "Soft update 66800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 83\n",
      "Added episode 50\n",
      "Replay buf 90567\n",
      "Soft update 66840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 90646\n",
      "Soft update 66880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Added episode 9\n",
      "Added episode 10\n",
      "Replay buf 90698\n",
      "Soft update 66920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 83\n",
      "Added episode 50\n",
      "Replay buf 90748\n",
      "Soft update 66960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 36\n",
      "Added episode 21\n",
      "Replay buf 90805\n",
      "Soft update 67000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 90878\n",
      "Soft update 67040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 90940\n",
      "Soft update 67080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 83\n",
      "Added episode 50\n",
      "Replay buf 90990\n",
      "Soft update 67120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 83\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 91058\n",
      "Soft update 67160\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 14:57:01.059054 EEST | [final-sideways-pixels-final-31] Epoch 83 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.66843\n",
      "trainer/Policy Loss                                              0.0102814\n",
      "trainer/Raw Policy Loss                                          0.0102814\n",
      "trainer/State estimation loss                                    0.00371561\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.5553\n",
      "trainer/Q Predictions Std                                       15.6034\n",
      "trainer/Q Predictions Max                                       26.2068\n",
      "trainer/Q Predictions Min                                      -70.4416\n",
      "trainer/Q Targets Mean                                         -10.6149\n",
      "trainer/Q Targets Std                                           15.7431\n",
      "trainer/Q Targets Max                                           26.1852\n",
      "trainer/Q Targets Min                                          -71.7415\n",
      "trainer/Bellman Errors Mean                                      1.66843\n",
      "trainer/Bellman Errors Std                                       9.09265\n",
      "trainer/Bellman Errors Max                                     218.861\n",
      "trainer/Bellman Errors Min                                       8.74024e-10\n",
      "trainer/Policy Action Mean                                      -0.204878\n",
      "trainer/Policy Action Std                                        0.649765\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  91058\n",
      "exploration/num paths total                                   2324\n",
      "exploration/path length Mean                                    26.3478\n",
      "exploration/path length Std                                     17.8949\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.975248\n",
      "exploration/Rewards Std                                          0.15537\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -25.6957\n",
      "exploration/Returns Std                                         18.355\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.197318\n",
      "exploration/Actions Std                                          0.651064\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           46\n",
      "exploration/Average Returns                                    -25.6957\n",
      "exploration/env_infos/final/is_success Mean                      0.652174\n",
      "exploration/env_infos/final/is_success Std                       0.47628\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0247525\n",
      "exploration/env_infos/is_success Std                             0.15537\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   42936\n",
      "evaluation/num paths total                                    1211\n",
      "evaluation/path length Mean                                     20.68\n",
      "evaluation/path length Std                                      16.5087\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.963249\n",
      "evaluation/Rewards Std                                           0.188149\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -19.92\n",
      "evaluation/Returns Std                                          16.935\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.214238\n",
      "evaluation/Actions Std                                           0.676378\n",
      "evaluation/Actions Max                                           0.999997\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            25\n",
      "evaluation/Average Returns                                     -19.92\n",
      "evaluation/env_infos/final/is_success Mean                       0.76\n",
      "evaluation/env_infos/final/is_success Std                        0.427083\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0367505\n",
      "evaluation/env_infos/is_success Std                              0.188149\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.129794\n",
      "time/evaluation sampling (s)                                    17.2179\n",
      "time/exploration sampling (s)                                   40.8976\n",
      "time/logging (s)                                                 0.00928717\n",
      "time/saving (s)                                                  0.0714653\n",
      "time/training (s)                                              224.185\n",
      "time/epoch (s)                                                 282.511\n",
      "time/total (s)                                               21859.3\n",
      "Epoch                                                           83\n",
      "-----------------------------------------------------------  ---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation sampling\n",
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 10\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 84\n",
      "\n",
      " Cycle 0 84\n",
      "Added episode 50\n",
      "Replay buf 91108\n",
      "Soft update 67200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 14\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 91204\n",
      "Soft update 67240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 91279\n",
      "Soft update 67280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 19\n",
      "Added episode 12\n",
      "Added episode 18\n",
      "Replay buf 91338\n",
      "Soft update 67320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 50\n",
      "Replay buf 91404\n",
      "Soft update 67360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 84\n",
      "Added episode 50\n",
      "Replay buf 91454\n",
      "Soft update 67400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 17\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 91530\n",
      "Soft update 67440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 84\n",
      "Added episode 50\n",
      "Replay buf 91580\n",
      "Soft update 67480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 33\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 91673\n",
      "Soft update 67520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 91744\n",
      "Soft update 67560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 84\n",
      "Added episode 50\n",
      "Replay buf 91794\n",
      "Soft update 67600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 20\n",
      "Added episode 28\n",
      "Replay buf 91851\n",
      "Soft update 67640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 91914\n",
      "Soft update 67680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 10\n",
      "Replay buf 91970\n",
      "Soft update 67720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 92053\n",
      "Soft update 67760\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 92112\n",
      "Soft update 67800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 21\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 92194\n",
      "Soft update 67840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 10\n",
      "Added episode 25\n",
      "Added episode 14\n",
      "Replay buf 92252\n",
      "Soft update 67880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 84\n",
      "Added episode 50\n",
      "Replay buf 92302\n",
      "Soft update 67920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 84\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 92364\n",
      "Soft update 67960\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 15:01:51.011900 EEST | [final-sideways-pixels-final-31] Epoch 84 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.43244\n",
      "trainer/Policy Loss                                              0.0107062\n",
      "trainer/Raw Policy Loss                                          0.0107062\n",
      "trainer/State estimation loss                                    0.00332198\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.9622\n",
      "trainer/Q Predictions Std                                       15.6916\n",
      "trainer/Q Predictions Max                                       31.1546\n",
      "trainer/Q Predictions Min                                      -58.369\n",
      "trainer/Q Targets Mean                                         -10.8762\n",
      "trainer/Q Targets Std                                           15.4962\n",
      "trainer/Q Targets Max                                           31.2217\n",
      "trainer/Q Targets Min                                          -56.2663\n",
      "trainer/Bellman Errors Mean                                      1.43244\n",
      "trainer/Bellman Errors Std                                       7.647\n",
      "trainer/Bellman Errors Max                                     228.263\n",
      "trainer/Bellman Errors Min                                       2.99591e-07\n",
      "trainer/Policy Action Mean                                      -0.206843\n",
      "trainer/Policy Action Std                                        0.696092\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  92364\n",
      "exploration/num paths total                                   2377\n",
      "exploration/path length Mean                                    24.6415\n",
      "exploration/path length Std                                     17.3043\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.971669\n",
      "exploration/Rewards Std                                          0.165916\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -23.9434\n",
      "exploration/Returns Std                                         17.7471\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.218619\n",
      "exploration/Actions Std                                          0.658133\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           53\n",
      "exploration/Average Returns                                    -23.9434\n",
      "exploration/env_infos/final/is_success Mean                      0.698113\n",
      "exploration/env_infos/final/is_success Std                       0.459076\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0283308\n",
      "exploration/env_infos/is_success Std                             0.165916\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   43459\n",
      "evaluation/num paths total                                    1248\n",
      "evaluation/path length Mean                                     14.1351\n",
      "evaluation/path length Std                                      10.728\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.93499\n",
      "evaluation/Rewards Std                                           0.246543\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -13.2162\n",
      "evaluation/Returns Std                                          10.9991\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.253329\n",
      "evaluation/Actions Std                                           0.733674\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            37\n",
      "evaluation/Average Returns                                     -13.2162\n",
      "evaluation/env_infos/final/is_success Mean                       0.918919\n",
      "evaluation/env_infos/final/is_success Std                        0.27296\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0650096\n",
      "evaluation/env_infos/is_success Std                              0.246543\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.133023\n",
      "time/evaluation sampling (s)                                    16.7842\n",
      "time/exploration sampling (s)                                   44.0369\n",
      "time/logging (s)                                                 0.010241\n",
      "time/saving (s)                                                  0.072169\n",
      "time/training (s)                                              228.911\n",
      "time/epoch (s)                                                 289.948\n",
      "time/total (s)                                               22149.2\n",
      "Epoch                                                           84\n",
      "-----------------------------------------------------------  ---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation sampling\n",
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 10\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 85\n",
      "\n",
      " Cycle 0 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 92444\n",
      "Soft update 68000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 85\n",
      "Added episode 50\n",
      "Replay buf 92494\n",
      "Soft update 68040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 50\n",
      "Replay buf 92562\n",
      "Soft update 68080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 16\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 92648\n",
      "Soft update 68120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 85\n",
      "Added episode 50\n",
      "Replay buf 92698\n",
      "Soft update 68160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 18\n",
      "Added episode 20\n",
      "Added episode 12\n",
      "Replay buf 92748\n",
      "Soft update 68200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 92807\n",
      "Soft update 68240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 92867\n",
      "Soft update 68280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 50\n",
      "Replay buf 92926\n",
      "Soft update 68320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 92998\n",
      "Soft update 68360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 85\n",
      "Added episode 50\n",
      "Replay buf 93048\n",
      "Soft update 68400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 85\n",
      "Added episode 50\n",
      "Replay buf 93098\n",
      "Soft update 68440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 15\n",
      "Added episode 13\n",
      "Added episode 9\n",
      "Added episode 13\n",
      "Replay buf 93159\n",
      "Soft update 68480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 16\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 93250\n",
      "Soft update 68520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 14\n",
      "Added episode 9\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Added episode 15\n",
      "Replay buf 93307\n",
      "Soft update 68560\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 13\n",
      "Added episode 11\n",
      "Added episode 16\n",
      "Replay buf 93359\n",
      "Soft update 68600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 85\n",
      "Added episode 50\n",
      "Replay buf 93409\n",
      "Soft update 68640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 85\n",
      "Added episode 50\n",
      "Replay buf 93459\n",
      "Soft update 68680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 85\n",
      "Added episode 50\n",
      "Replay buf 93509\n",
      "Soft update 68720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 85\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 93571\n",
      "Soft update 68760\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 15:06:37.406292 EEST | [final-sideways-pixels-final-31] Epoch 85 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  1.67882\n",
      "trainer/Policy Loss                                              0.0107379\n",
      "trainer/Raw Policy Loss                                          0.0107379\n",
      "trainer/State estimation loss                                    0.00353549\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -10.9769\n",
      "trainer/Q Predictions Std                                       15.8924\n",
      "trainer/Q Predictions Max                                       32.1731\n",
      "trainer/Q Predictions Min                                      -59.8377\n",
      "trainer/Q Targets Mean                                         -11.0074\n",
      "trainer/Q Targets Std                                           15.8282\n",
      "trainer/Q Targets Max                                           33.1787\n",
      "trainer/Q Targets Min                                          -60.9517\n",
      "trainer/Bellman Errors Mean                                      1.67882\n",
      "trainer/Bellman Errors Std                                      15.5105\n",
      "trainer/Bellman Errors Max                                     503.795\n",
      "trainer/Bellman Errors Min                                       3.84261e-09\n",
      "trainer/Policy Action Mean                                      -0.151585\n",
      "trainer/Policy Action Std                                        0.681992\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  93571\n",
      "exploration/num paths total                                   2425\n",
      "exploration/path length Mean                                    25.1458\n",
      "exploration/path length Std                                     17.7529\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.973488\n",
      "exploration/Rewards Std                                          0.160652\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -24.4792\n",
      "exploration/Returns Std                                         18.2197\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.208514\n",
      "exploration/Actions Std                                          0.675161\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           48\n",
      "exploration/Average Returns                                    -24.4792\n",
      "exploration/env_infos/final/is_success Mean                      0.666667\n",
      "exploration/env_infos/final/is_success Std                       0.471405\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.026512\n",
      "exploration/env_infos/is_success Std                             0.160652\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   43967\n",
      "evaluation/num paths total                                    1280\n",
      "evaluation/path length Mean                                     15.875\n",
      "evaluation/path length Std                                      11.6478\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                      10\n",
      "evaluation/Rewards Mean                                         -0.942913\n",
      "evaluation/Rewards Std                                           0.232008\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -14.9688\n",
      "evaluation/Returns Std                                          11.9229\n",
      "evaluation/Returns Max                                          -9\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.18388\n",
      "evaluation/Actions Std                                           0.707494\n",
      "evaluation/Actions Max                                           1\n",
      "evaluation/Actions Min                                          -0.999999\n",
      "evaluation/Num Paths                                            32\n",
      "evaluation/Average Returns                                     -14.9688\n",
      "evaluation/env_infos/final/is_success Mean                       0.90625\n",
      "evaluation/env_infos/final/is_success Std                        0.291481\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0570866\n",
      "evaluation/env_infos/is_success Std                              0.232008\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.131583\n",
      "time/evaluation sampling (s)                                    17.8825\n",
      "time/exploration sampling (s)                                   40.3035\n",
      "time/logging (s)                                                 0.0077588\n",
      "time/saving (s)                                                  0.0695575\n",
      "time/training (s)                                              227.991\n",
      "time/epoch (s)                                                 286.386\n",
      "time/total (s)                                               22435.6\n",
      "Epoch                                                           85\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 8\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 86\n",
      "\n",
      " Cycle 0 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 93655\n",
      "Soft update 68800\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 86\n",
      "Added episode 50\n",
      "Replay buf 93705\n",
      "Soft update 68840\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 93777\n",
      "Soft update 68880\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 50\n",
      "Replay buf 93840\n",
      "Soft update 68920\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 86\n",
      "Added episode 50\n",
      "Replay buf 93890\n",
      "Soft update 68960\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 5 86\n",
      "Added episode 50\n",
      "Replay buf 93940\n",
      "Soft update 69000\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 6 86\n",
      "Added episode 50\n",
      "Replay buf 93990\n",
      "Soft update 69040\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 7 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 16\n",
      "Added episode 11\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 94078\n",
      "Soft update 69080\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 8 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 94149\n",
      "Soft update 69120\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 9 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 17\n",
      "Added episode 10\n",
      "Added episode 9\n",
      "Added episode 11\n",
      "Replay buf 94207\n",
      "Soft update 69160\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 10 86\n",
      "Added episode 50\n",
      "Replay buf 94257\n",
      "Soft update 69200\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 11 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 22\n",
      "Added episode 10\n",
      "Added episode 13\n",
      "Added episode 13\n",
      "Replay buf 94315\n",
      "Soft update 69240\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 12 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 15\n",
      "Added episode 50\n",
      "Replay buf 94380\n",
      "Soft update 69280\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 13 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 13\n",
      "Added episode 20\n",
      "Added episode 50\n",
      "Replay buf 94463\n",
      "Soft update 69320\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 14 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 94525\n",
      "Soft update 69360\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 15 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 10\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 94606\n",
      "Soft update 69400\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 16 86\n",
      "Added episode 50\n",
      "Replay buf 94656\n",
      "Soft update 69440\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 17 86\n",
      "Added episode 50\n",
      "Replay buf 94706\n",
      "Soft update 69480\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 18 86\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 14\n",
      "Added episode 50\n",
      "Replay buf 94779\n",
      "Soft update 69520\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 19 86\n",
      "Added episode 50\n",
      "Replay buf 94829\n",
      "Soft update 69560\n",
      "Trained for 40 times\n",
      "Ending epoch\n",
      "2020-09-10 15:11:14.034968 EEST | [final-sideways-pixels-final-31] Epoch 86 finished\n",
      "Logging demo path stats\n",
      "Logged eval success rate and maybe state estimation loss\n",
      "-----------------------------------------------------------  ---------------\n",
      "trainer/QF Loss                                                  2.63803\n",
      "trainer/Policy Loss                                              0.0109505\n",
      "trainer/Raw Policy Loss                                          0.0109505\n",
      "trainer/State estimation loss                                    0.00364334\n",
      "trainer/Preactivation Policy Loss                                0\n",
      "trainer/Q Predictions Mean                                     -11.2098\n",
      "trainer/Q Predictions Std                                       16.0149\n",
      "trainer/Q Predictions Max                                       43.8192\n",
      "trainer/Q Predictions Min                                      -57.3959\n",
      "trainer/Q Targets Mean                                         -11.2069\n",
      "trainer/Q Targets Std                                           15.9889\n",
      "trainer/Q Targets Max                                           43.8483\n",
      "trainer/Q Targets Min                                          -57.099\n",
      "trainer/Bellman Errors Mean                                      2.63803\n",
      "trainer/Bellman Errors Std                                      25.2402\n",
      "trainer/Bellman Errors Max                                     637.195\n",
      "trainer/Bellman Errors Min                                       2.94676e-08\n",
      "trainer/Policy Action Mean                                      -0.186437\n",
      "trainer/Policy Action Std                                        0.664597\n",
      "trainer/Policy Action Max                                        1\n",
      "trainer/Policy Action Min                                       -1\n",
      "exploration/num steps total                                  94829\n",
      "exploration/num paths total                                   2472\n",
      "exploration/path length Mean                                    26.766\n",
      "exploration/path length Std                                     18.4647\n",
      "exploration/path length Max                                     50\n",
      "exploration/path length Min                                      9\n",
      "exploration/Rewards Mean                                        -0.976948\n",
      "exploration/Rewards Std                                          0.15007\n",
      "exploration/Rewards Max                                         -0\n",
      "exploration/Rewards Min                                         -1\n",
      "exploration/Returns Mean                                       -26.1489\n",
      "exploration/Returns Std                                         18.9467\n",
      "exploration/Returns Max                                         -8\n",
      "exploration/Returns Min                                        -50\n",
      "exploration/Actions Mean                                        -0.178322\n",
      "exploration/Actions Std                                          0.687636\n",
      "exploration/Actions Max                                          1\n",
      "exploration/Actions Min                                         -1\n",
      "exploration/Num Paths                                           47\n",
      "exploration/Average Returns                                    -26.1489\n",
      "exploration/env_infos/final/is_success Mean                      0.617021\n",
      "exploration/env_infos/final/is_success Std                       0.486113\n",
      "exploration/env_infos/final/is_success Max                       1\n",
      "exploration/env_infos/final/is_success Min                       0\n",
      "exploration/env_infos/initial/is_success Mean                    0\n",
      "exploration/env_infos/initial/is_success Std                     0\n",
      "exploration/env_infos/initial/is_success Max                     0\n",
      "exploration/env_infos/initial/is_success Min                     0\n",
      "exploration/env_infos/is_success Mean                            0.0230525\n",
      "exploration/env_infos/is_success Std                             0.15007\n",
      "exploration/env_infos/is_success Max                             1\n",
      "exploration/env_infos/is_success Min                             0\n",
      "evaluation/num steps total                                   44471\n",
      "evaluation/num paths total                                    1321\n",
      "evaluation/path length Mean                                     12.2927\n",
      "evaluation/path length Std                                       6.32935\n",
      "evaluation/path length Max                                      50\n",
      "evaluation/path length Min                                       9\n",
      "evaluation/Rewards Mean                                         -0.920635\n",
      "evaluation/Rewards Std                                           0.270308\n",
      "evaluation/Rewards Max                                          -0\n",
      "evaluation/Rewards Min                                          -1\n",
      "evaluation/Returns Mean                                        -11.3171\n",
      "evaluation/Returns Std                                           6.47486\n",
      "evaluation/Returns Max                                          -8\n",
      "evaluation/Returns Min                                         -50\n",
      "evaluation/Actions Mean                                         -0.238794\n",
      "evaluation/Actions Std                                           0.752176\n",
      "evaluation/Actions Max                                           0.999999\n",
      "evaluation/Actions Min                                          -1\n",
      "evaluation/Num Paths                                            41\n",
      "evaluation/Average Returns                                     -11.3171\n",
      "evaluation/env_infos/final/is_success Mean                       0.97561\n",
      "evaluation/env_infos/final/is_success Std                        0.154257\n",
      "evaluation/env_infos/final/is_success Max                        1\n",
      "evaluation/env_infos/final/is_success Min                        0\n",
      "evaluation/env_infos/initial/is_success Mean                     0\n",
      "evaluation/env_infos/initial/is_success Std                      0\n",
      "evaluation/env_infos/initial/is_success Max                      0\n",
      "evaluation/env_infos/initial/is_success Min                      0\n",
      "evaluation/env_infos/is_success Mean                             0.0793651\n",
      "evaluation/env_infos/is_success Std                              0.270308\n",
      "evaluation/env_infos/is_success Max                              1\n",
      "evaluation/env_infos/is_success Min                              0\n",
      "evaluation/demonstrations/Rewards Mean                          -0.971264\n",
      "evaluation/demonstrations/Rewards Std                            0.167063\n",
      "evaluation/demonstrations/Rewards Max                           -0\n",
      "evaluation/demonstrations/Rewards Min                           -1\n",
      "evaluation/demonstrations/Returns Mean                         -33.8\n",
      "evaluation/demonstrations/Returns Std                            5.97997\n",
      "evaluation/demonstrations/Returns Max                          -28\n",
      "evaluation/demonstrations/Returns Min                          -47\n",
      "evaluation/demonstrations/Actions Mean                          -0.0799319\n",
      "evaluation/demonstrations/Actions Std                            0.291659\n",
      "evaluation/demonstrations/Actions Max                            0.522945\n",
      "evaluation/demonstrations/Actions Min                           -0.779109\n",
      "evaluation/demonstrations/Num Paths                             10\n",
      "evaluation/demonstrations/Average Returns                      -33.8\n",
      "evaluation/demonstrations/env_infos/final/is_success Mean        1\n",
      "evaluation/demonstrations/env_infos/final/is_success Std         0\n",
      "evaluation/demonstrations/env_infos/final/is_success Max         1\n",
      "evaluation/demonstrations/env_infos/final/is_success Min         1\n",
      "evaluation/demonstrations/env_infos/initial/is_success Mean      0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Std       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Max       0\n",
      "evaluation/demonstrations/env_infos/initial/is_success Min       0\n",
      "evaluation/demonstrations/env_infos/is_success Mean              0.0287356\n",
      "evaluation/demonstrations/env_infos/is_success Std               0.167063\n",
      "evaluation/demonstrations/env_infos/is_success Max               1\n",
      "evaluation/demonstrations/env_infos/is_success Min               0\n",
      "time/data storing (s)                                            0.127748\n",
      "time/evaluation sampling (s)                                    16.0273\n",
      "time/exploration sampling (s)                                   41.0761\n",
      "time/logging (s)                                                 0.00788277\n",
      "time/saving (s)                                                  0.0694066\n",
      "time/training (s)                                              219.314\n",
      "time/epoch (s)                                                 276.623\n",
      "time/total (s)                                               22712.3\n",
      "Epoch                                                           86\n",
      "-----------------------------------------------------------  ---------------\n",
      "Evaluation sampling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image capture 0\n",
      "Image capture 1\n",
      "Image capture 2\n",
      "Image capture 3\n",
      "Image capture 4\n",
      "Image capture 5\n",
      "Image capture 6\n",
      "Image capture 7\n",
      "Image capture 8\n",
      "Image capture 9\n",
      "Image capture 10\n",
      "Image capture 11\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Image capture 12\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 87\n",
      "\n",
      " Cycle 0 87\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 11\n",
      "Added episode 9\n",
      "Added episode 11\n",
      "Added episode 10\n",
      "Replay buf 94879\n",
      "Soft update 69600\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 1 87\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 12\n",
      "Added episode 50\n",
      "Replay buf 94941\n",
      "Soft update 69640\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 2 87\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 10\n",
      "Added episode 50\n",
      "Replay buf 95001\n",
      "Soft update 69680\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 3 87\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 11\n",
      "Added episode 50\n",
      "Replay buf 95062\n",
      "Soft update 69720\n",
      "Trained for 40 times\n",
      "\n",
      " Cycle 4 87\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Added episode 9\n",
      "Added episode 19\n",
      "Added episode 50\n",
      "Replay buf 95140\n",
      "Soft update 69760\n"
     ]
    }
   ],
   "source": [
    "!python her_ddpg_cloth_sideways_pixels.py --run=1 --title=final-3\n",
    "!python her_ddpg_cloth_sideways_pixels.py --run=2 --title=final-3\n",
    "!python her_ddpg_cloth_sideways_pixels.py --run=3 --title=final-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
